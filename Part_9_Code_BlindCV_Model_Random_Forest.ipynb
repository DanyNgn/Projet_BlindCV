{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\python39\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python39\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python39\\lib\\site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python39\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip \n",
    "pip.main([\"install\",\"matplotlib\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\python39\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\python39\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\python39\\lib\\site-packages (from xgboost) (1.23.1)\n",
      "Requirement already satisfied: scipy in c:\\python39\\lib\\site-packages (from xgboost) (1.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # to avoid deprecation warnings\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la dataset\n",
    "## Choix de 4 datasets, ne pas oublier de choisir la features_list adéquate\n",
    "\n",
    "#dataset = pd.read_csv(\"dataset_CV_labelise_features1_100.csv\", delimiter = \";\", encoding = \"utf-8\") ## 100CV + 4 features numériques\n",
    "\n",
    "#dataset = pd.read_csv(\"dataset_CV_labelise_features1_200.csv\", delimiter = \";\", encoding = \"utf-8\") ## 200CV + 4 features numériques\n",
    "\n",
    "#dataset = pd.read_csv(\"dataset_CV_labelise_features2_100.csv\", delimiter = \";\", encoding = \"utf-8\") ## 100CV + 12 features numériques\n",
    "\n",
    "dataset = pd.read_csv(\"dataset_CV_labelise_features2_200.csv\", delimiter = \";\", encoding = \"utf-8\") ## 200CV + 12 features numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5594, 19)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Sentences</th>\n",
       "      <th>Sentences_CV_clean</th>\n",
       "      <th>CV_Number</th>\n",
       "      <th>Sentence_line</th>\n",
       "      <th>Nb_tokens</th>\n",
       "      <th>%texte_lu</th>\n",
       "      <th>%texte_lu_fin_ligne</th>\n",
       "      <th>Is_alpha</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Tokenization</th>\n",
       "      <th>Verb_count</th>\n",
       "      <th>Propn_count</th>\n",
       "      <th>Noun_count</th>\n",
       "      <th>Num_count</th>\n",
       "      <th>Pourcentage_verb_sentence</th>\n",
       "      <th>Pourcentage_propn_sentence</th>\n",
       "      <th>Pourcentage_noun_sentence</th>\n",
       "      <th>Pourcentage_num_sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5594</td>\n",
       "      <td>5592</td>\n",
       "      <td>5594</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594</td>\n",
       "      <td>5594</td>\n",
       "      <td>5592</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.00000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3805</td>\n",
       "      <td>3802</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1626</td>\n",
       "      <td>2748</td>\n",
       "      <td>3802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CV_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[False]</td>\n",
       "      <td>['NOUN']</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>638</td>\n",
       "      <td>334</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.673221</td>\n",
       "      <td>9.132285</td>\n",
       "      <td>50.470518</td>\n",
       "      <td>49.529483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297283</td>\n",
       "      <td>0.611012</td>\n",
       "      <td>2.83822</td>\n",
       "      <td>0.320164</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.105039</td>\n",
       "      <td>0.314979</td>\n",
       "      <td>0.042982</td>\n",
       "      <td>0.031105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.268076</td>\n",
       "      <td>10.914849</td>\n",
       "      <td>30.190027</td>\n",
       "      <td>30.190025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784780</td>\n",
       "      <td>1.129198</td>\n",
       "      <td>3.56600</td>\n",
       "      <td>0.693458</td>\n",
       "      <td>0.059959</td>\n",
       "      <td>0.227969</td>\n",
       "      <td>0.251108</td>\n",
       "      <td>0.131906</td>\n",
       "      <td>0.173616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.190000</td>\n",
       "      <td>23.552500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>49.530000</td>\n",
       "      <td>50.470000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>76.447500</td>\n",
       "      <td>75.810000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.760000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CV_Sentences Sentences_CV_clean CV_Number  Sentence_line    Nb_tokens  \\\n",
       "count          5594               5592      5594    5594.000000  5594.000000   \n",
       "unique         3805               3802       200            NaN          NaN   \n",
       "top                                        CV_10            NaN          NaN   \n",
       "freq            198                198        66            NaN          NaN   \n",
       "mean            NaN                NaN       NaN      15.673221     9.132285   \n",
       "std             NaN                NaN       NaN      11.268076    10.914849   \n",
       "min             NaN                NaN       NaN       0.000000     1.000000   \n",
       "25%             NaN                NaN       NaN       7.000000     2.000000   \n",
       "50%             NaN                NaN       NaN      14.000000     5.000000   \n",
       "75%             NaN                NaN       NaN      23.000000    12.000000   \n",
       "max             NaN                NaN       NaN      65.000000   124.000000   \n",
       "\n",
       "          %texte_lu  %texte_lu_fin_ligne Is_alpha   Grammar Tokenization  \\\n",
       "count   5594.000000          5594.000000     5594      5594         5592   \n",
       "unique          NaN                  NaN     1626      2748         3802   \n",
       "top             NaN                  NaN  [False]  ['NOUN']                \n",
       "freq            NaN                  NaN      638       334          198   \n",
       "mean      50.470518            49.529483      NaN       NaN          NaN   \n",
       "std       30.190027            30.190025      NaN       NaN          NaN   \n",
       "min        0.240000             0.000000      NaN       NaN          NaN   \n",
       "25%       24.190000            23.552500      NaN       NaN          NaN   \n",
       "50%       49.530000            50.470000      NaN       NaN          NaN   \n",
       "75%       76.447500            75.810000      NaN       NaN          NaN   \n",
       "max      100.000000            99.760000      NaN       NaN          NaN   \n",
       "\n",
       "         Verb_count  Propn_count  Noun_count    Num_count  \\\n",
       "count   5594.000000  5594.000000  5594.00000  5594.000000   \n",
       "unique          NaN          NaN         NaN          NaN   \n",
       "top             NaN          NaN         NaN          NaN   \n",
       "freq            NaN          NaN         NaN          NaN   \n",
       "mean       0.297283     0.611012     2.83822     0.320164   \n",
       "std        0.784780     1.129198     3.56600     0.693458   \n",
       "min        0.000000     0.000000     0.00000     0.000000   \n",
       "25%        0.000000     0.000000     1.00000     0.000000   \n",
       "50%        0.000000     0.000000     2.00000     0.000000   \n",
       "75%        0.000000     1.000000     4.00000     0.000000   \n",
       "max        8.000000    14.000000    39.00000     8.000000   \n",
       "\n",
       "        Pourcentage_verb_sentence  Pourcentage_propn_sentence  \\\n",
       "count                 5594.000000                 5594.000000   \n",
       "unique                        NaN                         NaN   \n",
       "top                           NaN                         NaN   \n",
       "freq                          NaN                         NaN   \n",
       "mean                     0.020117                    0.105039   \n",
       "std                      0.059959                    0.227969   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      0.000000                    0.000000   \n",
       "50%                      0.000000                    0.000000   \n",
       "75%                      0.000000                    0.102564   \n",
       "max                      1.000000                    1.000000   \n",
       "\n",
       "        Pourcentage_noun_sentence  Pourcentage_num_sentence        Label  \n",
       "count                 5594.000000               5594.000000  5594.000000  \n",
       "unique                        NaN                       NaN          NaN  \n",
       "top                           NaN                       NaN          NaN  \n",
       "freq                          NaN                       NaN          NaN  \n",
       "mean                     0.314979                  0.042982     0.031105  \n",
       "std                      0.251108                  0.131906     0.173616  \n",
       "min                      0.000000                  0.000000     0.000000  \n",
       "25%                      0.157895                  0.000000     0.000000  \n",
       "50%                      0.307692                  0.000000     0.000000  \n",
       "75%                      0.416667                  0.000000     0.000000  \n",
       "max                      1.000000                  1.000000     1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_desc = dataset.describe(include='all')\n",
    "display(data_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_Sentences                  0.000000\n",
       "Sentences_CV_clean            0.035753\n",
       "CV_Number                     0.000000\n",
       "Sentence_line                 0.000000\n",
       "Nb_tokens                     0.000000\n",
       "%texte_lu                     0.000000\n",
       "%texte_lu_fin_ligne           0.000000\n",
       "Is_alpha                      0.000000\n",
       "Grammar                       0.000000\n",
       "Tokenization                  0.035753\n",
       "Verb_count                    0.000000\n",
       "Propn_count                   0.000000\n",
       "Noun_count                    0.000000\n",
       "Num_count                     0.000000\n",
       "Pourcentage_verb_sentence     0.000000\n",
       "Pourcentage_propn_sentence    0.000000\n",
       "Pourcentage_noun_sentence     0.000000\n",
       "Pourcentage_num_sentence      0.000000\n",
       "Label                         0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(100*dataset.isnull().sum()/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifier des valeurs de la colonne label\n",
    "dataset[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5416, 19)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des lignes de CV_Sentences avec les '#NOM?'\n",
    "dataset = dataset.loc[(dataset['CV_Sentences'] != \"#NOM?\"),:]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 19)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des lignes de CV_Sentences avec ':'\n",
    "dataset = dataset.loc[(dataset['CV_Sentences'] != \":\"),:]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5410, 19)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppresion des lignes sans valeur (avec NaN)\n",
    "dataset = dataset.dropna(axis =0, how = 'any')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_Sentences                  0.0\n",
       "Sentences_CV_clean            0.0\n",
       "CV_Number                     0.0\n",
       "Sentence_line                 0.0\n",
       "Nb_tokens                     0.0\n",
       "%texte_lu                     0.0\n",
       "%texte_lu_fin_ligne           0.0\n",
       "Is_alpha                      0.0\n",
       "Grammar                       0.0\n",
       "Tokenization                  0.0\n",
       "Verb_count                    0.0\n",
       "Propn_count                   0.0\n",
       "Noun_count                    0.0\n",
       "Num_count                     0.0\n",
       "Pourcentage_verb_sentence     0.0\n",
       "Pourcentage_propn_sentence    0.0\n",
       "Pourcentage_noun_sentence     0.0\n",
       "Pourcentage_num_sentence      0.0\n",
       "Label                         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vérification de la présence des valeurs 'Null' dans la dataset\n",
    "display(100*dataset.isnull().sum()/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application du modèle Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Sentences</th>\n",
       "      <th>Sentences_CV_clean</th>\n",
       "      <th>CV_Number</th>\n",
       "      <th>Sentence_line</th>\n",
       "      <th>Nb_tokens</th>\n",
       "      <th>%texte_lu</th>\n",
       "      <th>%texte_lu_fin_ligne</th>\n",
       "      <th>Is_alpha</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Tokenization</th>\n",
       "      <th>Verb_count</th>\n",
       "      <th>Propn_count</th>\n",
       "      <th>Noun_count</th>\n",
       "      <th>Num_count</th>\n",
       "      <th>Pourcentage_verb_sentence</th>\n",
       "      <th>Pourcentage_propn_sentence</th>\n",
       "      <th>Pourcentage_noun_sentence</th>\n",
       "      <th>Pourcentage_num_sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE</td>\n",
       "      <td>SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE</td>\n",
       "      <td>CV_1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.80</td>\n",
       "      <td>97.20</td>\n",
       "      <td>[True, True, True, False, True, True]</td>\n",
       "      <td>['NOUN', 'PROPN', 'VERB', 'NUM', 'PROPN', 'PRO...</td>\n",
       "      <td>SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROFIL</td>\n",
       "      <td>PROFIL</td>\n",
       "      <td>CV_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>96.73</td>\n",
       "      <td>[True]</td>\n",
       "      <td>['NOUN']</td>\n",
       "      <td>PROFIL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 CV_Sentences  \\\n",
       "0  SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE   \n",
       "1                                      PROFIL   \n",
       "\n",
       "                           Sentences_CV_clean CV_Number  Sentence_line  \\\n",
       "0  SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE      CV_1              0   \n",
       "1                                      PROFIL      CV_1              1   \n",
       "\n",
       "   Nb_tokens  %texte_lu  %texte_lu_fin_ligne  \\\n",
       "0          6       2.80                97.20   \n",
       "1          1       3.27                96.73   \n",
       "\n",
       "                                Is_alpha  \\\n",
       "0  [True, True, True, False, True, True]   \n",
       "1                                 [True]   \n",
       "\n",
       "                                             Grammar  \\\n",
       "0  ['NOUN', 'PROPN', 'VERB', 'NUM', 'PROPN', 'PRO...   \n",
       "1                                           ['NOUN']   \n",
       "\n",
       "                                 Tokenization  Verb_count  Propn_count  \\\n",
       "0  SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE           1            3   \n",
       "1                                      PROFIL           0            0   \n",
       "\n",
       "   Noun_count  Num_count  Pourcentage_verb_sentence  \\\n",
       "0           1          1                   0.166667   \n",
       "1           1          0                   0.000000   \n",
       "\n",
       "   Pourcentage_propn_sentence  Pourcentage_noun_sentence  \\\n",
       "0                         0.5                   0.166667   \n",
       "1                         0.0                   1.000000   \n",
       "\n",
       "   Pourcentage_num_sentence  Label  \n",
       "0                  0.166667      1  \n",
       "1                  0.000000      0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "y : \n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "X :\n",
      "   Sentence_line  Nb_tokens  %texte_lu  %texte_lu_fin_ligne  Verb_count  \\\n",
      "0              0          6       2.80                97.20           1   \n",
      "1              1          1       3.27                96.73           0   \n",
      "2              2          8       7.01                92.99           0   \n",
      "3              3         24      18.22                81.78           5   \n",
      "4              4          1      18.69                81.31           0   \n",
      "\n",
      "   Propn_count  Noun_count  Num_count  Pourcentage_verb_sentence  \\\n",
      "0            3           1          1                   0.166667   \n",
      "1            0           1          0                   0.000000   \n",
      "2            1           2          0                   0.000000   \n",
      "3            1           5          1                   0.208333   \n",
      "4            0           1          0                   0.000000   \n",
      "\n",
      "   Pourcentage_propn_sentence  Pourcentage_noun_sentence  \\\n",
      "0                    0.500000                   0.166667   \n",
      "1                    0.000000                   1.000000   \n",
      "2                    0.125000                   0.250000   \n",
      "3                    0.041667                   0.208333   \n",
      "4                    0.000000                   1.000000   \n",
      "\n",
      "   Pourcentage_num_sentence  \n",
      "0                  0.166667  \n",
      "1                  0.000000  \n",
      "2                  0.000000  \n",
      "3                  0.041667  \n",
      "4                  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "\n",
    "## Choisir la features_list par rapport au dataset\n",
    "#features_list = [\"CV_Sentences\",\"Sentences_CV_clean\",\"CV_Number\", \"Is_alpha\", \"Grammar\", \"Label\"] ## Pour les datasets features1\n",
    "features_list = [\"CV_Sentences\",\"Sentences_CV_clean\",\"CV_Number\", \"Is_alpha\", \"Label\", \"Grammar\", \"Tokenization\"] ## Pour les datasets features2\n",
    "target_variable = \"Label\"\n",
    "\n",
    "X = dataset.drop(features_list, axis = 1)\n",
    "y = dataset.loc[:,target_variable]\n",
    "\n",
    "print('y : ')\n",
    "print(y.head())\n",
    "print()\n",
    "print('X :')\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['Sentence_line', 'Nb_tokens', '%texte_lu', '%texte_lu_fin_ligne', 'Verb_count', 'Propn_count', 'Noun_count', 'Num_count', 'Pourcentage_verb_sentence', 'Pourcentage_propn_sentence', 'Pourcentage_noun_sentence', 'Pourcentage_num_sentence']\n",
      "Found categorical features  []\n"
     ]
    }
   ],
   "source": [
    "# Automatically detect names of numeric/categorical columns\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "    if ('float' in str(t)) or ('int' in str(t)) :\n",
    "        numeric_features.append(i)\n",
    "    else :\n",
    "        categorical_features.append(i)\n",
    "\n",
    "print('Found numeric features ', numeric_features)\n",
    "print('Found categorical features ', categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_transformer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for categorical features\n",
    "categorical_transformer = OneHotEncoder(drop='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 10, 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 40}\n",
      "Best validation accuracy :  0.9798986546559364\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'n_estimators': [10, 20, 40, 60, 80, 100]\n",
    "}\n",
    "gridsearch = GridSearchCV(classifier, param_grid = params, cv = 3) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = gridsearch.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = gridsearch.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set :  0.982902033271719\n",
      "accuracy on test set :  0.9805914972273567\n",
      "\n",
      "f1-score on training set :  0.689075630252101\n",
      "f1-score on test set :  0.6666666666666665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print scores\n",
    "print(\"accuracy on training set : \", accuracy_score(y_train, Y_train_pred))\n",
    "print(\"accuracy on test set : \", accuracy_score(y_test, Y_test_pred))\n",
    "print()\n",
    "\n",
    "print(\"f1-score on training set : \", f1_score(y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(y_test, Y_test_pred))                              \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegarder résultat pour Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model'\n",
    "pickle.dump(gridsearch, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.predict(X_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(np.array([0, 6, 2.8, 97.2, 1, 3, 1, 1, 0.5, 1, 1, 1]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(np.array([1, 2, 2.8, 97.2, 0, 2, 0, 0, 0, 1, 0, 0]).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences_CV_clean</th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Label_Pred</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>-89  bonjour@supersite.fr  3, rue de la Républ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>Menuisier</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2210</th>\n",
       "      <td>CÉLIA ROBERT  ANTHROPOLOGUE           PARCOURS...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4201</th>\n",
       "      <td>Karine Perrin     7  À  Amoureuse de mode depu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>COMPÉTENCES  Alain Amari  Professeur de Musiqu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>erge</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>FRANCK</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>JEAN TIBUTÉ  VENDEUR EN MAGASIN BIO  QUI SUIS-JE?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3289</th>\n",
       "      <td>QE RP</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>ASSISTANT MARKETING  COMPÉTENCES CLTERIT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>HARUMI</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>Céline Letellier,  BTPro  01 45943675</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3084</th>\n",
       "      <td>EMMA GIRAUD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>TIBUTÉ  VENDEUR EN MAGASIN BIO     QUI SUIS-JE?</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3716</th>\n",
       "      <td>Li</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Samira Hadid  16 place Urbain II,</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2526</th>\n",
       "      <td>THOMAS  EXPÉRIENCES PROFESSIONNELLES</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>DD</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2654</th>\n",
       "      <td>GUÉRIN  Spécialiste en ressources humaines    ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>Victor Hugo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>SACHA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Sentences_CV_clean  True_Label  \\\n",
       "2620  -89  bonjour@supersite.fr  3, rue de la Républ...           1   \n",
       "4783                                          Menuisier           0   \n",
       "2210  CÉLIA ROBERT  ANTHROPOLOGUE           PARCOURS...           1   \n",
       "4201  Karine Perrin     7  À  Amoureuse de mode depu...           1   \n",
       "4992  COMPÉTENCES  Alain Amari  Professeur de Musiqu...           1   \n",
       "3037                                               erge           1   \n",
       "1683                                             FRANCK           1   \n",
       "4640  JEAN TIBUTÉ  VENDEUR EN MAGASIN BIO  QUI SUIS-JE?           1   \n",
       "3289                                              QE RP           0   \n",
       "4810           ASSISTANT MARKETING  COMPÉTENCES CLTERIT           0   \n",
       "1818                                             HARUMI           1   \n",
       "2499              Céline Letellier,  BTPro  01 45943675           1   \n",
       "3084                                      EMMA GIRAUD             0   \n",
       "1748  TIBUTÉ  VENDEUR EN MAGASIN BIO     QUI SUIS-JE?             1   \n",
       "3716                                                 Li           0   \n",
       "68                    Samira Hadid  16 place Urbain II,           0   \n",
       "2526             THOMAS  EXPÉRIENCES PROFESSIONNELLES             1   \n",
       "2521                                                 DD           0   \n",
       "2654  GUÉRIN  Spécialiste en ressources humaines    ...           1   \n",
       "3633                                      Victor Hugo             1   \n",
       "1586                                              SACHA           1   \n",
       "\n",
       "      Label_Pred Diff  \n",
       "2620           0    1  \n",
       "4783           1    1  \n",
       "2210           0    1  \n",
       "4201           0    1  \n",
       "4992           0    1  \n",
       "3037           0    1  \n",
       "1683           0    1  \n",
       "4640           0    1  \n",
       "3289           1    1  \n",
       "4810           1    1  \n",
       "1818           0    1  \n",
       "2499           0    1  \n",
       "3084           1    1  \n",
       "1748           0    1  \n",
       "3716           1    1  \n",
       "68             1    1  \n",
       "2526           0    1  \n",
       "2521           1    1  \n",
       "2654           0    1  \n",
       "3633           0    1  \n",
       "1586           0    1  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Choisir la features_list par rapport au dataset\n",
    "feature = \"Sentences_CV_clean\"\n",
    "target_variable = \"Label\"\n",
    "\n",
    "X = dataset.loc[:,feature]\n",
    "Y = dataset.loc[:,target_variable]\n",
    "\n",
    "## Split train pour obtenir uniquement les test avec le random 42\n",
    "_ , X_test, _, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify = Y)\n",
    "\n",
    "## Création d'un dataframe pour accueillir les prédictions \n",
    "dataset_pred = pd.DataFrame()\n",
    "\n",
    "## Création des colonnes avec les valeurs correspondantes dans la dataset_pred\n",
    "dataset_pred['Sentences_CV_clean'] = X_test\n",
    "dataset_pred['True_Label'] = Y_test\n",
    "dataset_pred['Label_Pred'] = Y_test_pred\n",
    "\n",
    "## Ajout de la colonne [\"Diff\"] pour visualiser les erreurs de prédictions du model\n",
    "import numpy as np\n",
    "dataset_pred['Diff'] = np.where(dataset_pred['True_Label'] != dataset_pred['Label_Pred'], '1', '0')\n",
    "dataset_pred.loc[dataset_pred['Diff'] == '1', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output(dataset_pred):\n",
    "    output = \"\"\n",
    "    for index, row in dataset_pred.iterrows():\n",
    "        if row[\"True_Label\"] == 1:\n",
    "            output = output + row[\"Sentences_CV_clean\"] + \"\\n\"\n",
    "            dataset_pred.drop(index, inplace=True)\n",
    "                                \n",
    "    return dataset_pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_final = final_output(dataset_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences_CV_clean</th>\n",
       "      <th>True_Label</th>\n",
       "      <th>Label_Pred</th>\n",
       "      <th>Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>SOLUTIONS</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1716</th>\n",
       "      <td>PROFIL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5533</th>\n",
       "      <td>DOTE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>1lolaRel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656</th>\n",
       "      <td>- à aujourd'hui  1.Gestion du positionnement d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2651</th>\n",
       "      <td>MASTER EN INGÉNIERIE LOGICIELLE, CLASSE DE 200...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>Linkedin:</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4623</th>\n",
       "      <td>Meilleure ouvrière de France 2013  INFOS  98, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>- À présenté un argument de vente qui a sécuri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1047 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Sentences_CV_clean  True_Label  \\\n",
       "1581                                                              0   \n",
       "2194                                          SOLUTIONS           0   \n",
       "1716                                           PROFIL             0   \n",
       "5533                                             DOTE             0   \n",
       "2733                                           1lolaRel           0   \n",
       "...                                                 ...         ...   \n",
       "1656  - à aujourd'hui  1.Gestion du positionnement d...           0   \n",
       "2651  MASTER EN INGÉNIERIE LOGICIELLE, CLASSE DE 200...           0   \n",
       "555                                           Linkedin:           0   \n",
       "4623  Meilleure ouvrière de France 2013  INFOS  98, ...           0   \n",
       "2030  - À présenté un argument de vente qui a sécuri...           0   \n",
       "\n",
       "      Label_Pred Diff  \n",
       "1581           0    0  \n",
       "2194           0    0  \n",
       "1716           0    0  \n",
       "5533           0    0  \n",
       "2733           0    0  \n",
       "...          ...  ...  \n",
       "1656           0    0  \n",
       "2651           0    0  \n",
       "555            0    0  \n",
       "4623           0    0  \n",
       "2030           0    0  \n",
       "\n",
       "[1047 rows x 4 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Création d'un fichier Excel avec toutes les phrases de tous les CV\n",
    "#PATH = \"dataset_final.csv\"\n",
    "#dataset_final.to_csv(path_or_buf = PATH, index = False, sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ],
         "name": "train",
         "type": "heatmap",
         "x": [
          "0",
          "1"
         ],
         "xaxis": "x",
         "y": [
          "0",
          "1"
         ],
         "yaxis": "y",
         "z": [
          [
           4174,
           15
          ],
          [
           58,
           81
          ]
         ],
         "zmax": 4174,
         "zmin": 0
        },
        {
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ],
         "name": "test",
         "type": "heatmap",
         "x": [
          "0",
          "1"
         ],
         "xaxis": "x2",
         "y": [
          "0",
          "1"
         ],
         "yaxis": "y2",
         "z": [
          [
           1040,
           7
          ],
          [
           14,
           21
          ]
         ],
         "zmax": 4174,
         "zmin": 0
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "train",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "test",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Prediction",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0,
          "yanchor": "top",
          "yref": "paper",
          "yshift": -30
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "True label",
          "textangle": -90,
          "x": 0,
          "xanchor": "right",
          "xref": "paper",
          "xshift": -40,
          "y": 0.5,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion matrices",
         "x": 0.5
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize confusion matrices\n",
    "from plotly.subplots import make_subplots\n",
    "cm_train = confusion_matrix(y_train, Y_train_pred)\n",
    "cm_test = confusion_matrix(y_test, Y_test_pred)\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = 2, subplot_titles = (\"train\", \"test\"), \n",
    "                    x_title = 'Prediction', y_title = 'True label')\n",
    "fig.update_layout(\n",
    "        title = go.layout.Title(text = \"Confusion matrices\", x = 0.5))\n",
    "fig.update_yaxes(autorange='reversed')\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        name = 'train',\n",
    "        x = ['0', '1'], \n",
    "        y = ['0', '1'], \n",
    "        z = cm_train,\n",
    "        colorscale = 'gnbu',\n",
    "        zmin = 0,\n",
    "        zmax = max(cm_train.max(), cm_test.max())\n",
    "    ),\n",
    "    row = 1,\n",
    "    col = 1\n",
    ")  \n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        name = 'test',\n",
    "        x = ['0', '1'], \n",
    "        y = ['0', '1'], \n",
    "        z = cm_test,\n",
    "        colorscale = 'gnbu',\n",
    "        zmin = 0,\n",
    "        zmax = max(cm_train.max(), cm_test.max())\n",
    "    ),\n",
    "    row = 1,\n",
    "    col = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "train",
         "type": "scatter",
         "x": [
          0,
          0.05755395683453238,
          0.15827338129496402,
          0.16546762589928057,
          0.2158273381294964,
          0.2302158273381295,
          0.2446043165467626,
          0.2446043165467626,
          0.2589928057553957,
          0.2733812949640288,
          0.2733812949640288,
          0.302158273381295,
          0.30935251798561153,
          0.33093525179856115,
          0.37410071942446044,
          0.37410071942446044,
          0.38848920863309355,
          0.38848920863309355,
          0.4028776978417266,
          0.4244604316546763,
          0.4316546762589928,
          0.4316546762589928,
          0.4460431654676259,
          0.460431654676259,
          0.460431654676259,
          0.4748201438848921,
          0.5251798561151079,
          0.539568345323741,
          0.539568345323741,
          0.5467625899280576,
          0.5467625899280576,
          0.5611510791366906,
          0.5827338129496403,
          0.5971223021582733,
          0.60431654676259,
          0.60431654676259,
          0.60431654676259,
          0.6115107913669064,
          0.6115107913669064,
          0.6330935251798561,
          0.6474820143884892,
          0.6546762589928058,
          0.6690647482014388,
          0.6762589928057554,
          0.6762589928057554,
          0.6834532374100719,
          0.6834532374100719,
          0.697841726618705,
          0.7122302158273381,
          0.7122302158273381,
          0.7266187050359713,
          0.7266187050359713,
          0.7338129496402878,
          0.7338129496402878,
          0.7410071942446043,
          0.7410071942446043,
          0.7553956834532374,
          0.7553956834532374,
          0.762589928057554,
          0.762589928057554,
          0.762589928057554,
          0.762589928057554,
          0.762589928057554,
          0.7697841726618705,
          0.7697841726618705,
          0.7769784172661871,
          0.7769784172661871,
          0.7913669064748201,
          0.7913669064748201,
          0.7985611510791367,
          0.8201438848920863,
          0.8201438848920863,
          0.8273381294964028,
          0.8273381294964028,
          0.841726618705036,
          0.841726618705036,
          0.8489208633093526,
          0.8489208633093526,
          0.8489208633093526,
          0.8489208633093526,
          0.8561151079136691,
          0.8561151079136691,
          0.8561151079136691,
          0.8561151079136691,
          0.8705035971223022,
          0.8705035971223022,
          0.8776978417266187,
          0.8776978417266187,
          0.8848920863309353,
          0.8848920863309353,
          0.8920863309352518,
          0.8920863309352518,
          0.9064748201438849,
          0.9064748201438849,
          0.9064748201438849,
          0.9064748201438849,
          0.9064748201438849,
          0.9064748201438849,
          0.9136690647482014,
          0.9136690647482014,
          0.9136690647482014,
          0.920863309352518,
          0.920863309352518,
          0.9280575539568345,
          0.9280575539568345,
          0.935251798561151,
          0.935251798561151,
          0.935251798561151,
          0.9424460431654677,
          0.9424460431654677,
          0.9424460431654677,
          0.9424460431654677,
          0.9424460431654677,
          0.9424460431654677,
          0.9424460431654677,
          0.9496402877697842,
          0.9496402877697842,
          0.9640287769784173,
          0.9640287769784173,
          0.9640287769784173,
          0.9640287769784173,
          0.9640287769784173,
          0.9640287769784173,
          0.9640287769784173,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9712230215827338,
          0.9784172661870504,
          0.9784172661870504,
          0.9784172661870504,
          0.9784172661870504,
          0.9856115107913669,
          0.9856115107913669,
          0.9928057553956835,
          0.9928057553956835,
          0.9928057553956835,
          0.9928057553956835,
          0.9928057553956835,
          0.9928057553956835,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          0,
          0,
          0,
          0.00023872045834328001,
          0.00023872045834328001,
          0.00023872045834328001,
          0.00023872045834328001,
          0.00047744091668656003,
          0.00047744091668656003,
          0.00047744091668656003,
          0.0007161613750298401,
          0.0007161613750298401,
          0.0009548818333731201,
          0.0009548818333731201,
          0.0009548818333731201,
          0.0014323227500596801,
          0.0014323227500596801,
          0.0016710432084029601,
          0.0016710432084029601,
          0.0021484841250895203,
          0.0021484841250895203,
          0.0026259250417760803,
          0.0026259250417760803,
          0.0026259250417760803,
          0.0028646455001193603,
          0.0028646455001193603,
          0.0028646455001193603,
          0.0028646455001193603,
          0.0031033659584626403,
          0.0031033659584626403,
          0.0033420864168059203,
          0.0035808068751492002,
          0.0035808068751492002,
          0.0035808068751492002,
          0.0035808068751492002,
          0.004296968250179041,
          0.004774409166865601,
          0.004774409166865601,
          0.005251850083552161,
          0.005251850083552161,
          0.005251850083552161,
          0.005251850083552161,
          0.005251850083552161,
          0.005251850083552161,
          0.0062067319169252805,
          0.0062067319169252805,
          0.0066841728336118405,
          0.0066841728336118405,
          0.0066841728336118405,
          0.006922893291955121,
          0.006922893291955121,
          0.0076390546669849605,
          0.0076390546669849605,
          0.007877775125328241,
          0.007877775125328241,
          0.0083552160420148,
          0.0083552160420148,
          0.00883265695870136,
          0.00883265695870136,
          0.00907137741704464,
          0.009548818333731201,
          0.00978753879207448,
          0.010264979708761042,
          0.010264979708761042,
          0.01098114108379088,
          0.01098114108379088,
          0.011219861542134162,
          0.011219861542134162,
          0.01169730245882072,
          0.011936022917164,
          0.011936022917164,
          0.012413463833850561,
          0.012413463833850561,
          0.013129625208880401,
          0.013129625208880401,
          0.01456194795894008,
          0.01456194795894008,
          0.015039388875626641,
          0.0155168297923132,
          0.015755550250656482,
          0.015755550250656482,
          0.0167104320840296,
          0.017187873000716163,
          0.01742659345905944,
          0.01742659345905944,
          0.01862019575077584,
          0.01862019575077584,
          0.01957507758414896,
          0.02005251850083552,
          0.02124612079255192,
          0.02124612079255192,
          0.022439723084268323,
          0.022439723084268323,
          0.02339460491764144,
          0.024110766292671282,
          0.024826927667701122,
          0.02530436858438768,
          0.02578180950107424,
          0.02578180950107424,
          0.02602052995941752,
          0.026975411792790643,
          0.026975411792790643,
          0.02721413225113392,
          0.02721413225113392,
          0.02793029362616376,
          0.02793029362616376,
          0.028169014084507043,
          0.028646455001193602,
          0.028646455001193602,
          0.02912389591788016,
          0.030078777751253283,
          0.030556218667939842,
          0.031272380042969686,
          0.03174982095965624,
          0.03318214370971592,
          0.03318214370971592,
          0.03389830508474576,
          0.03389830508474576,
          0.03485318691811888,
          0.035091907376462166,
          0.03556934829314872,
          0.035808068751492006,
          0.036762950584865124,
          0.03843399379326808,
          0.038911434709954645,
          0.04153735975173072,
          0.042014800668417285,
          0.04249224158510384,
          0.0429696825017904,
          0.04368584387682024,
          0.044402005251850084,
          0.045834328001909765,
          0.04631176891859633,
          0.04702793029362616,
          0.04750537121031272,
          0.047744091668656,
          0.047744091668656,
          0.047982812126999286,
          0.04846025304368584,
          0.048937693960372404,
          0.04917641441871568,
          0.052518500835521606,
          0.052518500835521606,
          0.053712103127238,
          0.05442826450226784,
          0.05538314633564097,
          0.05586058725232752,
          0.05824779183576032,
          0.05824779183576032,
          0.05920267366913345,
          0.060157555502506566,
          0.060873716877536406,
          0.06135115779422296,
          0.0632609214609692,
          0.06373836237765576,
          0.06636428741943184,
          0.0668417283361184,
          0.06731916925280497,
          0.06779661016949153,
          0.0680353306278348,
          0.06851277154452136,
          0.06875149200286465,
          0.0692289329195512,
          0.07137741704464072,
          0.07185485796132729,
          0.0740033420864168,
          0.07471950346144665,
          0.07519694437813321,
          0.07567438529481976,
          0.07639054666984961,
          0.07686798758653617,
          0.07973263308665553,
          0.08021007400334208,
          0.08068751492002865,
          0.08140367629505849,
          0.08283599904511817,
          0.083552160420148,
          0.08450704225352113,
          0.08498448317020768,
          0.08546192408689425,
          0.0859393650035808,
          0.08689424683695393,
          0.09238481737884936,
          0.09310097875387921,
          0.09381714012890904,
          0.09477202196228217,
          0.095488183337312,
          0.09596562425399857,
          0.09620434471234185,
          0.0966817856290284,
          0.09787538792074481,
          0.09906899021246121,
          0.09930771067080449,
          0.09978515158749104,
          0.10026259250417761,
          0.10074003342086417,
          0.101456194795894,
          0.10193363571258057,
          0.10241107662926713,
          0.10312723800429696,
          0.10360467892098353,
          0.10408211983767009,
          0.10503700167104321,
          0.10551444258772977,
          0.107424206254476,
          0.10790164717116257,
          0.11028885175459537,
          0.11076629267128194,
          0.1124373358796849,
          0.11291477679637145,
          0.11315349725471473,
          0.11410837908808785,
          0.11434709954643113,
          0.11482454046311769,
          0.11554070183814753,
          0.11601814275483409,
          0.11912150871329673,
          0.11959894962998328,
          0.12031511100501313,
          0.12079255192169969,
          0.12150871329672953,
          0.12198615421341609,
          0.12317975650513249,
          0.12365719742181905,
          0.12389591788016233,
          0.1243733587968489,
          0.12485079971353545,
          0.12532824063022202,
          0.12604440200525185,
          0.1267605633802817,
          0.1277154452136548,
          0.12843160658868466,
          0.12890904750537122,
          0.12962520888040105,
          0.13058009071377416,
          0.1315349725471473,
          0.1324898543805204,
          0.13296729529720697,
          0.13344473621389352,
          0.13392217713058008,
          0.1351157794222965,
          0.13559322033898305,
          0.13630938171401288,
          0.13678682263069944,
          0.13726426354738602,
          0.13798042492241586,
          0.1384578658391024,
          0.13893530675578897,
          0.14012890904750538,
          0.14060634996419194,
          0.14132251133922177,
          0.14227739317259488,
          0.1434709954643113,
          0.14490331821437097,
          0.14538075913105752,
          0.1456194795894008,
          0.14633564096443066,
          0.14657436142277394,
          0.1470518023394605,
          0.1480066841728336,
          0.14848412508952016,
          0.14896156600620672,
          0.1494390069228933,
          0.15015516829792314,
          0.1506326092146097,
          0.15134877058963953,
          0.15182621150632608,
          0.15206493196466936,
          0.1530198137980425,
          0.15349725471472905,
          0.15445213654810216,
          0.15492957746478872,
          0.15588445929816186,
          0.1566006206731917,
          0.1589878252566245,
          0.16065886846502744,
          0.16161375029840058,
          0.1625686321317737,
          0.16280735259011697,
          0.16376223442349008,
          0.16447839579851994,
          0.1649558367152065,
          0.16519455717354978,
          0.16567199809023633,
          0.167104320840296,
          0.1673430412986393,
          0.16782048221532586,
          0.16829792313201242,
          0.16877536404869897,
          0.1694915254237288,
          0.17020768679875867,
          0.17044640725710195,
          0.1709238481737885,
          0.17402721413225114,
          0.17426593459059442,
          0.17522081642396753,
          0.17569825734065408,
          0.17617569825734064,
          0.17641441871568395,
          0.1768918596323705,
          0.17760802100740034,
          0.17832418238243017,
          0.17951778467414659,
          0.18023394604917642,
          0.18071138696586297,
          0.18118882788254953,
          0.1814275483408928,
          0.18190498925757936,
          0.18214370971592264,
          0.18381475292432561,
          0.1840534733826689,
          0.18476963475769873,
          0.1854857961327286,
          0.1864406779661017,
          0.18811172117450464,
          0.19049892575793745,
          0.190976366674624,
          0.19169252804965387,
          0.19216996896634042,
          0.1924086894246837,
          0.19312485079971353,
          0.19575077584148962,
          0.19885414179995226,
          0.1995703031749821,
          0.20004774409166864,
          0.20100262592504178,
          0.20148006684172834,
          0.2033898305084746,
          0.2043447123418477,
          0.20506087371687753,
          0.20577703509190737,
          0.2067319169252805,
          0.20720935784196706,
          0.20888040105037,
          0.2093578419670566,
          0.21055144425877298,
          0.21102888517545954,
          0.2115063260921461,
          0.21246120792551923,
          0.21317736930054906,
          0.21413225113392217,
          0.21460969205060873,
          0.21675817617569826,
          0.21699689663404154,
          0.21795177846741465,
          0.21842921938410123,
          0.2186679398424445,
          0.21914538075913106,
          0.22010026259250418,
          0.22415851038433993,
          0.2248746717593698,
          0.2270231558844593,
          0.22797803771783243,
          0.2294103604678921,
          0.23012652184292193,
          0.2303652423012652,
          0.2308426832179518,
          0.2317975650513249,
          0.23227500596801146,
          0.23251372642635473,
          0.23466221055144426,
          0.23490093100978754,
          0.23585581284316065,
          0.23609453330150393,
          0.23848173788493673,
          0.23872045834328,
          0.23919789925996657,
          0.23991406063499643,
          0.24397230842683218,
          0.244688469801862,
          0.24540463117689185,
          0.24659823346860826,
          0.24707567438529482,
          0.24779183576032465,
          0.25041776080210076,
          0.2511339221771306,
          0.25161136309381715,
          0.2520888040105037,
          0.2532824063022201,
          0.25375984721890665,
          0.25399856767724993,
          0.2544760085939365,
          0.2556696108856529,
          0.25590833134399615,
          0.2580568154690857,
          0.25853425638577227,
          0.25877297684411554,
          0.2592504177608021,
          0.26068274051086177,
          0.26092146096920504,
          0.2613989018858916,
          0.2628312246359513,
          0.2640248269276677,
          0.26450226784435427,
          0.26593459059441393,
          0.2664120315111005,
          0.2680830747195035,
          0.27285748388636905,
          0.27572212938648843,
          0.2759608498448317,
          0.27643829076151827,
          0.27787061351157794,
          0.27858677488660777,
          0.27882549534495105,
          0.28049653855335405,
          0.28169014084507044,
          0.2840773454285032,
          0.28455478634518977,
          0.2878968727619957,
          0.2888517545953688,
          0.2900453568870852,
          0.29052279780377177,
          0.29171640009548816,
          0.29649080926235377,
          0.2969682501790403,
          0.2988780138457866,
          0.3010264979708761,
          0.3022201002625925,
          0.3050847457627119,
          0.3062783480544283,
          0.3079493912628312,
          0.3091429935545476,
          0.3122463595130103,
          0.31248507997135355,
          0.31343996180472666,
          0.31487228455478633,
          0.31558844592981616,
          0.3160658868465027,
          0.31654332776318933,
          0.31749820959656244,
          0.31869181188827883,
          0.3201241346383385,
          0.3210790164717116,
          0.3237049415134877,
          0.3251372642635474,
          0.3260921460969205,
          0.3311052757221294,
          0.3322988780138458,
          0.3377894485557412,
          0.3392217713058009,
          0.33969921222248745,
          0.3399379326808307,
          0.34113153497254717,
          0.34256385772260683,
          0.3428025781809501,
          0.34709954643112917,
          0.34948675101456195,
          0.35044163284793506,
          0.35068035330627834,
          0.3535449988063977,
          0.35449988063977084,
          0.3547386010981141,
          0.36022917164000956,
          0.36046789209835284,
          0.36261637622344234,
          0.3630938171401289,
          0.36357125805681545,
          0.3638099785151587,
          0.36643590355693484,
          0.3666746240152781,
          0.3740749582239198,
          0.37455239914060634,
          0.3762234423490093,
          0.38052041059918834,
          0.38529481976605395,
          0.3860109811410838,
          0.39006922893291957,
          0.40200525185008357,
          0.4051086178085462,
          0.41155407018381474,
          0.41919312485079974,
          0.4285032227261876,
          0.4421102888517546,
          0.44760085939365,
          0.44831702076867985,
          0.4958223919789926,
          0.5037001671043209,
          0.508952017187873,
          0.5094294581045595,
          0.526856051563619,
          1
         ]
        },
        {
         "mode": "lines",
         "name": "test",
         "type": "scatter",
         "x": [
          0,
          0.02857142857142857,
          0.11428571428571428,
          0.11428571428571428,
          0.14285714285714285,
          0.2,
          0.22857142857142856,
          0.22857142857142856,
          0.42857142857142855,
          0.42857142857142855,
          0.45714285714285713,
          0.45714285714285713,
          0.4857142857142857,
          0.6,
          0.6,
          0.6285714285714286,
          0.6285714285714286,
          0.6571428571428571,
          0.6571428571428571,
          0.6857142857142857,
          0.6857142857142857,
          0.7142857142857143,
          0.7142857142857143,
          0.7428571428571429,
          0.7428571428571429,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.7714285714285715,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8,
          0.8285714285714286,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.8857142857142857,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9142857142857143,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          0.9428571428571428,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          0,
          0,
          0,
          0.0009551098376313276,
          0.0009551098376313276,
          0.0009551098376313276,
          0.0009551098376313276,
          0.0019102196752626551,
          0.0019102196752626551,
          0.0028653295128939827,
          0.0028653295128939827,
          0.004775549188156638,
          0.0066857688634192934,
          0.0066857688634192934,
          0.007640878701050621,
          0.007640878701050621,
          0.008595988538681949,
          0.008595988538681949,
          0.009551098376313277,
          0.009551098376313277,
          0.018147086914995225,
          0.018147086914995225,
          0.025787965616045846,
          0.025787965616045846,
          0.05157593123209169,
          0.05157593123209169,
          0.05348615090735435,
          0.055396370582617004,
          0.06399235912129896,
          0.0659025787965616,
          0.06972301814708691,
          0.07163323782234957,
          0.08213944603629417,
          0.08404966571155682,
          0.09742120343839542,
          0.09742120343839542,
          0.10219675262655205,
          0.1041069723018147,
          0.11079274116523401,
          0.11270296084049666,
          0.12034383954154727,
          0.12320916905444126,
          0.1251193887297039,
          0.12702960840496658,
          0.12893982808022922,
          0.13944603629417382,
          0.1413562559694365,
          0.15663801337153774,
          0.15854823304680038,
          0.1623686723973257,
          0.16427889207258833,
          0.16905444126074498,
          0.17096466093600765,
          0.1728748806112703,
          0.1766953199617956,
          0.17956064947468958,
          0.1833810888252149,
          0.18433619866284623,
          0.18624641833810887,
          0.19006685768863418,
          0.19484240687679083,
          0.19675262655205347,
          0.19961795606494748,
          0.2034383954154728,
          0.2034383954154728,
          0.2082139446036294,
          0.21298949379178606,
          0.21967526265520534,
          0.22158548233046801,
          0.22254059216809932,
          0.224450811843362,
          0.22731614135625597,
          0.23113658070678128,
          0.23686723973256923,
          0.23973256924546324,
          0.24164278892072588,
          0.2502387774594078,
          0.2531041069723018,
          0.25501432664756446,
          0.25692454632282713,
          0.2588347659980898,
          0.2664756446991404,
          0.27602674307545366,
          0.27793696275071633,
          0.2808022922636103,
          0.28557784145176696,
          0.28844317096466093,
          0.2903533906399236,
          0.2922636103151863,
          0.2932187201528176,
          0.29512893982808025,
          0.2979942693409742,
          0.3037249283667622,
          0.30563514804202485,
          0.30850047755491883,
          0.3142311365807068,
          0.31614135625596945,
          0.3209169054441261,
          0.3218720152817574,
          0.3237822349570201,
          0.3247373447946514,
          0.32855778414517667,
          0.335243553008596,
          0.33715377268385865,
          0.33715377268385865,
          0.3390639923591213,
          0.34001910219675263,
          0.3419293218720153,
          0.3438395415472779,
          0.3467048710601719,
          0.35052531041069723,
          0.3533906399235912,
          0.3543457497612225,
          0.3562559694364852,
          0.35912129894937916,
          0.3648519579751671,
          0.3667621776504298,
          0.37822349570200575,
          0.38013371537726837,
          0.38204393505253104,
          0.39255014326647564,
          0.39350525310410694,
          0.40019102196752626,
          0.40210124164278893,
          0.40974212034383956,
          0.42311365807067813,
          0.4259789875835721,
          0.43457497612225404,
          0.4364851957975167,
          0.4469914040114613,
          0.4603629417382999,
          0.4670487106017192,
          0.501432664756447,
          0.5128939828080229,
          0.5214899713467048,
          0.5339063992359121,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROC curve",
         "x": 0.5
        },
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize ROC curves\n",
    "probas_train = gridsearch.predict_proba(X_train)[:,1]\n",
    "precisions, recalls, thresholds = roc_curve(y_train, probas_train)\n",
    "fig = go.Figure(\n",
    "    data = go.Scatter(\n",
    "        name = 'train',\n",
    "        x = recalls, \n",
    "        y = precisions, \n",
    "        mode = 'lines'\n",
    "    ),\n",
    "    layout = go.Layout(\n",
    "        title = go.layout.Title(text = \"ROC curve\", x = 0.5),\n",
    "        xaxis = go.layout.XAxis(title = 'False Positive Rate'),\n",
    "        yaxis = go.layout.YAxis(title = 'True Positive Rate')\n",
    "    )\n",
    ")\n",
    "\n",
    "probas_test = gridsearch.predict_proba(X_test)[:,1]\n",
    "precisions, recalls, thresholds = roc_curve(y_test, probas_test)\n",
    "fig.add_trace(go.Scatter(\n",
    "    name = 'test',\n",
    "    x = recalls, \n",
    "    y = precisions, \n",
    "    mode = 'lines'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer différents Algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "classifiers.append(tree)\n",
    "classifiers.append(knn)\n",
    "classifiers.append(nb)\n",
    "classifiers.append(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers:\n",
    "  cv_results.append(cross_val_score(classifier, X_train, y_train, cv=10 ,scoring=\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.96766744, 0.97690531, 0.96997691, 0.97690531, 0.98383372,\n",
       "        0.98383372, 0.98383372, 0.97228637, 0.98148148, 0.97453704]),\n",
       " array([0.9630485 , 0.96766744, 0.96535797, 0.97690531, 0.98383372,\n",
       "        0.98152425, 0.97228637, 0.97228637, 0.98611111, 0.97222222]),\n",
       " array([0.83140878, 0.8591224 , 0.84064665, 0.84064665, 0.86143187,\n",
       "        0.87528868, 0.84757506, 0.87528868, 0.84722222, 0.84027778]),\n",
       " array([0.96997691, 0.97459584, 0.96766744, 0.96997691, 0.98152425,\n",
       "        0.97690531, 0.97690531, 0.96997691, 0.9837963 , 0.97685185])]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.977126</td>\n",
       "      <td>0.005699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.974818</td>\n",
       "      <td>0.005098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.974124</td>\n",
       "      <td>0.007430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.851891</td>\n",
       "      <td>0.014443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Accuracy_mean       Std\n",
       "0      tree       0.977126  0.005699\n",
       "3    logreg       0.974818  0.005098\n",
       "1       knn       0.974124  0.007430\n",
       "2        nb       0.851891  0.014443"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Algorithm\": [\"tree\", \"knn\", \"nb\", \"logreg\"],\n",
    "             \"Accuracy_mean\": [cv_result.mean() for cv_result in cv_results],\n",
    "             \"Std\": [cv_result.std() for cv_result in cv_results]})\n",
    "\n",
    "results = results.sort_values(by=\"Accuracy_mean\", ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "best Tree score on the train set : \n",
      " 0.9805914972273567 \n",
      " best Tree score on the test set : \n",
      " 0.9787430683918669\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier() \n",
    "tree_param_grid = {\"max_depth\" : np.arange(1,10,1)}\n",
    "\n",
    "gsTree = GridSearchCV(tree,tree_param_grid, cv=10, scoring=\"accuracy\", verbose = 1)\n",
    "\n",
    "gsTree.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "tree_best = gsTree.best_estimator_\n",
    "\n",
    "# Best score\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Tree\", tree_best.score(X_train,y_train), tree_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n",
      "best Tree score on the train set : \n",
      " 0.9942236598890942 \n",
      " best Tree score on the test set : \n",
      " 0.9815157116451017\n"
     ]
    }
   ],
   "source": [
    "tree = RandomForestClassifier() \n",
    "tree_param_grid = {\"max_depth\" : np.arange(1,20,1)}\n",
    "\n",
    "gsTree = GridSearchCV(tree,tree_param_grid, cv=10, scoring=\"accuracy\", verbose = 1)\n",
    "\n",
    "gsTree.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "tree_best = gsTree.best_estimator_\n",
    "\n",
    "# Best score\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Tree\", tree_best.score(X_train,y_train), tree_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le meilleur résultat obtenu est sur Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "best Knn score on the train set : \n",
      " 0.9768946395563771 \n",
      " best Knn score on the test set : \n",
      " 0.9759704251386322\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_param_grid = {\"n_neighbors\": np.arange(1,10,1)}\n",
    "\n",
    "gsknn = GridSearchCV(knn,knn_param_grid, cv=10, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "gsknn.fit(X_train, y_train)\n",
    "\n",
    "gsknn_best = gsknn.best_estimator_\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Knn\", gsknn_best.score(X_train,y_train), gsknn_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "best Logistic regression score on the train set : \n",
      " 0.9755083179297597 \n",
      " best Logistic regression score on the test set : \n",
      " 0.977818853974122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Log = LogisticRegression()\n",
    "log_param_grid = {\"class_weight\": [None, \"balanced\"],\n",
    "                 \"C\": [0.5, 0.6,0.7,0.8,0.9,1.0]}\n",
    "gsLog = GridSearchCV(Log, log_param_grid, cv =10, scoring ='accuracy', n_jobs=-1, verbose=1)\n",
    "gsLog.fit(X_train, y_train)\n",
    "gsLog_best = gsLog.best_estimator_\n",
    "\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Logistic regression\", gsLog_best.score(X_train,y_train), gsLog_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no grid search needed on naive bayes\n",
    "Naive_Bayes = GaussianNB()\n",
    "gsNaive_Bayes_best = Naive_Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "votingC = VotingClassifier(estimators=[(\"tree\", tree_best),(\"knn\",gsknn_best),(\"LogisticRegression\",gsLog_best),(\"Naive Bayes\",gsNaive_Bayes_best)], \n",
    "                           voting='soft')\n",
    "\n",
    "votingC = votingC.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Voting Classifier score on the train set : \n",
      " 0.98590573012939 \n",
      " best Voting Classifier score on the test set : \n",
      " 0.977818853974122\n"
     ]
    }
   ],
   "source": [
    "print(\" {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Voting Classifier\", votingC.score(X_train,y_train), votingC.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score is : 0.9768956889915319 \n",
      " the standard deviation of the score is : 0.007658055177100429 \n",
      " the list of score : [0.96997691 0.97690531 0.96073903 0.97690531 0.98383372 0.98845266\n",
      " 0.98152425 0.97228637 0.9837963  0.97453704]\n"
     ]
    }
   ],
   "source": [
    "Xvalscore = cross_val_score(votingC, X_train, y_train, scoring = \"accuracy\", cv = 10, n_jobs=4)\n",
    "print(\"the average score is : {0} \\n the standard deviation of the score is : {1} \\n the list of score : {2}\".format(Xvalscore.mean(), Xvalscore.std(), Xvalscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_line', 'Nb_tokens', '%texte_lu', '%texte_lu_fin_ligne',\n",
       "       'Verb_count', 'Propn_count', 'Noun_count', 'Num_count',\n",
       "       'Pourcentage_verb_sentence', 'Pourcentage_propn_sentence',\n",
       "       'Pourcentage_noun_sentence', 'Pourcentage_num_sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_columns = dataset.drop(features_list, axis = 1)\n",
    "list_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = list_columns.columns\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 0.013 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEbCAYAAACYzoDSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8tUlEQVR4nO2deZhkRZW+349mRxaxW0Gg2QRkERUbWWfkx6KALIogi6gsgg4woKgjCAqiouK4gw4gIqCsgiyKg+gIoih0NzsoqyCgsi9tI0vD9/sjIuns6qyq7O6KuFWZ532efKpu5PLFjcq6556IE+fINkEQBEHQFPM13YEgCIKgvwlDFARBEDRKGKIgCIKgUcIQBUEQBI0ShigIgiBolDBEQRAEQaOEIQqCIAgaZVhDJGmqpAMlvbJGh4IgCIL+ohuPaFfgtcBkSWdLeockFe5XEARB0Ceo28wKkuYDtgO+B7wInAp8y/bj5boXBPOGpE8Dq9j+UNN96RdizIM5pStDJGldYG9gW+Ay4MfApsD7bb+pZAeD5pB0L/Aa0o1Hi9Vt/20eP/NDtn81b70be0g6Gnid7T2b7stYRZKBR4DX2p6R2xYAHgQm2FZuuwLYEHgBMHAncB7wDdvP5dccTfw9RgVdrREB3wAmA+vaPtj2Nba/BtxTuoNB42xv+xVtj7k2QiOBpPmb1J9bxmq/RylPANu0HW+T2wZykO3FgWWBjwO7AZfG0sLoo5s1ol1sb2H7zLY7iZUBbO9UtHfBqETSkpJOkfR3SQ9K+oKkcfm5VSX9n6THJD0q6ceSlsrPnQFMBC6R9E9J/yVpM0kPDPj8eyVtmX8/WtJPJP1I0tPAXkPpd+jr0ZJ+lH9fSZIl7S3pfklPSPqIpPUl3STpSUnHt713L0m/l3S8pKck/VnSFm3Pv1bSxZIel3SXpP0G6Lb3+yPAp4Fd87nfmF+3t6Q/SZom6R5JH277jM0kPSDp45Iezue7d9vzi0j6mqT7cv9+J2mR/NyGkq7O53SjpM0GnNc9WfMvkt43yNj9UNIXBvan7fhTefynSbq9NTaDjPkHJf01fyeOGHAOp+W/xZ/yd2KW70MHzgA+0Hb8AeD0wV5se7rtK4AdgI2Adw7z+UFlujFEP+myLegffgjMAF4HvBl4O9BaDxDwJVKAy5rACsDRALbfD/yVmV7WcV3q7Uj6zi1FmhYeSr8bNgBWIwXifBM4AtgSWBt4r6S3DXjt3cB44CjgAklL5+fOBh7I57ozcKykzQfp9ynAscA5+dzfmF/zMGntdQnS9Pc3JK3X9hnLAEsCywH7AidoZgTrfwNvATYGlgb+C3hJ0nLAz4Ev5PZPAOdLmiBpMeDbwDbZW9gYuGEOxg4ASWsABwHr5895B3DvEG/ZFFgD2AL4rKQ1c/tRwErAKsBWQDfTZBcC/y5pqTwW/wZcNNybbP8VmJJfH4wiBjVEkl4v6T3AkpJ2anvsBSxcrYdB01yY76qflHShpNeQ1go/mu80HyZN3e4GYPsu25fbfs72I8DXgbcN/vFd8QfbF9p+iXTBHlS/Sz5v+1nbvwSmA2fZftj2g8BVJOPW4mHgm7ZfsH0OcDvwTkkrAJsAn8qfdQPwfWa9U3+537b/1akjtn9u+24nrgR+yawXyheAY7L+pcA/gTWUgof2AQ6x/aDtF21fnWct9gQutX1p1r6cdAHeNn/mS8A6khax/Xfbt87B2LV4EVgIWEvSArbvtX33EK//nO1/2b4RuBFoGeL3AsfafsL2AyQjORzPApeQbiR2BS7Obd3wN5JxDkYRQ81br0G6U1sK2L6tfRqwX6c3BD3Ju9oDCyS9FVgA+LtmTrXPB9yfn38N8C3SxXTx/Fyn+fs54f6231ccSr9LHmr7/V8djl/RdvygZ43ouY/kAb0WeNz2tAHPTRqk3x2RtA3JK1iddB6LAje3veSx1qJ85pncv/GkG8JOF/8VgV0ktf/fLgD8xvZ0SbuSvKRTJP0e+LjtPw/X13Zs3yXpoyRvd21JlwGHDrGG+I8O5wBpHNvHqdu/4+kkz1vAp7p8DyTP8uo5eH1QgUENke2LgIskbWT7DxX7FIxu7geeA8YPuEC2OJYUpfQG249LehdwfNvzA8M0p5MuvgDktZ4JA17T/p7h9Eea5SSpzRhNJN2B/w1YWtLibcZoIil6q8XAc53lWNJCwPkkL+oi2y9IupB0cR2OR0lewKokD6Od+4EzbHe8YbR9GXBZXk/6AnAynaerZvnbkKYJ2z/nTOBMSUsAJwJfAd7fRd/b+TuwPHBbPl6hy/ddRQpCMPA70jgMSfZi35L7GYwihpqa+6/86x6Svj3wUal/wSjD9t9J00dfk7SEpPmUAhRa02+Lk6aPnsprFZ8c8BEPkdYDWtwBLCzpnUphuEeSpnzmVn+keTVwsKQFJO1CWve61Pb9pDvrL0laWGmLw77Aj4b4rIeAlfK0GsCCpHN9BJiRvaO3d9OpPE35A+DrSkET4yRtlI3bj4DtlTafj8v920zS8pJeI2nHvFb0HOlv9dIgMjcA20paWtIywEdbT0haQ9LmWe9Zkic52OcMxbnA4ZJemb8vB3V5/ibN1OwwwGOdDUmL5u/HRcC1wKVz0c+gIEMFK/wp/5wCTO3wCPqXD5AuoreRpt1+Qro7BfgcsB7wFGnB/IIB7/0ScGRec/qE7aeAA0jrKw+S7sKHi5oaSn+kuYYU2PAo8EVgZ9uP5ed2Jy20/w34KXDUMPujzss/H5N0XfakDiZdjJ8A9iB5W93yCdI03mTgcdKd/nzZSO5IitJ7hOQhfZL0/z4fcGju8+Ok9bv/GOTzzyB5W/eSjP85bc8tBHyZNC7/IBnsw+eg7y2OIf29/wL8ivS3fK6bN9q+dZj1reMlTSPdAHyT5H1unY14MIoYckNrnib5iu1P1OtSEIwOcmDOh2xv2nRf+gVJ/wHsZruUhxuMQoYM37b9IikyKAiCYMSRtKykTfIU6xqkjac/bbpfQV262e19g6SLSdMK01uNtgdOuQRBEMwpC5ICHVYGniTtzfpukx0K6jNsrjlJp3Zotu19ynQpCIIg6Ce6zr4dBEEQBCUYdmoue0SzWaumPKLx48d7pZVWakI6CIIgmEumTp36qO2BewSB7taIftb2+8LAu0mhn42w0korMWXKlKbkgyAIgrlA0n2DPTesIbJ9/oAPO4u0kzkIgiAI5plusm8PZDXS5rUgCIIgmGe6WSOaRlojUv75D+YsyWAQBEEQDEo3U3OL1+hIaTbbbDMArrjiikb7EQRBEMxKV+WLJe1EKmxl4CrbF5bsVBAEQdA/DLtGJOm7pDLHNwO3AB+RdELpjgVBEAT9QTce0ebAmq1U65JOA+amomMQBEEQzEY3UXN3kQp+tVghtwVBEATBPNONR7Q48CdJ1+bj9YEpOREqtnco1bkgCIKg9+nGEH22eC+CYkS0YBAEo51uwrevBMh16edva3+8YL+CIAiCPqGbDa37k8r5PkuqSd/a2LpK2a4FQRAE/UA3U3OfBNax/WjpzgS9Q0wJBkHQLd1Ezd0NPDM3Hy5pa0m3S7pL0mEdnv+IpJsl3SDpd5LWmhudIAiCYOzSjUd0OHC1pGuA51qNtg8e6k2SxgEnAFsBDwCTJV1s+7a2l51p+3/y63cAvg5sPWenEARBEIxlujFEJwL/R8qs8NIcfPZbgbts3wMg6WxgR+BlQ2T76bbXL0aHAnxBEARBb9ONIVrA9qFz8dnLAfe3HT8AbDDwRZIOBA4FFiRlcZiNHDCxP8DEiRM7vSQIgiAYo3SzRvQLSftLWlbS0q3HSHXA9gm2VyWVljhykNecZHuS7UkTJnSsNBsEQRCMUbrxiHbPPw9va+smfPtBUjqgFsvntsE4G/heF/0JgiAIeohuNrSuPJefPRlYTdLKJAO0G7BH+wskrWb7znz4TuBOgiAIgr5iUEMkaXPb/5drEc2G7QuG+mDbMyQdBFwGjAN+YPtWSccAU2xfDBwkaUvgBeAJ4INzeyJBEATB2GQoj+htpGi57Ts8Z2BIQwRg+1Lg0gFtn237/ZDuuhkEQRD0KoMaIttH5Z971+tOEARB0G90EzUXBEEQBMUIQxQEQRA0ShiiIAiCoFG62UeEpI2BlZi1HtHphfoUBEEQ9BHd1CM6A1gVuAF4MTcbCEMUBEEQzDPdeESTgLVsR0LSIAiCYMTpZo3oFmCZ0h0JgiAI+pNuPKLxwG2SrmXWekQ7FOtVEARB0Dd0Y4iOLt2JIAiCoH/pJunplTU6EgRBEPQnQyU9/Z3tTSVNY9bKqQJse4nivQuCIAh6nqFyzW2afy5erzvzzkqH/bxj+z/ueWzI5wHu/fI7i/QpCIIgGJyuNrQGo5uhjOtwBjiMbxAETROGKJgnwgMNgmBeKZprTtLWkm6XdJekwzo8f6ik2yTdJOnXklYs2Z8gCIJg9NGVIZK0Yq6kiqRFJA27biRpHHACsA2wFrC7pLUGvOx6YJLtdYGfAMfNSeeDIAiCsc+whkjSfiQjcWJuWh64sIvPfitwl+17bD8PnA3s2P4C27+x/Uw+/GP+7CAIgqCP6MYjOhDYBHgawPadwKu7eN9ywP1txw/ktsHYF/hFF58bBEEQ9BDdBCs8Z/t5SQBImp9Z9xXNM5L2JCVXfdsgz+8P7A8wceLEkZQOgiAIGqYbj+hKSZ8GFpG0FXAecEkX73sQWKHtePncNgt57ekIYAfbzw18HsD2SbYn2Z40YcKELqSDIAiCsUI3hugw4BHgZuDDwKXAkV28bzKwmqSVJS0I7AZc3P4CSW8mrT3tYPvhOel4EARB0Bt0k2vuJeBk4GRJSwPLd1ObyPYMSQcBlwHjgB/YvlXSMcAU2xcDXwVeAZyXp/7+Glm9gyAI+otuKrReAeyQXzsVeFjS1bY/Ntx7bV9K8qDa2z7b9vuWc9rhIAiCoLfoZmpuSdtPAzsBp9veANiibLeCIAiCfqEbQzS/pGWB9wI/K9yfIAiCoM/oxhAdQ1rnucv2ZEmrAHeW7VYQBEHQL3QTrHAeKWS7dXwP8J6SnQqCIAj6h26CFRYmZT1YG1i41W57n4L9CoIgCPqEbqbmzgCWAd4BXEnamDqtZKeCIAiC/qEbQ/Q6258Bpts+DXgnsEHZbgVBEAT9QjeG6IX880lJ6wBL0l3S0yAIgiAYlm6Snp4k6ZXAZ0gpel4BfHbotwRBEPQum222GQBXXHFFo/3oFbqJmvt+/vVKYJWy3QmCIAj6jW4K471G0imSfpGP15K0b/muBUEQBP1AN2tEPyRtaH1tPr4D+Gih/gRBEAR9RjeGaLztc4GXIGXVBl4s2qsgCIKgb+jGEE2X9CpyVVZJGwJPFe1VEARB0Dd0EzV3KClablVJvwcmADsX7VUw5llmjy833YUgCMYIQxoiSeOAt+XHGoCA222/MNT7gtFDGIQgCEY7Q07N2X4R2N32DNu32r5lToyQpK0l3S7pLkmHdXj+3yVdJ2mGpPCygiAI+pBupuZ+L+l44BxgeqvR9nVDvSl7UycAWwEPAJMlXWz7traX/RXYC/jEHPY7CIIg6BG6MURvyj+PaWszsPkw73srqYbRPQCSzgZ2BF42RLbvzc+91F13556YogpKE7vtg2Du6Cazwv+by89eDri/7fgBIllqEARBMIBu6hEdCxxn+8l8/Erg47aPLNy39j7sD+wPMHHixFqyQRD0MSsd9vNBn/vHPY8N+Zp7v/zOIn3qVbrZR7RNywgB2H4C2LaL9z0IrNB2vHxum2Nsn2R7ku1JEyZMmJuPCIIgCEYp3RiicZIWah1IWgRYaIjXt5gMrCZpZUkLAruR9iMFQRAEwct0Y4h+DPxa0r452enlwGnDvSmnAjqIlKfuT8C5tm+VdIykHQAkrS/pAWAX4ERJt87tiQRBEARjk26CFb4i6UZgy9z0eduXdfPhti8FLh3Q9tm23yeTpux6moimCoIgGJxuwrcheTQzbP9K0qKSFrc9rWTHgiAIgv6gm3pE+wE/AU7MTcsBFxbsUxAEQdBHdLNGdCCwCfA0gO07gVeX7FQQBEHQP3RjiJ6z/XzrQNL85JIQQRAEQTCvdLNGdKWkTwOLSNoKOAC4pGy3gmD0MtgmxuE2OUJsdAzmjV4NfOrGIzoMeAS4GfgwKQquWlaFIAiCoLfpJnz7JeDk/AgGYV7SgUDcKQdB0L8Maogk3cwQa0G21y3SoyAI5phenbIJ+oOhPKLt8s8D888z8s89iWCFIAj6mCgrM7IMaohs3wcgaSvbb2576lOSriOtHQVBEAQjTL8FxHQTrCBJm7QdbNzl+4IgCIJgWLoJ394X+IGkJfPxk8A+xXoUBEFHIiAm6FW6iZqbCryxZYhsP1W8Vz1GzCcHQRAMTrdJT8MABUEwqohIwd6ha0MUBMHQhOcblKZXv2NFgw4kbS3pdkl3SZotyk7SQpLOyc9fI2mlkv0J+oPNNtvs5bvloDwx3v1Byb9zVx5RjpRbqf31tk8f5j3jgBOArYAHgMmSLrZ9W9vL9gWesP06SbsBXwF2naMzCIKgZ++UI0CjPxjWEEk6A1gVuAF4MTcbGNIQAW8F7rJ9T/6cs4EdgXZDtCNwdP79J8DxkmQ7NswGQzIvF6i4OAVBZ5oy/N14RJOAtebCOCwH3N92/ACwwWCvsT1D0lPAq4BH51ArCIKCjEbD36teYD+i4eyLpPOAg23/fY4+WNoZ2Nr2h/Lx+4ENbB/U9ppb8mseyMd359c8OuCz9gf2B5g4ceJb7rvvvjnpShAEBYnotaAbJE21PanTc914ROOB2yRdCzzXarS9wzDvexBYoe14+dzW6TUP5IJ7SwKPDfwg2ycBJwFMmjQppu2CYBQRBiiYV7oxREfP5WdPBlaTtDLJ4OwG7DHgNRcDHwT+AOwM/F+sDwVBEPQX3WRWuHJuPjiv+RwEXAaMA35g+1ZJxwBTbF8MnAKcIeku4HGSsQqCIAj6iG6i5jYEvgOsCSxIMirTbS8x3HttX0qq6Nre9tm2358FdpnDPgdBEAQ9RDfBClNInsp5pAi6DwCr2z68fPc69ucRYG6jFcbTXEReP2rHOYd2r+o2qT1Wz3lF2xM6PdGVIbI9SdJNraqskq4fUKNoTNA6l9Dubd0mtfvxnJvUjnPuDe1ughWekbQgcIOk44C/E/WIgiAIghGiG4Py/vy6g4DppHDr95TsVBAEQdA/dBM1d5+kRYBlbX+uQp9KclJo94Vuk9r9eM5Nasc594B2N2tE2wP/DSxoe2VJbwKO6WJDaxAEQRAMSzdTc0eTEpg+CWD7BmDlYj0KgiAI+opuDNELHaqzRvaDIAiCYEToxhDdKmkPYJyk1SR9B7i6cL+CIOiCnEJr2LYgGM10Y4j+E1iblPD0LOBp4KMF+zTiSNpU0t759wlN/KNKeqWkdSvqfbbTo5L2ipK2zL8vImnxCpqHdNNWUH+TbtoKcH6Htp9U0EXSbFlROrX1Gk18v7PWopI+I+nkfLyapO1qaJdmWENk+xnbR9he3/ak/PuzNTo3Ekg6CvgU0MoEsQDwo0raV0haQtLSwHXAyZK+XkObFGrferwIbEOqslsUSfuRLoQn5qblgQtL65KS5w5krwq6Lb7TZduIIOn1kt4DLClpp7bHXsDCpXQH0Cm7SpWMK5JWl/TrXEoGSetKOrKCblPfb4BTSQ7BRvn4QeALpUVrjPWg4duSLh7qjWMoau7dwJtJhgDbf6t1BwMsaftpSR8CTrd9lKSbagjb/lr7saT/JiWgLc2BpOCWa3I/7pT06lJiknYnZXVfecB3dnFSIt2iSNoI2BiYIOnQtqeWIOVlLMUawHbAUsD2be3TgP0K6iJpG2BbYDlJ3257aglgRkntNk4GPkk2CLZvknQm5S/MVb/fA1jV9q75O4/tZySpgm7xsR5qH9FGpOqpZ5EGvcYJl+B525ZkAEmLVdSeX9KywHuBIyrqdmJR0t1baZ6z/Xzr/yPXmSoZ3HI1KdvHeKDd+E4Dahj9BYFXkP6X2m9wniaVNimC7YuAiyRtZPsPpXQG4W/AFGAHYGpb+zTgY5X6sKjtawdch2sYwdrf73aez3s6W9eyVWmrEVeQ4mM9lCFaBtgKaN1x/hw4y/atI9mBCpwr6URgqexW70Oy8DU4huSF/M72ZEmrAHfWEJZ0MzP/QcYBE3J/SnOlpE8Di0jaCjgAuKSUmO37SElwNxrutYX0rySd8w9zX2pzVx7vlWj7f7a9TylB2zcCN0o60/YLpXSG4dF8IW5dlHcm3ZCUpur3ewBHAf8LrCDpx8Am1Jl+Lj7Ww25ozcILkQzSV4HP2T5+JDtRmvyFeTvJq7vM9uUNd6k4klZsO5wBPGS7+B2jpPmAfWkbb+D7pQseStoJ+Arw6qwrwN2UKxkh/dWBTzC7Qdi8sO7VwFUkz+TFNt1OQQwjrb0JaZ/hiqRzbo35KhW0VyHt8t8YeAL4C7Cn7XsL6zby/W7TfxWwYdb+o+3iWbhrjPWQhigboHeSjNBKpIqqP7A9sOR30AFJE0jz9StR6W41B0YMiu3i6yZNoFRccXvbf2pI/0bgf5jdIEwd9E0jo3uD7TeV1BhC+8+kqbiB5/xYxT4sBsxne1pFvWdtv5iPxwEL2X6mgva7SVWsn8rHSwGb2b6wtHbWKzbWgxoiSacD65AK251t+5aRFq9Bk3fKTdytSvoLyYXutKZX/G61qbtkSb+3XSNcejD9qbbf0oDuF4CrcxHK2trX2N6gtm7WPhY4zvaT+fiVwMdtF42ck/RHYEvb/8zHrwB+aXvjkrpZa7abDlUoyVNjrIcyRC+RQn9h1sW4qlMe80qTd8pN3q0Oh6S1S6z3NXWXLOlbpHXNC2lbwLV9QUndNv2jgYeBnw7QL+qBSpoGLJY1X6DujdaXSeuPFzDrOV9XQXu2C7Ck62yvV1i3kzGo8n+utppwbW03235DYd3iYz1osILtXqk59FBT0zXAzyRt28TdahecAZT4p33K9i8KfO5wLAE8Q5q7b2HSRbIGrX1MnxygX9QTtF1rK0InWt5Qe6E0A0XXxTLjJC1k+zlIG0uBhSroTpe0XsvYSnoL8K8KugBTlPYhnpCPD2TWqMVSFB/rroIVxjJN3im33a0+nx+jxpss5dI3eZfcj0j6907ttn9buy81kfQp0v6pU3PT3sDFto8rrLs+cDYphF2ka8uupdcCs/ZiwGeALXPT5cAXbE8f/F0jolt8rPvBEJ3aodklAwbGAqWmMST9pkOzK0SPnUqH/Ry1/s6SPtCp3fbphXXbQ4cXJm22nFp6vLN2x5RRtmtsE2htrN0iH15uu8aGbSQtQNpQDHB7gyHs1Sg91j1viJok73p+H7Cy7c9LWoFUYPDahrtWZT69JkrpblosTMqo8TfbB1fSb0/nszDpn/Y628U2tQ7SjxWAb9ouXkVZ0sfbDhcmZXr4U6/f5EnamNkjYYvecGTdRrYI1KBnDZGk/7J9XL5AdLpTLn6BkvQ94CVgc9tr5miTX9pev7T2cEj6o+0NC3zuoR2anyLdpd8w0npD9GM+0kbi4tFMg+gvRYo23bqyroBbba9VUzdrL0Tap7dZBa1GomElnQGsCtzAzGAcV7qeNLVFoPhYD1sqfAzTClCY0mAfNrC9nqTrAWw/IWnBGsJt3tgqto+RNBFYpuWNlTBCmUn50Zoy2o6Uaucjks4rPYffxmqkf5ymmE6FApIDbrTmA95EzqvYALXSSAEcRzPRsJOAtdzMHfwM299rQLf4WPesIbJ9Sf55WoPdeCFveGulxphA8pBq8N2stTkptc80UsmA0t7Y8sB6bfssjiKlh/p30p1cEUOUA0Na+6cM/IOUdb0Kea2mPaXSmsC5FaTbb7RmkNJw/b6CbpNppKC5aNhbSAEKNdIJDeQSSQdQeYsAFca6Zw3RgAvDbLhO9vBvk740r5b0RVISzOKp6jNNeWOvZtZEjC8Ar7H9L0nFEjQ2HMYM8N9tv88A7rP9QGlR26flv+vquen20ppttNfCqZZGKjNF0jnUj4YdD9wm6doBujWuJ41sEaDCWPesIWLWC0NT/ITkBWxBulN/F/BQJe2mvLEfA9dIuigfbw+cmUNPbyspLGkHkucFcIXtn5XUa8f2lZJew0yPs1Zy282A04B7Sd+xFSR9sEb4tu37JL0R+Lfc9FvqZDyH5vaNHV348wfFdlOVd4uPdc8GK3SLpPNLRRhJ+jnwrlZ4p1JJiJ+5QioYSe8DdiVtWj2N5I19xnbx6SJJk0iZgQF+b7v4Ol3ev7Q+yRBCyo842fanS2tn/feSkgJfQTII/wZ80nbRaqmSpgJ72L49H69Omp6r8R07hJRLsXVBejdwku1iBQFHA0oJhVez/StJiwLjXCHXXdY6FJhoe39JqwFr1LzhKobtvn4A1xf87P1IU3PjSCGXNwFvr3huryftvj4IWLOw1hL559KdHhXO9SZSQsbW8TjgpopjfSPw6rbjCcCNNc67m7aCY75Y2/FiFbVXB34N3JKP1wWOrKC7HzAZuDsfrwb8utI5nwP8V9s5Lwrc0Atj3StpfOaFYi6h7ZOBX5HmVi8BPmL7l6X02pF0hu0/2z7B9vG2/5RDT0txZv45lbSA3nq0jmuwVNvvS1bSbDGf7Yfbjh+DKv9fUyR9X9Jm+XEy9cZbtIUR599rFdA8mVSW/AVIVUOB3SroHkjy9p/OundSLzpzVaeo09Y5P0Od8S4+1r28RtQYA/bSCJhI2newoaQNbX+9QjfWHtCncUCx6Rrb2+WfTc1jfwm4Pmd2EGmt6LCK+v8r6TJSRWNI06I1cu79B+ni2NrHchUpYrIGp5LWA3+aj98FnFJJOyq09kmF1n6hxB3FwAiuCwZpH3EkHQ60Kkg+3Wom5borVplW0pBZGlw415ztsyRdwcxggU/Z/kdJzQH6n8wb/zbNTSfZ/ulQ7xkh5ge+1bq5yTccNZJ/Yvvrecxb57y37etraNOfFVqPZvYKrXtX0B0dFVrHOvkuYqLzgu6A595eerpMqWYJzntraiDpS7YPr6jXKcdcC7t8rrmmi4atDPzd9rP5eBFS2Pq9hXWbrI+zISmLw7R8vARpLfKaCtqdqoa+z4XLtatDhdY8BV8FjZ4KrSM71jUW2Zp8kMKHbwf+ko/fRMocW0N7HeB64L78mAqsXUl73wHH44CjRsHfY6tCn3tDh7brK57XFGDBtuMFSVF7pXU7nfdsbYW0ryffzObj+Uj59Wpor5x/LgYs3t5WWPeQbtoKac8WFNGpbSyOdT8EKxxNykj8JIBTvrNa6xgnAYfaXtH2isDHKTg9NoAtJF0qaVlJ6wB/pMLUYBd8pdDndvou15x6nt/2862D/HuNDcTT26dFVbc+jpyvSgC2X6LemJ+fNad7Zuh00VD5zAc7tO1VUlDSwpKWBsZLeqWkpfNjJWC5ktqZ4mPdD2tEL9h+asBCW635yMVsvzxlZfuKvLGzOLb3kLQrcDMp79kerpT6ZRhKRfk0VTSsxSOSdrB9MYCkHYHi0ybAR4HzJM1SH6eCLsA9kg4GWvnPDgDuKSko6fWkQJwl85pciyVIGcBL6e4O7AGsLOnitqcWB0qn2Pkw6e/8WtJ3uvU/9DRwfCnRmmPdD4boVkl7kKoMrkaKLrq6kvY9kj5DqoYKsCeF/1Fb5HM9hHQ3sybwfqVieM/U0B+CUjcB/0kqGnZO1ricZIxq8RHgx5JaF4YHgPeXFrU9OV8wOtbHkbSV7csLyX+ElMbqSNKY/xrYv5BWizVIqYWWIk27t5hG2uNTiqtJC/Tjga8N0C2aTcL2t4BvSfpP190sXG2sez5YIe9GPoKZ6SkuI1U1fLaC9iuBz5GiikwKrT3a9pMVtP8MHOS0+1ukHdn72F57mLeW7lcjdZAkfcf2f1bQ6RiYktPuVE/A29R4Z+3DbX+p0GdvZPsPJT57NKMGaiHVGOueN0RNImkX2+cN11ZIewnbTw9oW932HaW1h0LSBbZ3Gv6VI67baCHABg3w9S5QEr5L7WLnrJQ7cT9mvygXLcqnhuogZe1GaiHVGOuen5qTdDmwS8sLyV7K2bbfUUH+cGCg0enUVoJFJH0DWM721pLWAjYCihuioe7amjBCo4RaGQcG0uSdZslzvog0w/ArZs3uUJqm6iBBc7WQio91zxsiYHz7VJhTOYSiKTmU6rtvCywn6dttTy1Bnd3fAD8k7Xw/Ih/fQVo/KbrzfbC7NqB4KeVRTj9OPZQ850VtV6s31UZTdZCguVpIxce6HwzRS5Im2v4rvJw5t/RF4W+kfSU7MGvk1jTgY4W1W4y3fW7OtIDtGZJq3Dk2WcFyKJrySJrWv7chXSh7zj+TtK3tSwtqdKKpOkjQXC2k4mPdD4boCOB3kq5kZnr+opE9tm8EbpR0ZnsE00BUsAQFaX/Jq5iZlmND4KlCWu00WcGytbvfnj0t/7ea6E8bxULnR/FUaMkp6EOAT0t6npS+qtZaTVN1kKC5WkjFx7ovghUkjSelxYBKaTG6oeRCct7k+B1SdodbSGUJdslGshg51c+bgKp3bZLWB35A2tch0gbmfWxX2UskaSHgPcxuEIqWzm5qATtrr0wKm1+JWc+5RrXSvkQN1UIqTT94RJCSQD5OOt+1JOEKFSy7oORdwK3A20h7AURKc1Qjk8bRFTQ6cQpwgO2rACRtSlojW7eS/kUkj3MqdTIit2hyKvRC0rhfQp3qvy+TtyS8j5Rq5vOSVgCWtX1tYd3VSRt4X2N7HUnrAjvY/kJJ3ay9H2k2Z2nSzcdywP+QKkCX1C0+1j3vEUn6Cmmn+a3M/GfxaLhrKxzeOttnNx3CXJJO3mXN85V0i+11amgN0D0PONh29alQSdfY3qC2btb+Hun/eXPba+Zo2F/aXn+Yt86r7pXAJ4ETW9+3Wn97STeQ0pVd06Z9s+03FNYtPtb94BG9i1ROt+ZdareM+GKupGVId0qLSHpzm8YSpIqORZD0O9ubSprGrJ5e0bl7zcyzdqWkE0n1gEy6+biihOYgXC3pDbZvrqgJzS1gQ9rtfxTwywHaRUt+ZDawvZ6k67PmE5Jq5PZrqg4SNFcLqfhY94MhugdYgLrTJS+T/2CvJ31hbndbYkygREjkO0hJGJcnpSJR1p5G2sNUig8A2K6dWPVrA46Pavu9pru/KbCXpL+QvmstA1x6avDowp8/FG8gpTHanLbZhnxcmheUai+1gnEmUGd6sKk6SNBcLaTiY90PU3PnA28k5cFqv2ursZj7TtIc7t2kC9PKwIdtF6/cKek9ts/P0XJHA4sA33ShYm2Sptp+i6Rf2y46Z91Bez5gZ9vn1tQd0IcVO7W7cH2cJpF0F2l96vlhXzzy2u8jeb3rAacBOwNHls5aos61efZ04bpTWXu2WkjA90uvD9YY634wRJ3StuMKeb+U8r1tZ/uufLwq8HPbry+ouYzbKpNKOpeZqeuvLTWfnN3280ilq78x8HkXLo8uaYrtSSU1uujDeszMK/j7GlNUA6ZCFyR5/9MrpZy5ENjf9sOltQbRfz1poV6kujzVNpoqZdGfr6mINaWyEMvbLppwtU2v6Fj3/NSc7dM0RIXWwkxrGaHMPaQpspL8j6TrgOOcErs+SbqDeYmUNr4Uu5HW4+anmbpHv5L0CVL2iOmtRtulU/QDIOmzwC7M3E9yqqTzSkdTtU+F5uimHZm5VaE0SwF/ljSZyutT+abuL7ZPkLQZsJWkv7twQmFJh5CiMacBJ+ebj8NcuMpz1r6CtEl+flJ05sOSrrZddJN8jbHuB49oe+C/SdUzV5b0JuCYkv8smlm7YytgReBc0l3rLsBfbR9QSjvrb0/ahHY6qYDVHqRAhbNsP1JYe5uhph5VKAt1XpsZiG2vMtJag+jfDrzRs5YKv8H2GkO/s0hfiu1PG6Dztk7ttq+soH0DKXR9JeDnwMWk6sfbFta90fYbJb2DVAbjSOCMGtGZrb+rpA8BK9g+StJNpdcha4x1z3tEzKzQegWkCq15nrck7bU7HiLt5wF4hILFu1rYvkTSpaTFzJ8CX6y1b6qL9a9DSPPMI61bq+ruYPyN9LdtlRdZCHiwtKhmLVg2H+mCUbzECdQxOEPwklPaqp2A421/pxXVVZhWuNy2wOm2b9WAELqCzC9pWeC9zMwhWYPiY90PhqhThdai0TW29y75+UMhaQdSPrsZwLGkonyfkXQAcITtu5vqW6bIP63SLvNDSVOw+ysVBlzD9s9K6HXgKVIRxstJ3u9WwLXKSW8LBse03/TMIOWW27GQ1iw0uT5FiuTanRSt2RqDBSroTpX0S1Lg0eGSFqfeZt5jSAEKv3MqiLgKcGcF3eJj3Q9Tc6eQIuYOI6VgORhYwPZHCmp+doinbfvzBbVvInmAiwCX2X5rbl8N+Lzt3Uppd9m/IptMlRJRTgU+4LTjfVHgattvGmmtQfQ7BsW0qBEc0yTt61O2D6ugtxZpauwPts9SSjf0XttfKaw7HymF1T22n1TK57hcK2hA0tq2by3ZhyH6VqQQYY2x7gdD1KlC6+dLbnCV9PEOzYuRQi9fZfsVBbWvIqUgWRR4l+3tSmnNDaXWL1pRc+2f35rPH2mtIfqwILB6PpylZHdBzeVJOQU3yU1XAYfYfqC09iD9qbI+1UU/SiYUHkq3yYq4TRVfnOex7oepuXfaPoK2OVVJu1AwM7DtlzdZZtf9EGBv4Gxm34A50rwb2B14gRSkMNoolYX6+Rwg0Np0tyoVNzHnaKLTSFNjAlbIgRml1+ZOBc4kBcIA7Jnbtiqs2+j6VBdUCVLpQJPlRprSnuex7gePqJGcaznO/1BSssDTgG/ZfqKk5mhgsGlJF8pCLekEUlqflue7FinlzCbAXravKKHboR9TgT1aWwSUkmOeZfsthXVvGDj92KmtkPapbYet9amTm9pX1E6D3kE/ekTzrNuzHpEarJIq6avATqQd2G+w/c+SeqOM6W2/LwxsB5TcaHgH8FVgWeByUjnj60jTUzXLfSzQvk/N9h2SaiyePyZpT5IxhuQNP1ZBt9GgnKAjTRd/nGt61iOS9EbSouIxQPtd+jTgNyW9E0kvkaaFZlAxAehoRKlOz2W2NyussyJpU+1upECNM4Gzbd9RUrdN/1RSPaAf5ab3kWrF7FNYd0XSGtFGpO/a1aRs3H8tqNlYME63NLVWJemPtmttKB6o/WnbxzagO89j3bOGqIWkBWosGgedUUoZP9n26ypqvplUJG9d2+MqaS4EHEhK8QMpaOC7JYNimqLJYJwB/Rg0obCkt7tQtgNJy5E2qrcXAyy+T08p2eh+zF6IsOjNznCMxFj3gyHahLSptfXFaXklTS1m9jSSbmamFziOVBn2GNvHF9adH9iG5BFtQdrAfJbti0rqZu1xwK0umEOwg+ao8EragnH2JWUQ+VqNNSI1lFBYM+ub3casFXFrpDW6mnSDM7VNG9vnF9bdDvg8s19Do1R4tyglHv0Ys//xqsyj9xuaNQv1DOAh28XW5JTS4e9OWg+8lhSZeJHt6UO+ceT7cRHwnyWnxAboNeqVNB2MowYSCmed20mednVPt1YQSgfdu0hr3je7kMHo2WCFNp4qfZcUvHxhgtmTui6hVJq9VPLRw0nrQR9vOCrxlaTMCtcya9LVInfKTW4RGCXBOE0kFG7pNFXf7GeStrV9aWXd+4FbShkh6A+P6MukKaILqF9Fsm9QSjpqOkfu9PxUqBpIANqUV9JkMI6aTyjcZH2zaSSv9znSPsEqwU+S1idNzV3JrOc8YqVd+sEj2iD/bK9VU6uKZN/gLpOONpkCpQSSFialP3kdcDNwSsmpyDbdxrwS2/PV0upAowmFSZmnL66gMxuuX/24xReBf5LGt0g59p73iILRRZMb/kqQc9y9QFpE3ga4z/YhFXT7dotADg452PZsBRgr6Q8arVdY9987tZeO2JN0i+11imr0uiGS9BpSFurX2t4mJ/DbyPYpDXetLxktuchGCkk3O1e9zZF71/aSoR2tSLrWOaFvZd1tgROpHK2XtS9pO1yYlNx4qu2iszuSjgN+VSocHvrDEP2ClHvrCKeCVvMD17tQyexgaHrQI5rlfHrt/EYrkr5BChoYWJG36NpvU9F6g/RlBeCbLpzctcbaVD+sEY23fa6kwwGcCjy9ONybgqBL3iipVYJdwCL5uOenyBrmTflnew7DGmu/TUXrdeIBYM3SIjXWpvrBEE1XqhnSysq8IamIWdAMVebTa1Erc0MwK7b/X0PSU5SqH7dH601uRfPZvqCUsKTvMHM9sFUXqXj0b421qX6YmluPlItrHeAW0k7/nZ0LWQUjiySRwolXsX2MpInAMravbbhrQQ/R1NrvgIzjA3HJdDuatfjiDOBe26XKqrTrFl+b6llDlGPf77f9j7wu9GFShdbbgM8W3GDZ10j6Hql08ua218y55n5pe/2Guxb0EP269qsGii926MOIr001uR+gNCcycxpoY1KtmhOAJ0h7L4IybGD7QHKBtLzBssjeg6CvGW/7XNJND3nvVvG1X0nLS/qppIfz43ylKrnFUSq+eCfpOvZd4I7Bps0KM+JrU728RjSuzevZFTgpJwc8X9INzXWr53kh7/NorclNIF8sgmAEaWrtt7GKuKTUTW/3gOKLQOnii8XXpnraEEmaP98pbQHs3/ZcL59303wb+CnwaklfBHYGPtNsl4Ie5OOkDAerSvo9ee23gu4E2+3rRD+U9NEKutBc8cUpbb/PIGW1H9G1qV6+IJ8FXCnpUeBfpJ3vSHodETVXDNs/ViqbvQUphPldtktWaA36ENtTc36/NUjfs1rrJY1VxCVF7H2fWYsvThni9SOC7dNKa/RssAK87K4vS1osn57bVgdeEUlPyyDpDNvvH64tCOYFSTeRMo2fY/vuirrVK+K2aTdSfLFGTbeeNkRBfTpkGhhHqmOyVoPdCnqMbBB2zY+XSBkWzi1pEPJ3+XTb7yulMRqpUdOtl6PmgopIOjynAllX0tP5MQ14mIayFQe9i+37bB9n+y3AHsC6wF8Ka74IrJhDqKsjaRNJl0u6Q9I9rUcF6ads/8L2w7Yfaz1GUiA8omBEkfQl24c33Y+g9xngFb1ImqYrXRTwdFLo8sXMmuNuxGrzDKHdSLXpGjXdejlYIWiG9jxcremMI21/rqH+BD2IpGtISU/PBXaxXcMzgJR1+27SbFLt+kBNVZsuXtMtPKJgRJF0JrAUsC/wKtIeiyttf6LJfgW9haQ12kOZOzz/wZLRXpKWIC3YV0t4OlqrTY/EWIchCkYcSbuSdn9PB/aokQ8rCNopVY5D0iTSzVXLG3oK2Mf21JHW6qD9mw7NLl2PaDhGYqxjai4YUSStBhwCnE+aS39/Lob3TLM9C/oMFfrcHwAH2G7tS9yUZJjWLaT3MsNlHC/tBQ4lPa8fEFFzwUhzCSmp7IeBt5FyY01utktBH1JqqufFlhECsP07UraB0UDxEvWDMM9jHR5RMNK81fbTkOYMgK8NSCMfBDUo5RFdKelEUmYFkyL2rsjlZpperyl1zsV1wxAFI80iuYzzcra3btWJAe5ouF9Bf1FqXfKN+edRA9rfTJ0KsUPR1IL/PI91BCsEI0q/1okJ6tJUYbwu+tXUOg15LfbNBT63+FjHGlEw0jRSJyboO34IXAa8Nh/fAXy0qc600dQ6DZTzAn9I4bEOQxSMNE3ViQn6i9F6w1NsnUbSaySdkmcdkLSWpH1bz9s+qJB08bEOQxSMNIcya52Y04GDm+1S0IOM1huekmsdP6QZL7D4WEewQjDS3EoK2365TgxxwxOMPANveGoVxhuOkpFr422fK+lwSJ6JpBpeYPGxDkMUjDR/yLusb201SLoOGPFd7kH/Yvu6hgrjDUfJLCKNeIE1xjoMUTAiSFoGWI4Uvv1mZt4ZLgEs2ljHgp5E0k4DmlaX9BSp9tXDBXWHjCAruE4DDXmBNcY6wreDEUHSB4G9SBl6J5OrOALTgB/a/mlzvQt6DUk/J+1Pa+Vf24xUHmFl4BjbZxTSbXR7Qtar6gXWGOvwiIIRIe+dOE3Se2yfn6cNjiZl4g6CkWZ+YE3bD8HLnsrppJIFvwWKGCKaW6dpzAukwliHIQpGBEnL2P6H7fNz06HAu/Pv1wLhEQUjyQqtC2Pm4dz2uKSSXkKT0Xr7MohnIqmYF0iFsQ5DFIwU/5ODEo6z/SzwJGn++iXg6SY7FvQkV0j6GXBePn5PbluM9N0rRZPRek15gcXHOtaIghFD0vakneWnAz8B9iAFKpxl+5Em+xb0FpJEuiBukpt+D5zvChe0JtZpsu5tttdqOxZwq+21SqX3adMpOtZhiIIRJZcGPwDYDvii7d823KUgGDE6rNNAmporvU6DpO8CE5nVM3kA+CTws+HqFY1mwhAFI4KkHYCPkWqzHAtcD3yGFNJ9hO27G+xe0GPktZnvkIovLkgqoT3d9hKFdRuJ1svajXiBNcY6DFEwIki6CXgrsAhwme235vbVgM/b3q3J/gW9haQpwG4k72AS8AFgdduHF9a9DPhAh3Wa3YHf2l6npH4T1BjrSL0SjBRPATuR7thenqKwfWcYoaAEtu8Cxtl+0fapwNYVZAeNIAOKrhVJ2lDSZEn/lPS8pBclVQkEKj3WETUXjBTvJt0VvkAKUgiCkjwjaUHgBknHAX+nzo11U9F6AMfTwTMprAkVxjqm5oIgGHNIWhF4iLRm8TFgSeCE0muRDUfrTbE9SdJNttfNbcWi5dp0i491GKIgCMYckg6x/a3h2noJSb8FtgS+D/yD5JnsZfuNQ75x3nWLj3WsEQVBMBb5YIe2vUqLNrlOA7yfdM0+CJgOrEBaly1N8bGONaIgCMYMknYnrUGuLOnitqcWBx6v0IWm1mkA3pW9kGeBz0HyTIAiXmDNsY6puSAIxgx5vWJl4EvAYW1PTQNuymWsS+o3sk6Tda7Ltb7a20pmVKg21uERBUEwZrB9H3AfaVNpE1SP1mvKC6w51mGIgiAYc+RUO18BXk3K+SbApTMrMOs6zceos05zNcngjQe+1tY+DbipsHaVsY6puSAIxhyS7gK2t/2nyrr9GK1XfKwjai4IgrHIQ7WNUKaRaD1InomkOyU9JelpSdMqRewVH+vwiIIgGHNI+hawDHAh8Fyr3fYFhfRa6zSbAle1PbU48JLtLUroDuhDU15g8bGONaIgCMYiSwDPAG9vazNQxBDR8DpNpikvsPhYh0cUBEEwBqjtBdYk1oiCIBhzSFpd0q8l3ZKP15V0ZAXdptZpYFbPZPv82K60aI2xDo8oCIIxh6QrSZVJT2xt6JR0S+l6QE2t0zRJjbEOjygIgrHIoravHdBWNKtCpql1msa8QCqMdRiiIAjGIo9KWpW0aI6knUnBBKWZIukcSbvnabqd8obPGpwMHE4uwGf7JlLeu9IUH+uImguCYCxyIHAS8HpJDwJ/AfasoFs7Wq+dRW1fm0oivUwNL7D4WIchCoJgzGH7HmDLXBl1PtvTKunuXUNnEBrxAmuMdUzNBUEw5pB0rKSlbE+3PU3SKyV9oYJuU+s0kDyTE5npmXwU+I/SojXGOqLmgiAYc3Qqf9CpTEIB3Uai9Qb0oaoXWGOswyMKgmAsMk7SQq0DSYsACw3x+pGiqWi9xrxAKox1GKIgCMYiPwZ+LWlfSfsClwOnVdBtKloPYBvbT7YObD8BbFtBt/hYx9RcEARjCqWwseWBtYEtc/Plti+roL0KKYJsY+AJcgSZ7XsraN8ErG/7uXy8CDDF9toFNauMdRiiIAjGHJJutv2GBvWrrtNkzU+R0vqcmpv2Bi62fVxh3eJjHVNzQRCMRa6TtH5t0Qaj9QScCXwBWDM/Pl/aCGWKj3V4REEQjDkk/Rl4HXAfMJ2Z5avXLazbSLRe1mnEC6wx1rGhNQiCscg7GtIdJ2mhAes0NaL1IHsmtidX0mtRfKzDEAVBMBZpaiqnFUHWvk5TI1oPYAPgfZKqeoFUGOuYmguCYMwh6WbSBVLAwsDKwO29EEE2hP6Kndpt31dYt/hYh0cUBMGYY+BaiaT1gAMKa1rSpVn7f0tqDdaFBjSrjHUYoiAIxjy2r5O0QQWpptZpAH5OB8+E5KFVo8RYhyEKgmDMIenQtsP5gPWAv1WQbmqdphEvMOsUH+swREEQjEUWb/t9BslbOL+CblPRerNR0QssPtYRrBAEwZhF0isAbP+zkt7ETu22/1pBu5Nn8irbVYxjybEOjygIgjGHpHWAM4Cl8/GjwAdt31JYusl1mka8wBpjHR5REARjDklXA0fY/k0+3gw41vbGlfuxHnCA7Q9V1KztBRYf68g1FwTBWGSx1oURwPYVwGK1O2H7OlIAQ3EkrSPpeuBW4FZJU7O3UpriYx1Tc0EQjEXukfQZ0pQRwJ7APaVFG4zWg1R+4tABnkmrJEVJio91eERBEIxF9gEmABeQ1knG57bSLN72WIi0TrNjBV1ozgssPtaxRhQEwZhB0sLAR0jZoG8GfmD7hQb6UXWdJmv+FLiOWT2Tt9h+dyG9amMdHlEQBGOJ04BJpAvjNsBXa4o3uE4D9b3AamMdHlEQBGOG9po8kuYHrq1RC6hNv3q0XlNeYM2xDo8oCIKxxMsXYNszGtBvYp2mKS+w2liHRxQEwZhB0oukHG+QNpUuAjzDzJxvSxTWr7pOkzUb8QJrjnWEbwdBMGawPa7hLuwDfI60TmPgKspH683imaSySOWpOdbhEQVBEAxDk9F6TXuBNQhDFARBMAySziF5JleR1mnutf3RRjvVQ4QhCoIgGIamo/V6nYiaC4IgGJ6mo/V6mvCIgiAIhqEf1mmaJAxREARB0CgxNRcEQRA0ShiiIAiCoFHCEAVBEASNEoYoCIIgaJQwREEQBEGj/H8D66h/9a95vAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin part 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
