{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\python39\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python39\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python39\\lib\\site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python39\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip \n",
    "pip.main([\"install\",\"matplotlib\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\python39\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\python39\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in c:\\python39\\lib\\site-packages (from xgboost) (1.23.1)\n",
      "Requirement already satisfied: scipy in c:\\python39\\lib\\site-packages (from xgboost) (1.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # to avoid deprecation warnings\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la dataset\n",
    "## Choix de 4 datasets, ne pas oublier de choisir la features_list adéquate\n",
    "\n",
    "#dataset = pd.read_csv(\"dataset_CV_labelise_features1_100.csv\", delimiter = \";\", encoding = \"utf-8\") ## 100CV + 4 features numériques\n",
    "\n",
    "#dataset = pd.read_csv(\"dataset_CV_labelise_features1_200.csv\", delimiter = \";\", encoding = \"utf-8\") ## 200CV + 4 features numériques\n",
    "\n",
    "#dataset = pd.read_csv(\"dataset_CV_labelise_features2_100.csv\", delimiter = \";\", encoding = \"utf-8\") ## 100CV + 12 features numériques\n",
    "\n",
    "dataset = pd.read_csv(\"dataset_CV_labelise_features2_200.csv\", delimiter = \";\", encoding = \"utf-8\") ## 200CV + 12 features numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5594, 19)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Sentences</th>\n",
       "      <th>Sentences_CV_clean</th>\n",
       "      <th>CV_Number</th>\n",
       "      <th>Sentence_line</th>\n",
       "      <th>Nb_tokens</th>\n",
       "      <th>%texte_lu</th>\n",
       "      <th>%texte_lu_fin_ligne</th>\n",
       "      <th>Is_alpha</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Tokenization</th>\n",
       "      <th>Verb_count</th>\n",
       "      <th>Propn_count</th>\n",
       "      <th>Noun_count</th>\n",
       "      <th>Num_count</th>\n",
       "      <th>Pourcentage_verb_sentence</th>\n",
       "      <th>Pourcentage_propn_sentence</th>\n",
       "      <th>Pourcentage_noun_sentence</th>\n",
       "      <th>Pourcentage_num_sentence</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5594</td>\n",
       "      <td>5592</td>\n",
       "      <td>5594</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594</td>\n",
       "      <td>5594</td>\n",
       "      <td>5592</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.00000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3805</td>\n",
       "      <td>3802</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1626</td>\n",
       "      <td>2748</td>\n",
       "      <td>3802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CV_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[False]</td>\n",
       "      <td>['NOUN']</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>638</td>\n",
       "      <td>334</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.673221</td>\n",
       "      <td>9.132285</td>\n",
       "      <td>50.470518</td>\n",
       "      <td>49.529483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297283</td>\n",
       "      <td>0.611012</td>\n",
       "      <td>2.83822</td>\n",
       "      <td>0.320164</td>\n",
       "      <td>0.020117</td>\n",
       "      <td>0.105039</td>\n",
       "      <td>0.314979</td>\n",
       "      <td>0.042982</td>\n",
       "      <td>0.037898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.268076</td>\n",
       "      <td>10.914849</td>\n",
       "      <td>30.190027</td>\n",
       "      <td>30.190025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.784780</td>\n",
       "      <td>1.129198</td>\n",
       "      <td>3.56600</td>\n",
       "      <td>0.693458</td>\n",
       "      <td>0.059959</td>\n",
       "      <td>0.227969</td>\n",
       "      <td>0.251108</td>\n",
       "      <td>0.131906</td>\n",
       "      <td>0.190966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.190000</td>\n",
       "      <td>23.552500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>49.530000</td>\n",
       "      <td>50.470000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>76.447500</td>\n",
       "      <td>75.810000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.760000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>39.00000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CV_Sentences Sentences_CV_clean CV_Number  Sentence_line    Nb_tokens  \\\n",
       "count          5594               5592      5594    5594.000000  5594.000000   \n",
       "unique         3805               3802       200            NaN          NaN   \n",
       "top                                        CV_10            NaN          NaN   \n",
       "freq            198                198        66            NaN          NaN   \n",
       "mean            NaN                NaN       NaN      15.673221     9.132285   \n",
       "std             NaN                NaN       NaN      11.268076    10.914849   \n",
       "min             NaN                NaN       NaN       0.000000     1.000000   \n",
       "25%             NaN                NaN       NaN       7.000000     2.000000   \n",
       "50%             NaN                NaN       NaN      14.000000     5.000000   \n",
       "75%             NaN                NaN       NaN      23.000000    12.000000   \n",
       "max             NaN                NaN       NaN      65.000000   124.000000   \n",
       "\n",
       "          %texte_lu  %texte_lu_fin_ligne Is_alpha   Grammar Tokenization  \\\n",
       "count   5594.000000          5594.000000     5594      5594         5592   \n",
       "unique          NaN                  NaN     1626      2748         3802   \n",
       "top             NaN                  NaN  [False]  ['NOUN']                \n",
       "freq            NaN                  NaN      638       334          198   \n",
       "mean      50.470518            49.529483      NaN       NaN          NaN   \n",
       "std       30.190027            30.190025      NaN       NaN          NaN   \n",
       "min        0.240000             0.000000      NaN       NaN          NaN   \n",
       "25%       24.190000            23.552500      NaN       NaN          NaN   \n",
       "50%       49.530000            50.470000      NaN       NaN          NaN   \n",
       "75%       76.447500            75.810000      NaN       NaN          NaN   \n",
       "max      100.000000            99.760000      NaN       NaN          NaN   \n",
       "\n",
       "         Verb_count  Propn_count  Noun_count    Num_count  \\\n",
       "count   5594.000000  5594.000000  5594.00000  5594.000000   \n",
       "unique          NaN          NaN         NaN          NaN   \n",
       "top             NaN          NaN         NaN          NaN   \n",
       "freq            NaN          NaN         NaN          NaN   \n",
       "mean       0.297283     0.611012     2.83822     0.320164   \n",
       "std        0.784780     1.129198     3.56600     0.693458   \n",
       "min        0.000000     0.000000     0.00000     0.000000   \n",
       "25%        0.000000     0.000000     1.00000     0.000000   \n",
       "50%        0.000000     0.000000     2.00000     0.000000   \n",
       "75%        0.000000     1.000000     4.00000     0.000000   \n",
       "max        8.000000    14.000000    39.00000     8.000000   \n",
       "\n",
       "        Pourcentage_verb_sentence  Pourcentage_propn_sentence  \\\n",
       "count                 5594.000000                 5594.000000   \n",
       "unique                        NaN                         NaN   \n",
       "top                           NaN                         NaN   \n",
       "freq                          NaN                         NaN   \n",
       "mean                     0.020117                    0.105039   \n",
       "std                      0.059959                    0.227969   \n",
       "min                      0.000000                    0.000000   \n",
       "25%                      0.000000                    0.000000   \n",
       "50%                      0.000000                    0.000000   \n",
       "75%                      0.000000                    0.102564   \n",
       "max                      1.000000                    1.000000   \n",
       "\n",
       "        Pourcentage_noun_sentence  Pourcentage_num_sentence        Label  \n",
       "count                 5594.000000               5594.000000  5594.000000  \n",
       "unique                        NaN                       NaN          NaN  \n",
       "top                           NaN                       NaN          NaN  \n",
       "freq                          NaN                       NaN          NaN  \n",
       "mean                     0.314979                  0.042982     0.037898  \n",
       "std                      0.251108                  0.131906     0.190966  \n",
       "min                      0.000000                  0.000000     0.000000  \n",
       "25%                      0.157895                  0.000000     0.000000  \n",
       "50%                      0.307692                  0.000000     0.000000  \n",
       "75%                      0.416667                  0.000000     0.000000  \n",
       "max                      1.000000                  1.000000     1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_desc = dataset.describe(include='all')\n",
    "display(data_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_Sentences                  0.000000\n",
       "Sentences_CV_clean            0.035753\n",
       "CV_Number                     0.000000\n",
       "Sentence_line                 0.000000\n",
       "Nb_tokens                     0.000000\n",
       "%texte_lu                     0.000000\n",
       "%texte_lu_fin_ligne           0.000000\n",
       "Is_alpha                      0.000000\n",
       "Grammar                       0.000000\n",
       "Tokenization                  0.035753\n",
       "Verb_count                    0.000000\n",
       "Propn_count                   0.000000\n",
       "Noun_count                    0.000000\n",
       "Num_count                     0.000000\n",
       "Pourcentage_verb_sentence     0.000000\n",
       "Pourcentage_propn_sentence    0.000000\n",
       "Pourcentage_noun_sentence     0.000000\n",
       "Pourcentage_num_sentence      0.000000\n",
       "Label                         0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(100*dataset.isnull().sum()/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifier des valeurs de la colonne label\n",
    "dataset[\"Label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5416, 19)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des lignes de CV_Sentences avec les '#NOM?'\n",
    "dataset = dataset.loc[(dataset['CV_Sentences'] != \"#NOM?\"),:]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 19)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppression des lignes de CV_Sentences avec ':'\n",
    "dataset = dataset.loc[(dataset['CV_Sentences'] != \":\"),:]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5410, 19)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppresion des lignes sans valeur (avec NaN)\n",
    "dataset = dataset.dropna(axis =0, how = 'any')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_Sentences                  0.0\n",
       "Sentences_CV_clean            0.0\n",
       "CV_Number                     0.0\n",
       "Sentence_line                 0.0\n",
       "Nb_tokens                     0.0\n",
       "%texte_lu                     0.0\n",
       "%texte_lu_fin_ligne           0.0\n",
       "Is_alpha                      0.0\n",
       "Grammar                       0.0\n",
       "Tokenization                  0.0\n",
       "Verb_count                    0.0\n",
       "Propn_count                   0.0\n",
       "Noun_count                    0.0\n",
       "Num_count                     0.0\n",
       "Pourcentage_verb_sentence     0.0\n",
       "Pourcentage_propn_sentence    0.0\n",
       "Pourcentage_noun_sentence     0.0\n",
       "Pourcentage_num_sentence      0.0\n",
       "Label                         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vérification de la présence des valeurs 'Null' dans la dataset\n",
    "display(100*dataset.isnull().sum()/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Application du modèle Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "y : \n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "X :\n",
      "   Sentence_line  Nb_tokens  %texte_lu  %texte_lu_fin_ligne  Verb_count  \\\n",
      "0              0          6       2.80                97.20           1   \n",
      "1              1          1       3.27                96.73           0   \n",
      "2              2          8       7.01                92.99           0   \n",
      "3              3         24      18.22                81.78           5   \n",
      "4              4          1      18.69                81.31           0   \n",
      "\n",
      "   Propn_count  Noun_count  Num_count  Pourcentage_verb_sentence  \\\n",
      "0            3           1          1                   0.166667   \n",
      "1            0           1          0                   0.000000   \n",
      "2            1           2          0                   0.000000   \n",
      "3            1           5          1                   0.208333   \n",
      "4            0           1          0                   0.000000   \n",
      "\n",
      "   Pourcentage_propn_sentence  Pourcentage_noun_sentence  \\\n",
      "0                    0.500000                   0.166667   \n",
      "1                    0.000000                   1.000000   \n",
      "2                    0.125000                   0.250000   \n",
      "3                    0.041667                   0.208333   \n",
      "4                    0.000000                   1.000000   \n",
      "\n",
      "   Pourcentage_num_sentence  \n",
      "0                  0.166667  \n",
      "1                  0.000000  \n",
      "2                  0.000000  \n",
      "3                  0.041667  \n",
      "4                  0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "\n",
    "## Choisir la features_list par rapport au dataset\n",
    "#features_list = [\"CV_Sentences\",\"Sentences_CV_clean\",\"CV_Number\", \"Is_alpha\", \"Grammar\", \"Label\"] ## Pour les datasets features1\n",
    "features_list = [\"CV_Sentences\",\"Sentences_CV_clean\",\"CV_Number\", \"Is_alpha\", \"Label\", \"Grammar\", \"Tokenization\"] ## Pour les datasets features2\n",
    "target_variable = \"Label\"\n",
    "\n",
    "X = dataset.drop(features_list, axis = 1)\n",
    "y = dataset.loc[:,target_variable]\n",
    "\n",
    "print('y : ')\n",
    "print(y.head())\n",
    "print()\n",
    "print('X :')\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['Sentence_line', 'Nb_tokens', '%texte_lu', '%texte_lu_fin_ligne', 'Verb_count', 'Propn_count', 'Noun_count', 'Num_count', 'Pourcentage_verb_sentence', 'Pourcentage_propn_sentence', 'Pourcentage_noun_sentence', 'Pourcentage_num_sentence']\n",
      "Found categorical features  []\n"
     ]
    }
   ],
   "source": [
    "# Automatically detect names of numeric/categorical columns\n",
    "numeric_features = []\n",
    "categorical_features = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "    if ('float' in str(t)) or ('int' in str(t)) :\n",
    "        numeric_features.append(i)\n",
    "    else :\n",
    "        categorical_features.append(i)\n",
    "\n",
    "print('Found numeric features ', numeric_features)\n",
    "print('Found categorical features ', categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_transformer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for categorical features\n",
    "categorical_transformer = OneHotEncoder(drop='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ColumnTransformer to make a preprocessor object that describes all the treatments to be done\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid search...\n",
      "...Done.\n",
      "Best hyperparameters :  {'max_depth': 8, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 20}\n",
      "Best validation accuracy :  0.9743533675572511\n"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "print(\"Grid search...\")\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Grid of values to be tested\n",
    "params = {\n",
    "    'max_depth': [2, 4, 6, 8, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'min_samples_split': [2, 4, 8],\n",
    "    'n_estimators': [10, 20, 40, 60, 80, 100]\n",
    "}\n",
    "gridsearch = GridSearchCV(classifier, param_grid = params, cv = 3) # cv : the number of folds to be used for CV\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print(\"...Done.\")\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best validation accuracy : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = gridsearch.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = gridsearch.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set :  0.9831330868761553\n",
      "accuracy on test set :  0.9704251386321626\n",
      "\n",
      "f1-score on training set :  0.7420494699646644\n",
      "f1-score on test set :  0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print scores\n",
    "print(\"accuracy on training set : \", accuracy_score(y_train, Y_train_pred))\n",
    "print(\"accuracy on test set : \", accuracy_score(y_test, Y_test_pred))\n",
    "print()\n",
    "\n",
    "print(\"f1-score on training set : \", f1_score(y_train, Y_train_pred))\n",
    "print(\"f1-score on test set : \", f1_score(y_test, Y_test_pred))                              \n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice de Confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ],
         "name": "train",
         "type": "heatmap",
         "x": [
          "0",
          "1"
         ],
         "xaxis": "x",
         "y": [
          "0",
          "1"
         ],
         "yaxis": "y",
         "z": [
          [
           4150,
           8
          ],
          [
           65,
           105
          ]
         ],
         "zmax": 4150,
         "zmin": 0
        },
        {
         "colorscale": [
          [
           0,
           "rgb(247,252,240)"
          ],
          [
           0.125,
           "rgb(224,243,219)"
          ],
          [
           0.25,
           "rgb(204,235,197)"
          ],
          [
           0.375,
           "rgb(168,221,181)"
          ],
          [
           0.5,
           "rgb(123,204,196)"
          ],
          [
           0.625,
           "rgb(78,179,211)"
          ],
          [
           0.75,
           "rgb(43,140,190)"
          ],
          [
           0.875,
           "rgb(8,104,172)"
          ],
          [
           1,
           "rgb(8,64,129)"
          ]
         ],
         "name": "test",
         "type": "heatmap",
         "x": [
          "0",
          "1"
         ],
         "xaxis": "x2",
         "y": [
          "0",
          "1"
         ],
         "yaxis": "y2",
         "z": [
          [
           1034,
           6
          ],
          [
           26,
           16
          ]
         ],
         "zmax": 4150,
         "zmin": 0
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "train",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "test",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Prediction",
          "x": 0.5,
          "xanchor": "center",
          "xref": "paper",
          "y": 0,
          "yanchor": "top",
          "yref": "paper",
          "yshift": -30
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "True label",
          "textangle": -90,
          "x": 0,
          "xanchor": "right",
          "xref": "paper",
          "xshift": -40,
          "y": 0.5,
          "yanchor": "middle",
          "yref": "paper"
         }
        ],
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Confusion matrices",
         "x": 0.5
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          0.45
         ]
        },
        "xaxis2": {
         "anchor": "y2",
         "domain": [
          0.55,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        },
        "yaxis2": {
         "anchor": "x2",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ]
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize confusion matrices\n",
    "from plotly.subplots import make_subplots\n",
    "cm_train = confusion_matrix(y_train, Y_train_pred)\n",
    "cm_test = confusion_matrix(y_test, Y_test_pred)\n",
    "\n",
    "fig = make_subplots(rows = 1, cols = 2, subplot_titles = (\"train\", \"test\"), \n",
    "                    x_title = 'Prediction', y_title = 'True label')\n",
    "fig.update_layout(\n",
    "        title = go.layout.Title(text = \"Confusion matrices\", x = 0.5))\n",
    "fig.update_yaxes(autorange='reversed')\n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        name = 'train',\n",
    "        x = ['0', '1'], \n",
    "        y = ['0', '1'], \n",
    "        z = cm_train,\n",
    "        colorscale = 'gnbu',\n",
    "        zmin = 0,\n",
    "        zmax = max(cm_train.max(), cm_test.max())\n",
    "    ),\n",
    "    row = 1,\n",
    "    col = 1\n",
    ")  \n",
    "fig.add_trace(\n",
    "    go.Heatmap(\n",
    "        name = 'test',\n",
    "        x = ['0', '1'], \n",
    "        y = ['0', '1'], \n",
    "        z = cm_test,\n",
    "        colorscale = 'gnbu',\n",
    "        zmin = 0,\n",
    "        zmax = max(cm_train.max(), cm_test.max())\n",
    "    ),\n",
    "    row = 1,\n",
    "    col = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "train",
         "type": "scatter",
         "x": [
          0,
          0.0058823529411764705,
          0.041176470588235294,
          0.052941176470588235,
          0.06470588235294118,
          0.07647058823529412,
          0.10588235294117647,
          0.1411764705882353,
          0.16470588235294117,
          0.17647058823529413,
          0.18235294117647058,
          0.20588235294117646,
          0.2235294117647059,
          0.23529411764705882,
          0.2529411764705882,
          0.2647058823529412,
          0.27058823529411763,
          0.28823529411764703,
          0.3411764705882353,
          0.36470588235294116,
          0.3941176470588235,
          0.3941176470588235,
          0.4117647058823529,
          0.4235294117647059,
          0.4294117647058823,
          0.4294117647058823,
          0.43529411764705883,
          0.4470588235294118,
          0.5235294117647059,
          0.5352941176470588,
          0.5705882352941176,
          0.5705882352941176,
          0.5764705882352941,
          0.5764705882352941,
          0.5882352941176471,
          0.5882352941176471,
          0.5941176470588235,
          0.6058823529411764,
          0.6058823529411764,
          0.6176470588235294,
          0.6176470588235294,
          0.6294117647058823,
          0.6352941176470588,
          0.6411764705882353,
          0.6411764705882353,
          0.6470588235294118,
          0.6470588235294118,
          0.6764705882352942,
          0.6764705882352942,
          0.6823529411764706,
          0.6823529411764706,
          0.6882352941176471,
          0.6882352941176471,
          0.7,
          0.7,
          0.711764705882353,
          0.711764705882353,
          0.7176470588235294,
          0.7176470588235294,
          0.7352941176470589,
          0.7352941176470589,
          0.7411764705882353,
          0.7411764705882353,
          0.7470588235294118,
          0.7470588235294118,
          0.7529411764705882,
          0.7529411764705882,
          0.7764705882352941,
          0.7764705882352941,
          0.7823529411764706,
          0.7823529411764706,
          0.788235294117647,
          0.788235294117647,
          0.7941176470588235,
          0.7941176470588235,
          0.8,
          0.8,
          0.8058823529411765,
          0.8058823529411765,
          0.8117647058823529,
          0.8117647058823529,
          0.8235294117647058,
          0.8235294117647058,
          0.8352941176470589,
          0.8352941176470589,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8470588235294118,
          0.8529411764705882,
          0.8529411764705882,
          0.8588235294117647,
          0.8588235294117647,
          0.8647058823529412,
          0.8705882352941177,
          0.8764705882352941,
          0.8764705882352941,
          0.8823529411764706,
          0.8823529411764706,
          0.888235294117647,
          0.888235294117647,
          0.9,
          0.9,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9117647058823529,
          0.9117647058823529,
          0.9176470588235294,
          0.9176470588235294,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9294117647058824,
          0.9294117647058824,
          0.9352941176470588,
          0.9352941176470588,
          0.9352941176470588,
          0.9352941176470588,
          0.9352941176470588,
          0.9470588235294117,
          0.9470588235294117,
          0.9470588235294117,
          0.9470588235294117,
          0.9470588235294117,
          0.9470588235294117,
          0.9470588235294117,
          0.9470588235294117,
          0.9529411764705882,
          0.9529411764705882,
          0.9529411764705882,
          0.9529411764705882,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9705882352941176,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0.0002405002405002405,
          0.0002405002405002405,
          0.0002405002405002405,
          0.0002405002405002405,
          0.000481000481000481,
          0.000481000481000481,
          0.000481000481000481,
          0.000481000481000481,
          0.000481000481000481,
          0.000481000481000481,
          0.0007215007215007215,
          0.0007215007215007215,
          0.0012025012025012026,
          0.0012025012025012026,
          0.001443001443001443,
          0.0016835016835016834,
          0.0016835016835016834,
          0.001924001924001924,
          0.001924001924001924,
          0.0021645021645021645,
          0.0021645021645021645,
          0.0021645021645021645,
          0.002405002405002405,
          0.0026455026455026454,
          0.0026455026455026454,
          0.002886002886002886,
          0.002886002886002886,
          0.0036075036075036075,
          0.0036075036075036075,
          0.003848003848003848,
          0.003848003848003848,
          0.00456950456950457,
          0.00456950456950457,
          0.005050505050505051,
          0.005050505050505051,
          0.005291005291005291,
          0.005291005291005291,
          0.005531505531505531,
          0.005531505531505531,
          0.005772005772005772,
          0.005772005772005772,
          0.006493506493506494,
          0.006493506493506494,
          0.006734006734006734,
          0.006734006734006734,
          0.006974506974506974,
          0.006974506974506974,
          0.007455507455507456,
          0.007455507455507456,
          0.007696007696007696,
          0.007696007696007696,
          0.007936507936507936,
          0.007936507936507936,
          0.008177008177008177,
          0.008177008177008177,
          0.008658008658008658,
          0.008658008658008658,
          0.00913900913900914,
          0.00913900913900914,
          0.00937950937950938,
          0.00937950937950938,
          0.009860509860509861,
          0.009860509860509861,
          0.011063011063011063,
          0.011303511303511303,
          0.012746512746512747,
          0.013227513227513227,
          0.013227513227513227,
          0.013468013468013467,
          0.013708513708513708,
          0.013708513708513708,
          0.013949013949013949,
          0.013949013949013949,
          0.01418951418951419,
          0.01418951418951419,
          0.01467051467051467,
          0.01467051467051467,
          0.015151515151515152,
          0.015151515151515152,
          0.015873015873015872,
          0.015873015873015872,
          0.016594516594516596,
          0.016594516594516596,
          0.01875901875901876,
          0.01924001924001924,
          0.019721019721019722,
          0.019721019721019722,
          0.020202020202020204,
          0.02068302068302068,
          0.021404521404521405,
          0.021404521404521405,
          0.021645021645021644,
          0.022126022126022125,
          0.02405002405002405,
          0.024531024531024532,
          0.025252525252525252,
          0.025733525733525733,
          0.026936026936026935,
          0.027417027417027416,
          0.02861952861952862,
          0.0291005291005291,
          0.02934102934102934,
          0.030303030303030304,
          0.03150553150553151,
          0.03198653198653199,
          0.032467532467532464,
          0.03342953342953343,
          0.035594035594035595,
          0.035594035594035595,
          0.037758537758537755,
          0.037758537758537755,
          0.03872053872053872,
          0.03896103896103896,
          0.039442039442039445,
          0.04064454064454064,
          0.04064454064454064,
          0.04280904280904281,
          0.04353054353054353,
          0.04497354497354497,
          0.045454545454545456,
          0.0456950456950457,
          0.04641654641654642,
          0.046657046657046654,
          0.046897546897546896,
          0.04713804713804714,
          0.047619047619047616,
          0.048340548340548344,
          0.048340548340548344,
          0.05026455026455026,
          0.050745550745550747,
          0.05170755170755171,
          0.05218855218855219,
          0.05242905242905243,
          0.05291005291005291,
          0.05291005291005291,
          0.05339105339105339,
          0.054353054353054354,
          0.0545935545935546,
          0.055074555074555075,
          0.056998556998557,
          0.05772005772005772,
          0.05844155844155844,
          0.058922558922558925,
          0.060365560365560365,
          0.06084656084656084,
          0.061808561808561806,
          0.06228956228956229,
          0.06517556517556518,
          0.06565656565656566,
          0.07046657046657047,
          0.07190957190957191,
          0.07263107263107263,
          0.07311207311207311,
          0.07407407407407407,
          0.07455507455507455,
          0.07527657527657527,
          0.07888407888407889,
          0.07960557960557961,
          0.08273208273208273,
          0.08321308321308321,
          0.08345358345358346,
          0.08393458393458393,
          0.08537758537758537,
          0.08585858585858586,
          0.08898508898508899,
          0.08946608946608947,
          0.0913900913900914,
          0.09283309283309284,
          0.09307359307359307,
          0.09403559403559404,
          0.09475709475709476,
          0.09523809523809523,
          0.09547859547859548,
          0.09595959595959595,
          0.09716209716209716,
          0.09788359788359788,
          0.09836459836459836,
          0.09884559884559885,
          0.09908609908609908,
          0.09956709956709957,
          0.10052910052910052,
          0.10125060125060124,
          0.10149110149110149,
          0.10221260221260221,
          0.10245310245310245,
          0.10341510341510342,
          0.10533910533910534,
          0.10606060606060606,
          0.10654160654160655,
          0.10702260702260702,
          0.10726310726310727,
          0.1075036075036075,
          0.10870610870610871,
          0.10966810966810966,
          0.11038961038961038,
          0.11087061087061087,
          0.11159211159211159,
          0.11207311207311207,
          0.11255411255411256,
          0.11303511303511303,
          0.11351611351611351,
          0.113997113997114,
          0.11447811447811448,
          0.11592111592111592,
          0.11784511784511785,
          0.11832611832611832,
          0.11952861952861953,
          0.12000962000962001,
          0.1204906204906205,
          0.12097162097162097,
          0.12361712361712361,
          0.12433862433862433,
          0.12481962481962482,
          0.12578162578162577,
          0.1265031265031265,
          0.12698412698412698,
          0.12842712842712842,
          0.12890812890812892,
          0.12914862914862915,
          0.12962962962962962,
          0.12987012987012986,
          0.13083213083213083,
          0.13107263107263106,
          0.13107263107263106,
          0.13155363155363156,
          0.132996632996633,
          0.13347763347763347,
          0.1349206349206349,
          0.13564213564213565,
          0.13612313612313612,
          0.13660413660413662,
          0.13732563732563732,
          0.13876863876863876,
          0.13924963924963926,
          0.14045214045214044,
          0.14093314093314094,
          0.14165464165464164,
          0.14213564213564214,
          0.14502164502164502,
          0.145983645983646,
          0.14766714766714767,
          0.14814814814814814,
          0.1491101491101491,
          0.14959114959114958,
          0.14983164983164984,
          0.15031265031265031,
          0.15271765271765272,
          0.15367965367965367,
          0.15536315536315537,
          0.15608465608465608,
          0.15776815776815778,
          0.15921115921115922,
          0.16137566137566137,
          0.16161616161616163,
          0.1620971620971621,
          0.16354016354016354,
          0.16522366522366522,
          0.16570466570466572,
          0.16594516594516595,
          0.16666666666666666,
          0.16714766714766716,
          0.16762866762866763,
          0.16786916786916786,
          0.1685906685906686,
          0.16883116883116883,
          0.1693121693121693,
          0.16955266955266957,
          0.17075517075517074,
          0.17147667147667148,
          0.17195767195767195,
          0.17291967291967292,
          0.1734006734006734,
          0.1738816738816739,
          0.1746031746031746,
          0.1750841750841751,
          0.17652717652717653,
          0.1774891774891775,
          0.1794131794131794,
          0.17989417989417988,
          0.18133718133718132,
          0.18181818181818182,
          0.1822991822991823,
          0.18302068302068303,
          0.18398268398268397,
          0.18446368446368447,
          0.1847041847041847,
          0.18542568542568544,
          0.18662818662818662,
          0.18710918710918711,
          0.18759018759018758,
          0.18807118807118808,
          0.1887926887926888,
          0.18951418951418952,
          0.18975468975468976,
          0.19023569023569023,
          0.19071669071669073,
          0.1911976911976912,
          0.19143819143819144,
          0.1936026936026936,
          0.19456469456469455,
          0.19552669552669552,
          0.19600769600769602,
          0.1964886964886965,
          0.19817219817219817,
          0.19937469937469937,
          0.19985569985569984,
          0.20202020202020202,
          0.20298220298220299,
          0.20346320346320346,
          0.20394420394420396,
          0.20514670514670516,
          0.20562770562770563,
          0.2065897065897066,
          0.20707070707070707,
          0.20899470899470898,
          0.20947570947570948,
          0.2113997113997114,
          0.21212121212121213,
          0.21284271284271283,
          0.21356421356421357,
          0.21476671476671477,
          0.21524771524771524,
          0.21572871572871574,
          0.21645021645021645,
          0.21693121693121692,
          0.21765271765271765,
          0.21861471861471862,
          0.22005772005772006,
          0.22077922077922077,
          0.22174122174122174,
          0.22198172198172197,
          0.22294372294372294,
          0.22318422318422318,
          0.22414622414622415,
          0.22486772486772486,
          0.22582972582972582,
          0.22607022607022606,
          0.22703222703222703,
          0.227994227994228,
          0.2291967291967292,
          0.22943722943722944,
          0.23160173160173161,
          0.2328042328042328,
          0.2332852332852333,
          0.23352573352573353,
          0.23424723424723426,
          0.2344877344877345,
          0.2352092352092352,
          0.23617123617123617,
          0.2368927368927369,
          0.23737373737373738,
          0.2376142376142376,
          0.23809523809523808,
          0.24025974025974026,
          0.24122174122174123,
          0.2417027417027417,
          0.2421837421837422,
          0.24242424242424243,
          0.24314574314574314,
          0.24362674362674364,
          0.2441077441077441,
          0.24434824434824434,
          0.24482924482924484,
          0.24555074555074555,
          0.24603174603174602,
          0.24723424723424722,
          0.24963924963924963,
          0.25036075036075034,
          0.2506012506012506,
          0.2510822510822511,
          0.2518037518037518,
          0.2522847522847523,
          0.25276575276575275,
          0.2566137566137566,
          0.25757575757575757,
          0.2585377585377585,
          0.2587782587782588,
          0.25925925925925924,
          0.26046176046176045,
          0.2607022607022607,
          0.2619047619047619,
          0.2623857623857624,
          0.26455026455026454,
          0.26551226551226553,
          0.265993265993266,
          0.2662337662337662,
          0.26671476671476674,
          0.2671957671957672,
          0.2676767676767677,
          0.2691197691197691,
          0.2696007696007696,
          0.2700817700817701,
          0.27224627224627224,
          0.2724867724867725,
          0.27344877344877344,
          0.2736892736892737,
          0.2741702741702742,
          0.2756132756132756,
          0.2763347763347763,
          0.2777777777777778,
          0.27825877825877826,
          0.27970177970177973,
          0.2801827801827802,
          0.2804232804232804,
          0.2816257816257816,
          0.2825877825877826,
          0.284030784030784,
          0.2845117845117845,
          0.2852332852332852,
          0.2857142857142857,
          0.28715728715728717,
          0.28763828763828764,
          0.2890812890812891,
          0.2895622895622896,
          0.2905242905242905,
          0.2943722943722944,
          0.2946127946127946,
          0.2950937950937951,
          0.29605579605579607,
          0.29653679653679654,
          0.29677729677729675,
          0.2974987974987975,
          0.2982202982202982,
          0.3023088023088023,
          0.30254930254930257,
          0.30303030303030304,
          0.30327080327080325,
          0.3037518037518038,
          0.30423280423280424,
          0.3047138047138047,
          0.30567580567580566,
          0.3061568061568062,
          0.30735930735930733,
          0.3088023088023088,
          0.30976430976430974,
          0.31000481000481,
          0.31072631072631074,
          0.3112073112073112,
          0.31216931216931215,
          0.3126503126503126,
          0.31337181337181336,
          0.31577681577681577,
          0.31625781625781624,
          0.31697931697931697,
          0.3177008177008177,
          0.3193843193843194,
          0.32227032227032226,
          0.3225108225108225,
          0.32347282347282347,
          0.32395382395382394,
          0.3241943241943242,
          0.32515632515632514,
          0.3253968253968254,
          0.32635882635882635,
          0.3268398268398268,
          0.3278018278018278,
          0.3282828282828283,
          0.32876382876382876,
          0.329004329004329,
          0.3294853294853295,
          0.3302068302068302,
          0.33116883116883117,
          0.33140933140933143,
          0.3321308321308321,
          0.3323713323713324,
          0.33285233285233284,
          0.335016835016835,
          0.3354978354978355,
          0.335978835978836,
          0.3367003367003367,
          0.3374218374218374,
          0.33814333814333813,
          0.3386243386243386,
          0.33934583934583934,
          0.3398268398268398,
          0.3407888407888408,
          0.3412698412698413,
          0.3422318422318422,
          0.3431938431938432,
          0.34415584415584416,
          0.3443963443963444,
          0.3451178451178451,
          0.34559884559884557,
          0.348003848003848,
          0.3496873496873497,
          0.3504088504088504,
          0.3511303511303511,
          0.3525733525733526,
          0.35305435305435307,
          0.3532948532948533,
          0.3537758537758538,
          0.354016354016354,
          0.3544973544973545,
          0.35473785473785474,
          0.3556998556998557,
          0.3569023569023569,
          0.35738335738335736,
          0.3581048581048581,
          0.35834535834535836,
          0.3590668590668591,
          0.35954785954785956,
          0.36002886002886003,
          0.3605098605098605,
          0.36075036075036077,
          0.3617123617123617,
          0.3621933621933622,
          0.36267436267436265,
          0.3629148629148629,
          0.3633958633958634,
          0.36363636363636365,
          0.3643578643578644,
          0.3658008658008658,
          0.36628186628186626,
          0.367003367003367,
          0.37012987012987014,
          0.37133237133237135,
          0.3720538720538721,
          0.37277537277537276,
          0.3746993746993747,
          0.37542087542087543,
          0.37566137566137564,
          0.37614237614237617,
          0.3763828763828764,
          0.37734487734487737,
          0.37806637806637805,
          0.37902837902837905,
          0.37926887926887926,
          0.3797498797498797,
          0.38047138047138046,
          0.3811928811928812,
          0.38191438191438193,
          0.3823953823953824,
          0.38263588263588266,
          0.38335738335738334,
          0.3835978835978836,
          0.38455988455988455,
          0.38552188552188554,
          0.386002886002886,
          0.3862433862433862,
          0.38672438672438675,
          0.3874458874458874,
          0.38816738816738816,
          0.3888888888888889,
          0.38936988936988937,
          0.3903318903318903,
          0.39081289081289083,
          0.3917748917748918,
          0.39225589225589225,
          0.39321789321789324,
          0.3939393939393939,
          0.3941798941798942,
          0.3951418951418951,
          0.3953823953823954,
          0.39730639730639733,
          0.3977873977873978,
          0.3992303992303992,
          0.3997113997113997,
          0.4004329004329004,
          0.4009139009139009,
          0.4016354016354016,
          0.4021164021164021,
          0.40283790283790283,
          0.4037999037999038,
          0.4042809042809043,
          0.40524290524290524,
          0.4062049062049062,
          0.4071669071669072,
          0.40764790764790765,
          0.40885040885040885,
          0.4093314093314093,
          0.4095719095719096,
          0.41005291005291006,
          0.41125541125541126,
          0.41173641173641173,
          0.411976911976912,
          0.41245791245791247,
          0.4131794131794132,
          0.4136604136604137,
          0.4143819143819144,
          0.4151034151034151,
          0.4155844155844156,
          0.4160654160654161,
          0.417027417027417,
          0.41774891774891776,
          0.41943241943241943,
          0.4203944203944204,
          0.4208754208754209,
          0.42183742183742184,
          0.42424242424242425,
          0.4247234247234247,
          0.4252044252044252,
          0.4264069264069264,
          0.42664742664742666,
          0.42736892736892734,
          0.4276094276094276,
          0.42857142857142855,
          0.4316979316979317,
          0.43217893217893216,
          0.43362193362193363,
          0.4345839345839346,
          0.43746993746993745,
          0.43915343915343913,
          0.43963443963443966,
          0.4405964405964406,
          0.44107744107744107,
          0.44155844155844154,
          0.44203944203944207,
          0.443001443001443,
          0.4434824434824435,
          0.44396344396344395,
          0.4446849446849447,
          0.44492544492544495,
          0.4458874458874459,
          0.44733044733044736,
          0.4478114478114478,
          0.44805194805194803,
          0.44877344877344877,
          0.44901394901394903,
          0.4494949494949495,
          0.45021645021645024,
          0.4511784511784512,
          0.45141895141895144,
          0.4518999518999519,
          0.45286195286195285,
          0.4535834535834536,
          0.4538239538239538,
          0.4543049543049543,
          0.4555074555074555,
          0.45695045695045694,
          0.4574314574314574,
          0.4600769600769601,
          0.4603174603174603,
          0.4615199615199615,
          0.4624819624819625,
          0.46344396344396344,
          0.46440596440596443,
          0.4656084656084656,
          0.4668109668109668,
          0.4677729677729678,
          0.46825396825396826,
          0.4687349687349687,
          0.46993746993746993,
          0.4704184704184704,
          0.47113997113997114,
          0.4713804713804714,
          0.47186147186147187,
          0.4733044733044733,
          0.4737854737854738,
          0.4754689754689755,
          0.47739297739297737,
          0.4781144781144781,
          0.4785954785954786,
          0.4790764790764791,
          0.4797979797979798,
          0.4807599807599808,
          0.481000481000481,
          0.4831649831649832,
          0.48508898508898507,
          0.4858104858104858,
          0.48653198653198654,
          0.487012987012987,
          0.48725348725348727,
          0.48773448773448774,
          0.4884559884559885,
          0.4896584896584897,
          0.49013949013949015,
          0.49182299182299183,
          0.494949494949495,
          0.4951899951899952,
          0.4961519961519962,
          0.4975949975949976,
          0.49927849927849927,
          0.5024050024050024,
          0.5038480038480039,
          0.5043290043290043,
          0.5045695045695046,
          0.506974506974507,
          0.5084175084175084,
          0.5086580086580087,
          0.5096200096200096,
          0.51010101010101,
          0.5113035113035113,
          0.5115440115440115,
          0.5141895141895142,
          0.5149110149110149,
          0.5153920153920154,
          0.5158730158730159,
          0.5168350168350169,
          0.5177970177970178,
          0.5185185185185185,
          0.5187590187590188,
          0.5192400192400193,
          0.5202020202020202,
          0.5223665223665224,
          0.5226070226070226,
          0.5245310245310245,
          0.5254930254930255,
          0.5262145262145262,
          0.5266955266955267,
          0.5283790283790284,
          0.5288600288600288,
          0.5293410293410293,
          0.5339105339105339,
          0.5353535353535354,
          0.5363155363155363,
          0.5367965367965368,
          0.5401635401635402,
          0.5406445406445406,
          0.543049543049543,
          0.5444925444925445,
          0.5447330447330447,
          0.5452140452140453,
          0.5454545454545454,
          0.5464165464165465,
          0.5471380471380471,
          0.5473785473785474,
          0.5497835497835498,
          0.550986050986051,
          0.5517075517075517,
          0.551948051948052,
          0.5524290524290524,
          0.5526695526695526,
          0.5548340548340548,
          0.5555555555555556,
          0.5557960557960558,
          0.5562770562770563,
          0.5572390572390572,
          0.557960557960558,
          0.5598845598845599,
          0.5603655603655604,
          0.5606060606060606,
          0.5610870610870611,
          0.562049062049062,
          0.5625300625300625,
          0.5632515632515632,
          0.5646945646945647,
          0.5651755651755652,
          0.5656565656565656,
          0.5668590668590668,
          0.5673400673400674,
          0.5683020683020683,
          0.5687830687830688,
          0.5695045695045695,
          0.56998556998557,
          0.5707070707070707,
          0.5726310726310726,
          0.5728715728715729,
          0.5743145743145743,
          0.5767195767195767,
          0.5776815776815777,
          0.5781625781625782,
          0.5791245791245792,
          0.5808080808080808,
          0.5822510822510822,
          0.5824915824915825,
          0.5829725829725829,
          0.5858585858585859,
          0.5863395863395864,
          0.5873015873015873,
          0.5875420875420876,
          0.588023088023088,
          0.5887445887445888,
          0.5894660894660895,
          0.5904280904280904,
          0.5909090909090909,
          0.5916305916305916,
          0.5928330928330928,
          0.5945165945165946,
          0.5952380952380952,
          0.5957190957190958,
          0.5964405964405964,
          0.5966810966810967,
          0.5974025974025974,
          0.5976430976430976,
          0.5981240981240982,
          0.5993265993265994,
          0.5998075998075998,
          0.6002886002886003,
          0.6007696007696007,
          0.601010101010101,
          0.6022126022126022,
          0.6026936026936027,
          0.6034151034151034,
          0.6043771043771043,
          0.6053391053391053,
          0.6060606060606061,
          0.6118326118326118,
          0.6123136123136124,
          0.6132756132756133,
          0.6135161135161136,
          0.6149591149591149,
          0.6159211159211159,
          0.6161616161616161,
          0.6171236171236171,
          0.6180856180856181,
          0.6185666185666185,
          0.6188071188071188,
          0.62000962000962,
          0.6202501202501203,
          0.6207311207311207,
          0.6214526214526215,
          0.6219336219336219,
          0.6221741221741222,
          0.6231361231361231,
          0.6289081289081289,
          0.6291486291486291,
          0.6298701298701299,
          0.6298701298701299,
          0.6325156325156325,
          0.6332371332371333,
          0.6337181337181337,
          0.6339586339586339,
          0.6349206349206349,
          0.6351611351611351,
          0.6361231361231361,
          0.6363636363636364,
          0.6375661375661376,
          0.6380471380471381,
          0.6385281385281385,
          0.639009139009139,
          0.6402116402116402,
          0.6409331409331409,
          0.6430976430976431,
          0.6435786435786436,
          0.6438191438191438,
          0.6447811447811448,
          0.6452621452621453,
          0.6464646464646465,
          0.6474266474266475,
          0.6479076479076479,
          0.6483886483886484,
          0.6503126503126503,
          0.6534391534391535,
          0.658008658008658,
          0.6582491582491582,
          0.6592111592111592,
          0.6637806637806638,
          0.6657046657046657,
          0.6671476671476672,
          0.6673881673881674,
          0.6693121693121693,
          0.6697931697931698,
          0.6731601731601732,
          0.6734006734006734,
          0.690957190957191,
          0.6916786916786917,
          0.6921596921596922,
          0.6926406926406926,
          0.6974506974506974,
          0.6984126984126984,
          0.6991341991341992,
          0.7005772005772006,
          0.7008177008177008,
          0.702020202020202,
          0.7034632034632035,
          0.7037037037037037,
          0.7061087061087061,
          0.7063492063492064,
          0.7068302068302068,
          0.7075517075517076,
          0.708994708994709,
          0.7092352092352092,
          0.7097162097162097,
          0.7128427128427128,
          0.7138047138047138,
          0.714045214045214,
          0.7145262145262146,
          0.7164502164502164,
          0.716931216931217,
          0.721019721019721,
          0.7217412217412218,
          0.7224627224627225,
          0.7229437229437229,
          0.7236652236652237,
          0.7255892255892256,
          0.7258297258297258,
          0.7277537277537277,
          0.7306397306397306,
          0.7325637325637325,
          0.7438672438672439,
          0.7443482443482443,
          0.7453102453102453,
          0.7457912457912458,
          0.746031746031746,
          0.7467532467532467,
          0.746993746993747,
          0.7477152477152477,
          0.7491582491582491,
          0.7525252525252525,
          0.753968253968254,
          0.7542087542087542,
          0.7645502645502645,
          0.7652717652717653,
          0.7662337662337663,
          0.7681577681577682,
          0.7691197691197691,
          0.7727272727272727,
          0.7734487734487735,
          0.7736892736892736,
          0.7744107744107744,
          0.7816257816257817,
          0.7828282828282829,
          0.783068783068783,
          0.7854737854737854,
          0.7857142857142857,
          0.7881192881192881,
          0.7895622895622896,
          0.7912457912457912,
          0.7972582972582972,
          0.7974987974987975,
          0.7999037999037999,
          0.8003848003848004,
          0.8023088023088023,
          0.8037518037518038,
          0.804954304954305,
          0.8068783068783069,
          0.8071188071188071,
          0.8075998075998077,
          0.8112073112073112,
          0.8116883116883117,
          0.8140933140933141,
          0.8155363155363156,
          0.816979316979317,
          0.8181818181818182,
          0.8184223184223184,
          0.8196248196248196,
          0.8198653198653199,
          0.8208273208273208,
          0.822029822029822,
          0.8246753246753247,
          0.828042328042328,
          0.82996632996633,
          0.8330928330928331,
          0.8352573352573353,
          0.8489658489658489,
          0.8578643578643579,
          0.8581048581048581,
          0.8658008658008658,
          0.8682058682058682,
          0.8691678691678691,
          0.873015873015873,
          0.8751803751803752,
          0.8754208754208754,
          0.8785473785473785,
          0.8838383838383839,
          0.8848003848003848,
          0.8850408850408851,
          0.8872053872053872,
          0.8905723905723906,
          0.8924963924963925,
          0.8934583934583935,
          0.8956228956228957,
          0.8980278980278981,
          0.898989898989899,
          0.8997113997113997,
          0.9025974025974026,
          0.9066859066859067,
          0.9069264069264069,
          0.9126984126984127,
          0.9139009139009139,
          0.9141414141414141,
          0.9153439153439153,
          0.9170274170274171,
          0.9177489177489178,
          0.923039923039923,
          0.9252044252044253,
          0.9288119288119289,
          0.9336219336219336,
          0.9357864357864358,
          0.943001443001443,
          0.9432419432419432,
          0.9485329485329486,
          0.9648869648869649,
          0.9682539682539683,
          0.9841269841269841,
          0.9853294853294853,
          0.9997594997594997,
          1
         ]
        },
        {
         "mode": "lines",
         "name": "test",
         "type": "scatter",
         "x": [
          0,
          0,
          0.047619047619047616,
          0.09523809523809523,
          0.09523809523809523,
          0.14285714285714285,
          0.2857142857142857,
          0.2857142857142857,
          0.3333333333333333,
          0.3333333333333333,
          0.4523809523809524,
          0.4523809523809524,
          0.4523809523809524,
          0.4523809523809524,
          0.47619047619047616,
          0.47619047619047616,
          0.5,
          0.5,
          0.5238095238095238,
          0.5238095238095238,
          0.5238095238095238,
          0.5238095238095238,
          0.5238095238095238,
          0.5714285714285714,
          0.5714285714285714,
          0.5952380952380952,
          0.5952380952380952,
          0.6190476190476191,
          0.6190476190476191,
          0.6190476190476191,
          0.6190476190476191,
          0.6428571428571429,
          0.6428571428571429,
          0.6428571428571429,
          0.6428571428571429,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6666666666666666,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.7142857142857143,
          0.7142857142857143,
          0.7142857142857143,
          0.7142857142857143,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7380952380952381,
          0.7619047619047619,
          0.7619047619047619,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.8333333333333334,
          0.8333333333333334,
          0.8333333333333334,
          0.8333333333333334,
          0.8333333333333334,
          0.8333333333333334,
          0.8333333333333334,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8571428571428571,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          0.9761904761904762,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          0,
          0.0009615384615384616,
          0.0009615384615384616,
          0.0009615384615384616,
          0.0028846153846153848,
          0.0028846153846153848,
          0.0028846153846153848,
          0.0038461538461538464,
          0.0038461538461538464,
          0.0057692307692307696,
          0.0057692307692307696,
          0.009615384615384616,
          0.011538461538461539,
          0.0125,
          0.0125,
          0.019230769230769232,
          0.019230769230769232,
          0.03461538461538462,
          0.03461538461538462,
          0.03653846153846154,
          0.038461538461538464,
          0.04903846153846154,
          0.051923076923076926,
          0.051923076923076926,
          0.057692307692307696,
          0.057692307692307696,
          0.0625,
          0.0625,
          0.06346153846153846,
          0.06538461538461539,
          0.06634615384615385,
          0.06634615384615385,
          0.10576923076923077,
          0.1076923076923077,
          0.11634615384615385,
          0.11634615384615385,
          0.11826923076923077,
          0.1201923076923077,
          0.12115384615384615,
          0.12115384615384615,
          0.12788461538461537,
          0.12980769230769232,
          0.175,
          0.17692307692307693,
          0.18076923076923077,
          0.18461538461538463,
          0.1875,
          0.18846153846153846,
          0.19038461538461537,
          0.19230769230769232,
          0.19423076923076923,
          0.20096153846153847,
          0.20288461538461539,
          0.20384615384615384,
          0.20576923076923076,
          0.2201923076923077,
          0.2221153846153846,
          0.2230769230769231,
          0.225,
          0.22596153846153846,
          0.22884615384615384,
          0.23365384615384616,
          0.23653846153846153,
          0.23846153846153847,
          0.24134615384615385,
          0.24326923076923077,
          0.24423076923076922,
          0.24423076923076922,
          0.24807692307692308,
          0.25,
          0.2548076923076923,
          0.25576923076923075,
          0.25769230769230766,
          0.26346153846153847,
          0.26634615384615384,
          0.2701923076923077,
          0.2721153846153846,
          0.275,
          0.2875,
          0.28942307692307695,
          0.2923076923076923,
          0.29423076923076924,
          0.3019230769230769,
          0.3038461538461538,
          0.30673076923076925,
          0.30865384615384617,
          0.3144230769230769,
          0.31634615384615383,
          0.31826923076923075,
          0.32211538461538464,
          0.32596153846153847,
          0.3278846153846154,
          0.33942307692307694,
          0.33942307692307694,
          0.34134615384615385,
          0.3423076923076923,
          0.34615384615384615,
          0.34807692307692306,
          0.3490384615384615,
          0.35192307692307695,
          0.3682692307692308,
          0.375,
          0.3798076923076923,
          0.3817307692307692,
          0.38269230769230766,
          0.3855769230769231,
          0.3875,
          0.3894230769230769,
          0.40384615384615385,
          0.40384615384615385,
          0.4096153846153846,
          0.4115384615384615,
          0.4153846153846154,
          0.4182692307692308,
          0.4355769230769231,
          0.4375,
          0.4375,
          0.4394230769230769,
          0.44326923076923075,
          0.4442307692307692,
          0.4480769230769231,
          0.45384615384615384,
          0.4625,
          0.46826923076923077,
          0.4721153846153846,
          0.4740384615384615,
          0.47596153846153844,
          0.48846153846153845,
          0.4913461538461538,
          0.49615384615384617,
          0.4980769230769231,
          0.5,
          0.5019230769230769,
          0.5048076923076923,
          0.5096153846153846,
          0.5134615384615384,
          0.5163461538461539,
          0.5192307692307693,
          0.525,
          0.5288461538461539,
          0.5326923076923077,
          0.5346153846153846,
          0.5355769230769231,
          0.5413461538461538,
          0.5423076923076923,
          0.5451923076923076,
          0.5461538461538461,
          0.5461538461538461,
          0.5557692307692308,
          0.5596153846153846,
          0.5625,
          0.5663461538461538,
          0.5682692307692307,
          0.5721153846153846,
          0.5740384615384615,
          0.5778846153846153,
          0.5836538461538462,
          0.5865384615384616,
          0.5865384615384616,
          0.5894230769230769,
          0.5913461538461539,
          0.6,
          0.6057692307692307,
          0.6076923076923076,
          0.6086538461538461,
          0.6115384615384616,
          0.6182692307692308,
          0.6211538461538462,
          0.6259615384615385,
          0.6298076923076923,
          0.6326923076923077,
          0.6346153846153846,
          0.6375,
          0.6394230769230769,
          0.6442307692307693,
          0.65,
          0.6509615384615385,
          0.6528846153846154,
          0.6538461538461539,
          0.6576923076923077,
          0.6586538461538461,
          0.6615384615384615,
          0.6817307692307693,
          0.6855769230769231,
          0.6884615384615385,
          0.6923076923076923,
          0.6951923076923077,
          0.6961538461538461,
          0.698076923076923,
          0.7,
          0.7038461538461539,
          0.7105769230769231,
          0.7134615384615385,
          0.7173076923076923,
          0.7211538461538461,
          0.7375,
          0.7384615384615385,
          0.7423076923076923,
          0.7461538461538462,
          0.7480769230769231,
          0.7548076923076923,
          0.7567307692307692,
          0.7586538461538461,
          0.7625,
          0.7644230769230769,
          0.7721153846153846,
          0.7778846153846154,
          0.7826923076923077,
          0.7865384615384615,
          0.7894230769230769,
          0.7913461538461538,
          0.7932692307692307,
          0.7971153846153847,
          0.8038461538461539,
          0.8086538461538462,
          0.8105769230769231,
          0.8115384615384615,
          0.8144230769230769,
          0.8163461538461538,
          0.8192307692307692,
          0.825,
          0.8278846153846153,
          0.8298076923076924,
          0.8432692307692308,
          0.8548076923076923,
          0.8557692307692307,
          0.8653846153846154,
          0.8711538461538462,
          0.8721153846153846,
          0.8769230769230769,
          0.8826923076923077,
          0.8846153846153846,
          0.8865384615384615,
          0.8894230769230769,
          0.8932692307692308,
          0.8951923076923077,
          0.8990384615384616,
          0.9086538461538461,
          0.9096153846153846,
          0.9125,
          0.9173076923076923,
          0.9240384615384616,
          0.926923076923077,
          0.9326923076923077,
          0.9375,
          0.9394230769230769,
          0.9644230769230769,
          0.9663461538461539,
          0.9711538461538461,
          0.9865384615384616,
          0.9884615384615385,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROC curve",
         "x": 0.5
        },
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize ROC curves\n",
    "probas_train = gridsearch.predict_proba(X_train)[:,1]\n",
    "precisions, recalls, thresholds = roc_curve(y_train, probas_train)\n",
    "fig = go.Figure(\n",
    "    data = go.Scatter(\n",
    "        name = 'train',\n",
    "        x = recalls, \n",
    "        y = precisions, \n",
    "        mode = 'lines'\n",
    "    ),\n",
    "    layout = go.Layout(\n",
    "        title = go.layout.Title(text = \"ROC curve\", x = 0.5),\n",
    "        xaxis = go.layout.XAxis(title = 'False Positive Rate'),\n",
    "        yaxis = go.layout.YAxis(title = 'True Positive Rate')\n",
    "    )\n",
    ")\n",
    "\n",
    "probas_test = gridsearch.predict_proba(X_test)[:,1]\n",
    "precisions, recalls, thresholds = roc_curve(y_test, probas_test)\n",
    "fig.add_trace(go.Scatter(\n",
    "    name = 'test',\n",
    "    x = recalls, \n",
    "    y = precisions, \n",
    "    mode = 'lines'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer différents Algorithmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = []\n",
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "knn = KNeighborsClassifier()\n",
    "nb = GaussianNB()\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "classifiers.append(tree)\n",
    "classifiers.append(knn)\n",
    "classifiers.append(nb)\n",
    "classifiers.append(logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_results = []\n",
    "for classifier in classifiers:\n",
    "  cv_results.append(cross_val_score(classifier, X_train, y_train, cv=10 ,scoring=\"accuracy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.97228637, 0.97690531, 0.97228637, 0.97228637, 0.96073903,\n",
       "        0.96766744, 0.97228637, 0.97228637, 0.97222222, 0.97685185]),\n",
       " array([0.96997691, 0.96766744, 0.96535797, 0.96997691, 0.9630485 ,\n",
       "        0.9630485 , 0.96766744, 0.96997691, 0.96990741, 0.96759259]),\n",
       " array([0.91224018, 0.93533487, 0.91685912, 0.90300231, 0.88452656,\n",
       "        0.86143187, 0.89376443, 0.89145497, 0.90740741, 0.90509259]),\n",
       " array([0.96766744, 0.9630485 , 0.97228637, 0.9630485 , 0.95612009,\n",
       "        0.96535797, 0.97459584, 0.96766744, 0.97222222, 0.96990741])]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Accuracy_mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.971582</td>\n",
       "      <td>0.004381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.967422</td>\n",
       "      <td>0.002616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.967192</td>\n",
       "      <td>0.005236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nb</td>\n",
       "      <td>0.901111</td>\n",
       "      <td>0.018971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Algorithm  Accuracy_mean       Std\n",
       "0      tree       0.971582  0.004381\n",
       "1       knn       0.967422  0.002616\n",
       "3    logreg       0.967192  0.005236\n",
       "2        nb       0.901111  0.018971"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({\"Algorithm\": [\"tree\", \"knn\", \"nb\", \"logreg\"],\n",
    "             \"Accuracy_mean\": [cv_result.mean() for cv_result in cv_results],\n",
    "             \"Std\": [cv_result.std() for cv_result in cv_results]})\n",
    "\n",
    "results = results.sort_values(by=\"Accuracy_mean\", ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "best Tree score on the train set : \n",
      " 0.975739371534196 \n",
      " best Tree score on the test set : \n",
      " 0.9685767097966729\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier() \n",
    "tree_param_grid = {\"max_depth\" : np.arange(1,10,1)}\n",
    "\n",
    "gsTree = GridSearchCV(tree,tree_param_grid, cv=10, scoring=\"accuracy\", verbose = 1)\n",
    "\n",
    "gsTree.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "tree_best = gsTree.best_estimator_\n",
    "\n",
    "# Best score\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Tree\", tree_best.score(X_train,y_train), tree_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n",
      "best Tree score on the train set : \n",
      " 0.9932994454713494 \n",
      " best Tree score on the test set : \n",
      " 0.9685767097966729\n"
     ]
    }
   ],
   "source": [
    "tree = RandomForestClassifier() \n",
    "tree_param_grid = {\"max_depth\" : np.arange(1,20,1)}\n",
    "\n",
    "gsTree = GridSearchCV(tree,tree_param_grid, cv=10, scoring=\"accuracy\", verbose = 1)\n",
    "\n",
    "gsTree.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "tree_best = gsTree.best_estimator_\n",
    "\n",
    "# Best score\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Tree\", tree_best.score(X_train,y_train), tree_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n",
      "best Knn score on the train set : \n",
      " 0.9715804066543438 \n",
      " best Knn score on the test set : \n",
      " 0.9685767097966729\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_param_grid = {\"n_neighbors\": np.arange(1,10,1)}\n",
    "\n",
    "gsknn = GridSearchCV(knn,knn_param_grid, cv=10, scoring=\"accuracy\", n_jobs= -1, verbose = 1)\n",
    "gsknn.fit(X_train, y_train)\n",
    "\n",
    "gsknn_best = gsknn.best_estimator_\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Knn\", gsknn_best.score(X_train,y_train), gsknn_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "best Logistic regression score on the train set : \n",
      " 0.967652495378928 \n",
      " best Logistic regression score on the test set : \n",
      " 0.9658040665434381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Log = LogisticRegression()\n",
    "log_param_grid = {\"class_weight\": [None, \"balanced\"],\n",
    "                 \"C\": [0.5, 0.6,0.7,0.8,0.9,1.0]}\n",
    "gsLog = GridSearchCV(Log, log_param_grid, cv =10, scoring ='accuracy', n_jobs=-1, verbose=1)\n",
    "gsLog.fit(X_train, y_train)\n",
    "gsLog_best = gsLog.best_estimator_\n",
    "\n",
    "print(\"best {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Logistic regression\", gsLog_best.score(X_train,y_train), gsLog_best.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no grid search needed on naive bayes\n",
    "Naive_Bayes = GaussianNB()\n",
    "gsNaive_Bayes_best = Naive_Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "votingC = VotingClassifier(estimators=[(\"tree\", tree_best),(\"knn\",gsknn_best),(\"LogisticRegression\",gsLog_best),(\"Naive Bayes\",gsNaive_Bayes_best)], \n",
    "                           voting='soft')\n",
    "\n",
    "votingC = votingC.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Voting Classifier score on the train set : \n",
      " 0.9771256931608133 \n",
      " best Voting Classifier score on the test set : \n",
      " 0.9713493530499075\n"
     ]
    }
   ],
   "source": [
    "print(\" {0} score on the train set : \\n {1} \\n best {0} score on the test set : \\n {2}\".format(\"Voting Classifier\", votingC.score(X_train,y_train), votingC.score(X_test,y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average score is : 0.9725039560345564 \n",
      " the standard deviation of the score is : 0.003649625858810165 \n",
      " the list of score : [0.97459584 0.97459584 0.97690531 0.97228637 0.96535797 0.96766744\n",
      " 0.97690531 0.97459584 0.97222222 0.96990741]\n"
     ]
    }
   ],
   "source": [
    "Xvalscore = cross_val_score(votingC, X_train, y_train, scoring = \"accuracy\", cv = 10, n_jobs=4)\n",
    "print(\"the average score is : {0} \\n the standard deviation of the score is : {1} \\n the list of score : {2}\".format(Xvalscore.mean(), Xvalscore.std(), Xvalscore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=12,\n",
    "    n_informative=3,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    random_state=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" checked><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "feature_names = list_columns.columns\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to compute the importances: 0.010 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "start_time = time.time()\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Elapsed time to compute the importances: {elapsed_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sentence_line', 'Nb_tokens', '%texte_lu', '%texte_lu_fin_ligne',\n",
       "       'Verb_count', 'Propn_count', 'Noun_count', 'Num_count',\n",
       "       'Pourcentage_verb_sentence', 'Pourcentage_propn_sentence',\n",
       "       'Pourcentage_noun_sentence', 'Pourcentage_num_sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_columns = dataset.drop(features_list, axis = 1)\n",
    "list_columns.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" checked><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "# fit model no training data\n",
    "model = XGBClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False,\n",
      "              eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, ...)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.00%\n"
     ]
    }
   ],
   "source": [
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1-score on test set :  0.9236641221374046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"f1-score on test set : \", f1_score(y_test, predictions))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin part 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
