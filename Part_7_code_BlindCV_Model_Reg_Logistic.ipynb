{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7 - Test modèle - Régression logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U scikit-learn    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\python39\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python39\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python39\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python39\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python39\\lib\\site-packages (from matplotlib) (1.23.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python39\\lib\\site-packages (from matplotlib) (4.34.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dany\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pip \n",
    "pip.main([\"install\",\"matplotlib\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-learn in c:\\python39\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.23.1)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in c:\\python39\\lib\\site-packages (from scikit-learn) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in c:\\python39\\lib\\site-packages (from scikit-learn) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, RocCurveDisplay, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning) # to avoid deprecation warnings\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la dataset\n",
    "dataset = pd.read_csv(\"dataset_CV_labelise_features1_200.csv\", delimiter = \";\", encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5594, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows : 5594\n",
      "\n",
      "Display of dataset: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Sentences</th>\n",
       "      <th>Sentences_CV_clean</th>\n",
       "      <th>CV_Number</th>\n",
       "      <th>Sentence_line</th>\n",
       "      <th>Nb_tokens</th>\n",
       "      <th>%texte_lu</th>\n",
       "      <th>%texte_lu_fin_ligne</th>\n",
       "      <th>Is_alpha</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE</td>\n",
       "      <td>SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE</td>\n",
       "      <td>CV_1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2.80</td>\n",
       "      <td>97.20</td>\n",
       "      <td>[True, True, True, False, True, True]</td>\n",
       "      <td>['NOUN', 'PROPN', 'VERB', 'NUM', 'PROPN', 'PRO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROFIL</td>\n",
       "      <td>PROFIL</td>\n",
       "      <td>CV_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>96.73</td>\n",
       "      <td>[True]</td>\n",
       "      <td>['NOUN']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PERSONNEL Je suis étudiante au lycée Condorcet.</td>\n",
       "      <td>PERSONNEL Je suis étudiante au lycée Condorcet.</td>\n",
       "      <td>CV_1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7.01</td>\n",
       "      <td>92.99</td>\n",
       "      <td>[True, True, True, True, True, True, True, False]</td>\n",
       "      <td>['NOUN', 'PRON', 'AUX', 'ADJ', 'ADP', 'NOUN', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Je code depuis l'âge de 13 ans et j'aime créer...</td>\n",
       "      <td>Je code depuis l'âge de 13 ans et j'aime créer...</td>\n",
       "      <td>CV_1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>18.22</td>\n",
       "      <td>81.78</td>\n",
       "      <td>[True, True, True, False, True, True, False, T...</td>\n",
       "      <td>['PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RÉALISATIONS</td>\n",
       "      <td>RÉALISATIONS</td>\n",
       "      <td>CV_1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18.69</td>\n",
       "      <td>81.31</td>\n",
       "      <td>[True]</td>\n",
       "      <td>['NOUN']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        CV_Sentences  \\\n",
       "0         SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE   \n",
       "1                                             PROFIL   \n",
       "2    PERSONNEL Je suis étudiante au lycée Condorcet.   \n",
       "3  Je code depuis l'âge de 13 ans et j'aime créer...   \n",
       "4                                       RÉALISATIONS   \n",
       "\n",
       "                                  Sentences_CV_clean CV_Number  Sentence_line  \\\n",
       "0         SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE      CV_1              0   \n",
       "1                                             PROFIL      CV_1              1   \n",
       "2    PERSONNEL Je suis étudiante au lycée Condorcet.      CV_1              2   \n",
       "3  Je code depuis l'âge de 13 ans et j'aime créer...      CV_1              3   \n",
       "4                                       RÉALISATIONS      CV_1              4   \n",
       "\n",
       "   Nb_tokens  %texte_lu  %texte_lu_fin_ligne  \\\n",
       "0          6       2.80                97.20   \n",
       "1          1       3.27                96.73   \n",
       "2          8       7.01                92.99   \n",
       "3         24      18.22                81.78   \n",
       "4          1      18.69                81.31   \n",
       "\n",
       "                                            Is_alpha  \\\n",
       "0              [True, True, True, False, True, True]   \n",
       "1                                             [True]   \n",
       "2  [True, True, True, True, True, True, True, False]   \n",
       "3  [True, True, True, False, True, True, False, T...   \n",
       "4                                             [True]   \n",
       "\n",
       "                                             Grammar  Label  \n",
       "0  ['NOUN', 'PROPN', 'VERB', 'NUM', 'PROPN', 'PRO...      1  \n",
       "1                                           ['NOUN']      0  \n",
       "2  ['NOUN', 'PRON', 'AUX', 'ADJ', 'ADP', 'NOUN', ...      0  \n",
       "3  ['PRON', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', ...      0  \n",
       "4                                           ['NOUN']      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basics statistics: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV_Sentences</th>\n",
       "      <th>Sentences_CV_clean</th>\n",
       "      <th>CV_Number</th>\n",
       "      <th>Sentence_line</th>\n",
       "      <th>Nb_tokens</th>\n",
       "      <th>%texte_lu</th>\n",
       "      <th>%texte_lu_fin_ligne</th>\n",
       "      <th>Is_alpha</th>\n",
       "      <th>Grammar</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5594</td>\n",
       "      <td>5592</td>\n",
       "      <td>5594</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594.000000</td>\n",
       "      <td>5594</td>\n",
       "      <td>5594</td>\n",
       "      <td>5594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3805</td>\n",
       "      <td>3802</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1626</td>\n",
       "      <td>2748</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>CV_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[False]</td>\n",
       "      <td>['NOUN']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>66</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>638</td>\n",
       "      <td>334</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.673221</td>\n",
       "      <td>9.132285</td>\n",
       "      <td>50.470518</td>\n",
       "      <td>49.529483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.268076</td>\n",
       "      <td>10.914849</td>\n",
       "      <td>30.190027</td>\n",
       "      <td>30.190025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.190000</td>\n",
       "      <td>23.552500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>49.530000</td>\n",
       "      <td>50.470000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>76.447500</td>\n",
       "      <td>75.810000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>99.760000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CV_Sentences Sentences_CV_clean CV_Number  Sentence_line    Nb_tokens  \\\n",
       "count          5594               5592      5594    5594.000000  5594.000000   \n",
       "unique         3805               3802       200            NaN          NaN   \n",
       "top                                        CV_10            NaN          NaN   \n",
       "freq            198                198        66            NaN          NaN   \n",
       "mean            NaN                NaN       NaN      15.673221     9.132285   \n",
       "std             NaN                NaN       NaN      11.268076    10.914849   \n",
       "min             NaN                NaN       NaN       0.000000     1.000000   \n",
       "25%             NaN                NaN       NaN       7.000000     2.000000   \n",
       "50%             NaN                NaN       NaN      14.000000     5.000000   \n",
       "75%             NaN                NaN       NaN      23.000000    12.000000   \n",
       "max             NaN                NaN       NaN      65.000000   124.000000   \n",
       "\n",
       "          %texte_lu  %texte_lu_fin_ligne Is_alpha   Grammar        Label  \n",
       "count   5594.000000          5594.000000     5594      5594  5594.000000  \n",
       "unique          NaN                  NaN     1626      2748          NaN  \n",
       "top             NaN                  NaN  [False]  ['NOUN']          NaN  \n",
       "freq            NaN                  NaN      638       334          NaN  \n",
       "mean      50.470518            49.529483      NaN       NaN     0.037898  \n",
       "std       30.190027            30.190025      NaN       NaN     0.190966  \n",
       "min        0.240000             0.000000      NaN       NaN     0.000000  \n",
       "25%       24.190000            23.552500      NaN       NaN     0.000000  \n",
       "50%       49.530000            50.470000      NaN       NaN     0.000000  \n",
       "75%       76.447500            75.810000      NaN       NaN     0.000000  \n",
       "max      100.000000            99.760000      NaN       NaN     1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage of missing values: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CV_Sentences           0.000000\n",
       "Sentences_CV_clean     0.035753\n",
       "CV_Number              0.000000\n",
       "Sentence_line          0.000000\n",
       "Nb_tokens              0.000000\n",
       "%texte_lu              0.000000\n",
       "%texte_lu_fin_ligne    0.000000\n",
       "Is_alpha               0.000000\n",
       "Grammar                0.000000\n",
       "Label                  0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic stats\n",
    "print(\"Number of rows : {}\".format(dataset.shape[0]))\n",
    "print()\n",
    "\n",
    "print(\"Display of dataset: \")\n",
    "display(dataset.head())\n",
    "print()\n",
    "\n",
    "print(\"Basics statistics: \")\n",
    "data_desc = dataset.describe(include='all')\n",
    "display(data_desc)\n",
    "print()\n",
    "\n",
    "print(\"Percentage of missing values: \")\n",
    "display(100*dataset.isnull().sum()/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5416, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"Label\"].unique()\n",
    "dataset = dataset.loc[(dataset['CV_Sentences'] != \"#NOM?\"),:]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5412, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.loc[(dataset['CV_Sentences'] != \":\"),:]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5410, 10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.dropna(axis =0, how = 'any')\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CV_Sentences           0.0\n",
       "Sentences_CV_clean     0.0\n",
       "CV_Number              0.0\n",
       "Sentence_line          0.0\n",
       "Nb_tokens              0.0\n",
       "%texte_lu              0.0\n",
       "%texte_lu_fin_ligne    0.0\n",
       "Is_alpha               0.0\n",
       "Grammar                0.0\n",
       "Label                  0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(100*dataset.isnull().sum()/dataset.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating labels from features...\n",
      "...Done.\n",
      "\n",
      "Y : \n",
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Label, dtype: int64\n",
      "\n",
      "X :\n",
      "   Sentence_line  Nb_tokens  %texte_lu  %texte_lu_fin_ligne\n",
      "0              0          6       2.80                97.20\n",
      "1              1          1       3.27                96.73\n",
      "2              2          8       7.01                92.99\n",
      "3              3         24      18.22                81.78\n",
      "4              4          1      18.69                81.31\n"
     ]
    }
   ],
   "source": [
    "# Separate target variable Y from features X\n",
    "print(\"Separating labels from features...\")\n",
    "features_list = [\"CV_Sentences\",\"Sentences_CV_clean\",\"CV_Number\", \"Is_alpha\", \"Grammar\", \"Label\"]\n",
    "target_variable = \"Label\"\n",
    "\n",
    "X = dataset.drop(features_list, axis = 1)\n",
    "Y = dataset.loc[:,target_variable]\n",
    "\n",
    "print(\"...Done.\")\n",
    "print()\n",
    "\n",
    "print('Y : ')\n",
    "print(Y.head())\n",
    "print()\n",
    "print('X :')\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found numeric features  ['Sentence_line', 'Nb_tokens', '%texte_lu', '%texte_lu_fin_ligne']  at positions  [0, 1, 2, 3]\n",
      "Found categorical features  []  at positions  []\n"
     ]
    }
   ],
   "source": [
    "# Automatically detect positions of numeric/categorical features\n",
    "idx = 0\n",
    "numeric_features = []\n",
    "numeric_indices = []\n",
    "categorical_features = []\n",
    "categorical_indices = []\n",
    "for i,t in X.dtypes.iteritems():\n",
    "    if ('float' in str(t)) or ('int' in str(t)) :\n",
    "        numeric_features.append(i)\n",
    "        numeric_indices.append(idx)\n",
    "    else :\n",
    "        categorical_features.append(i)\n",
    "        categorical_indices.append(idx)\n",
    "\n",
    "    idx = idx + 1\n",
    "\n",
    "print('Found numeric features ', numeric_features,' at positions ', numeric_indices)\n",
    "print('Found categorical features ', categorical_features,' at positions ', categorical_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing into train and test sets...\n",
      "...Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Divide dataset Train set & Test set \n",
    "print(\"Dividing into train and test sets...\")\n",
    "# WARNING : don't forget stratify=Y for classification problems\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify = Y)\n",
    "print(\"...Done.\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert pandas DataFrames to numpy arrays...\n",
      "...Done\n",
      "[[25.    1.   45.85 54.15]\n",
      " [14.    6.   76.08 23.92]\n",
      " [17.    3.   47.06 52.94]\n",
      " [11.    1.   27.   73.  ]\n",
      " [ 6.    9.   20.78 79.22]]\n",
      "[[ 3.   15.   35.22 64.78]\n",
      " [13.    2.   36.42 63.58]]\n",
      "\n",
      "[0, 0, 0, 0, 0]\n",
      "[0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert pandas DataFrames to numpy arrays before using scikit-learn\n",
    "print(\"Convert pandas DataFrames to numpy arrays...\")\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "Y_train = Y_train.tolist()\n",
    "Y_test = Y_test.tolist()\n",
    "print(\"...Done\")\n",
    "\n",
    "print(X_train[0:5,:])\n",
    "print(X_test[0:2,:])\n",
    "print()\n",
    "print(Y_train[0:5])\n",
    "print(Y_test[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values...\n",
      "[[25.    1.   45.85 54.15]\n",
      " [14.    6.   76.08 23.92]\n",
      " [17.    3.   47.06 52.94]\n",
      " [11.    1.   27.   73.  ]\n",
      " [ 6.    9.   20.78 79.22]]\n",
      "\n",
      "...Done!\n",
      "[[25.    1.   45.85 54.15]\n",
      " [14.    6.   76.08 23.92]\n",
      " [17.    3.   47.06 52.94]\n",
      " [11.    1.   27.   73.  ]\n",
      " [ 6.    9.   20.78 79.22]]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "\n",
      "[[25.    1.   45.85 54.15]\n",
      " [14.    6.   76.08 23.92]\n",
      " [17.    3.   47.06 52.94]\n",
      " [11.    1.   27.   73.  ]\n",
      " [ 6.    9.   20.78 79.22]]\n",
      "...Done\n",
      "[[ 0.84941168 -0.74490809 -0.14998016  0.14998009]\n",
      " [-0.13204091 -0.30377703  0.8477846  -0.84778473]\n",
      " [ 0.13562797 -0.56845567 -0.11004316  0.1100431 ]\n",
      " [-0.3997098  -0.74490809 -0.77213913  0.7721391 ]\n",
      " [-0.84582462 -0.0390984  -0.97743509  0.97743507]]\n",
      "Encoding labels...\n",
      "[0, 0, 0, 0, 0]\n",
      "...Done\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "print(\"Imputing missing values...\")\n",
    "print(X_train[0:5,:])\n",
    "print()\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train[:,numeric_indices] = imputer.fit_transform(X_train[:,numeric_indices])\n",
    "print(\"...Done!\")\n",
    "print(X_train[0:5,:]) \n",
    "print() \n",
    "\n",
    "# Encoding categorical features and standardizing numerical features\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "print()\n",
    "print(X_train[0:5,:])\n",
    "\n",
    "# Normalization\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# OHE / dummyfication\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "featureencoder = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_indices),    \n",
    "        ('num', numeric_transformer, numeric_indices)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "X_train = featureencoder.fit_transform(X_train)\n",
    "print(\"...Done\")\n",
    "print(X_train[0:5,:])\n",
    "\n",
    "# Label encoding\n",
    "print(\"Encoding labels...\")\n",
    "print(Y_train[0:5])\n",
    "encoder = LabelEncoder()\n",
    "Y_train = encoder.fit_transform(Y_train)\n",
    "print(\"...Done\")\n",
    "print(Y_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model...\n",
      "...Done.\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train model...\")\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, Y_train)\n",
    "print(\"...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on training set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on training set\n",
    "print(\"Predictions on training set...\")\n",
    "Y_train_pred = classifier.predict(X_train)\n",
    "print(\"...Done.\")\n",
    "print(Y_train_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values...\n",
      "[[ 3.   15.   35.22 64.78]\n",
      " [13.    2.   36.42 63.58]\n",
      " [26.    3.   73.29 26.71]\n",
      " [ 5.    3.   46.59 53.41]\n",
      " [20.    9.   99.46  0.54]]\n",
      "...Done!\n",
      "[[ 3.   15.   35.22 64.78]\n",
      " [13.    2.   36.42 63.58]\n",
      " [26.    3.   73.29 26.71]\n",
      " [ 5.    3.   46.59 53.41]\n",
      " [20.    9.   99.46  0.54]]\n",
      "\n",
      "Encoding categorical features and standardizing numerical features...\n",
      "[[ 3.   15.   35.22 64.78]\n",
      " [13.    2.   36.42 63.58]\n",
      " [26.    3.   73.29 26.71]\n",
      " [ 5.    3.   46.59 53.41]\n",
      " [20.    9.   99.46  0.54]]\n",
      "...Done\n",
      "[[-1.1134935   0.49025887 -0.50083161  0.50083157]\n",
      " [-0.22126388 -0.65668188 -0.46122467  0.46122463]\n",
      " [ 0.93863464 -0.56845567  0.75569847 -0.75569859]\n",
      " [-0.93504758 -0.56845567 -0.12555588  0.12555581]\n",
      " [ 0.40329686 -0.0390984   1.61945976 -1.61945993]]\n",
      "Encoding labels...\n",
      "[0, 0, 0, 0, 0]\n",
      "...Done\n",
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Missing values\n",
    "print(\"Imputing missing values...\")\n",
    "print(X_test[0:5,:])\n",
    "X_test[:,numeric_indices] = imputer.transform(X_test[:,numeric_indices])\n",
    "print(\"...Done!\")\n",
    "print(X_test[0:5,:]) \n",
    "print() \n",
    "\n",
    "# Encoding categorical features and standardizing numerical features\n",
    "print(\"Encoding categorical features and standardizing numerical features...\")\n",
    "print(X_test[0:5,:])\n",
    "X_test = featureencoder.transform(X_test)\n",
    "print(\"...Done\")\n",
    "print(X_test[0:5,:])\n",
    "\n",
    "# Label encoding\n",
    "print(\"Encoding labels...\")\n",
    "print(Y_test[0:5])\n",
    "Y_test = encoder.transform(Y_test)\n",
    "print(\"...Done\")\n",
    "print(Y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on test set...\n",
      "...Done.\n",
      "[0 0 0 ... 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions on test set\n",
    "print(\"Predictions on test set...\")\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"...Done.\")\n",
    "print(Y_test_pred)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set :  0.960720887245841\n",
      "accuracy on test set :  0.9611829944547134\n",
      "\n",
      "f1-score on training set :  0.0\n",
      "f1-score on test set :  0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print scores\n",
    "print(\"accuracy on training set : \", accuracy_score(Y_train, Y_train_pred))\n",
    "print(\"accuracy on test set : \", accuracy_score(Y_test, Y_test_pred))\n",
    "print()\n",
    "\n",
    "print(\"f1-score on training set : \", f1_score(Y_train, Y_train_pred))                                            ## ATTENTION REVOIR F1-SCORE\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "train",
         "type": "scatter",
         "x": [
          0,
          0.0058823529411764705,
          0.0058823529411764705,
          0.0058823529411764705,
          0.0058823529411764705,
          0.01764705882352941,
          0.023529411764705882,
          0.023529411764705882,
          0.023529411764705882,
          0.03529411764705882,
          0.03529411764705882,
          0.041176470588235294,
          0.041176470588235294,
          0.052941176470588235,
          0.058823529411764705,
          0.058823529411764705,
          0.06470588235294118,
          0.06470588235294118,
          0.07058823529411765,
          0.07058823529411765,
          0.07647058823529412,
          0.1,
          0.10588235294117647,
          0.10588235294117647,
          0.11176470588235295,
          0.11176470588235295,
          0.11764705882352941,
          0.12352941176470589,
          0.13529411764705881,
          0.13529411764705881,
          0.1411764705882353,
          0.16470588235294117,
          0.16470588235294117,
          0.17058823529411765,
          0.18235294117647058,
          0.18823529411764706,
          0.18823529411764706,
          0.2,
          0.2,
          0.21176470588235294,
          0.21176470588235294,
          0.21764705882352942,
          0.21764705882352942,
          0.2235294117647059,
          0.2235294117647059,
          0.24705882352941178,
          0.24705882352941178,
          0.2647058823529412,
          0.2647058823529412,
          0.27647058823529413,
          0.27647058823529413,
          0.2823529411764706,
          0.2823529411764706,
          0.28823529411764703,
          0.29411764705882354,
          0.3058823529411765,
          0.3058823529411765,
          0.3235294117647059,
          0.3235294117647059,
          0.3352941176470588,
          0.3411764705882353,
          0.3411764705882353,
          0.34705882352941175,
          0.34705882352941175,
          0.37058823529411766,
          0.37058823529411766,
          0.38823529411764707,
          0.4,
          0.4176470588235294,
          0.4176470588235294,
          0.4235294117647059,
          0.4235294117647059,
          0.4470588235294118,
          0.4470588235294118,
          0.4823529411764706,
          0.4823529411764706,
          0.49411764705882355,
          0.49411764705882355,
          0.5176470588235295,
          0.5176470588235295,
          0.5294117647058824,
          0.5294117647058824,
          0.5411764705882353,
          0.5411764705882353,
          0.5470588235294118,
          0.5470588235294118,
          0.5529411764705883,
          0.5529411764705883,
          0.5529411764705883,
          0.5529411764705883,
          0.5529411764705883,
          0.5647058823529412,
          0.5647058823529412,
          0.5647058823529412,
          0.5647058823529412,
          0.5764705882352941,
          0.5764705882352941,
          0.5882352941176471,
          0.5882352941176471,
          0.5882352941176471,
          0.5882352941176471,
          0.5941176470588235,
          0.5941176470588235,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6,
          0.6058823529411764,
          0.6058823529411764,
          0.6058823529411764,
          0.6058823529411764,
          0.6058823529411764,
          0.6058823529411764,
          0.6176470588235294,
          0.6176470588235294,
          0.6176470588235294,
          0.6176470588235294,
          0.6294117647058823,
          0.6294117647058823,
          0.6352941176470588,
          0.6352941176470588,
          0.6411764705882353,
          0.6411764705882353,
          0.6411764705882353,
          0.6411764705882353,
          0.6411764705882353,
          0.6411764705882353,
          0.6470588235294118,
          0.6470588235294118,
          0.6529411764705882,
          0.6529411764705882,
          0.6588235294117647,
          0.6588235294117647,
          0.6647058823529411,
          0.6647058823529411,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6705882352941176,
          0.6764705882352942,
          0.6764705882352942,
          0.6764705882352942,
          0.6764705882352942,
          0.6823529411764706,
          0.6823529411764706,
          0.6882352941176471,
          0.6882352941176471,
          0.6941176470588235,
          0.6941176470588235,
          0.6941176470588235,
          0.6941176470588235,
          0.6941176470588235,
          0.6941176470588235,
          0.6941176470588235,
          0.6941176470588235,
          0.7,
          0.7,
          0.7,
          0.7,
          0.7058823529411765,
          0.7058823529411765,
          0.7058823529411765,
          0.7058823529411765,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.711764705882353,
          0.7176470588235294,
          0.7176470588235294,
          0.7235294117647059,
          0.7235294117647059,
          0.7294117647058823,
          0.7294117647058823,
          0.7352941176470589,
          0.7352941176470589,
          0.7352941176470589,
          0.7352941176470589,
          0.7352941176470589,
          0.7352941176470589,
          0.7411764705882353,
          0.7411764705882353,
          0.7411764705882353,
          0.7411764705882353,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7470588235294118,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7529411764705882,
          0.7588235294117647,
          0.7588235294117647,
          0.7588235294117647,
          0.7588235294117647,
          0.7588235294117647,
          0.7588235294117647,
          0.7588235294117647,
          0.7588235294117647,
          0.7647058823529411,
          0.7647058823529411,
          0.7647058823529411,
          0.7647058823529411,
          0.7647058823529411,
          0.7647058823529411,
          0.7647058823529411,
          0.7647058823529411,
          0.7705882352941177,
          0.7705882352941177,
          0.7705882352941177,
          0.7705882352941177,
          0.7764705882352941,
          0.7764705882352941,
          0.7764705882352941,
          0.7764705882352941,
          0.7823529411764706,
          0.7823529411764706,
          0.7823529411764706,
          0.788235294117647,
          0.788235294117647,
          0.788235294117647,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.7941176470588235,
          0.8058823529411765,
          0.8058823529411765,
          0.8058823529411765,
          0.8058823529411765,
          0.8176470588235294,
          0.8176470588235294,
          0.8235294117647058,
          0.8235294117647058,
          0.8235294117647058,
          0.8235294117647058,
          0.8235294117647058,
          0.8235294117647058,
          0.8235294117647058,
          0.8235294117647058,
          0.8294117647058824,
          0.8294117647058824,
          0.8294117647058824,
          0.8294117647058824,
          0.8294117647058824,
          0.8352941176470589,
          0.8352941176470589,
          0.8352941176470589,
          0.8352941176470589,
          0.8352941176470589,
          0.8352941176470589,
          0.8352941176470589,
          0.8352941176470589,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8411764705882353,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8470588235294118,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8529411764705882,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8588235294117647,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8647058823529412,
          0.8705882352941177,
          0.8705882352941177,
          0.8705882352941177,
          0.8764705882352941,
          0.8764705882352941,
          0.8764705882352941,
          0.8764705882352941,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.8823529411764706,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.888235294117647,
          0.8941176470588236,
          0.8941176470588236,
          0.8941176470588236,
          0.8941176470588236,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9058823529411765,
          0.9117647058823529,
          0.9117647058823529,
          0.9117647058823529,
          0.9117647058823529,
          0.9117647058823529,
          0.9117647058823529,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9235294117647059,
          0.9352941176470588,
          0.9352941176470588,
          0.9352941176470588,
          0.9352941176470588,
          0.9352941176470588,
          0.9352941176470588,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9411764705882353,
          0.9470588235294117,
          0.9470588235294117,
          0.9529411764705882,
          0.9529411764705882,
          0.9529411764705882,
          0.9529411764705882,
          0.9529411764705882,
          0.9529411764705882,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9588235294117647,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9647058823529412,
          0.9705882352941176,
          0.9705882352941176,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9764705882352941,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9823529411764705,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9882352941176471,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          0.9941176470588236,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1
         ],
         "y": [
          0,
          0,
          0.000481000481000481,
          0.000962000962000962,
          0.0012025012025012026,
          0.0012025012025012026,
          0.0016835016835016834,
          0.001924001924001924,
          0.002405002405002405,
          0.002405002405002405,
          0.0031265031265031266,
          0.0031265031265031266,
          0.0036075036075036075,
          0.0036075036075036075,
          0.003848003848003848,
          0.004329004329004329,
          0.004329004329004329,
          0.00456950456950457,
          0.00456950456950457,
          0.00481000481000481,
          0.00481000481000481,
          0.00481000481000481,
          0.00481000481000481,
          0.005050505050505051,
          0.005050505050505051,
          0.005291005291005291,
          0.005772005772005772,
          0.005772005772005772,
          0.005772005772005772,
          0.006493506493506494,
          0.006493506493506494,
          0.006493506493506494,
          0.006734006734006734,
          0.006734006734006734,
          0.006734006734006734,
          0.006734006734006734,
          0.006974506974506974,
          0.006974506974506974,
          0.007215007215007215,
          0.007215007215007215,
          0.007696007696007696,
          0.007696007696007696,
          0.007936507936507936,
          0.007936507936507936,
          0.008177008177008177,
          0.008177008177008177,
          0.008417508417508417,
          0.008417508417508417,
          0.008658008658008658,
          0.008658008658008658,
          0.008898508898508899,
          0.008898508898508899,
          0.00913900913900914,
          0.00913900913900914,
          0.00937950937950938,
          0.00937950937950938,
          0.00962000962000962,
          0.00962000962000962,
          0.010101010101010102,
          0.010101010101010102,
          0.010101010101010102,
          0.01034151034151034,
          0.01034151034151034,
          0.010822510822510822,
          0.010822510822510822,
          0.011303511303511303,
          0.011303511303511303,
          0.011303511303511303,
          0.011303511303511303,
          0.011544011544011544,
          0.011544011544011544,
          0.012025012025012025,
          0.012025012025012025,
          0.012265512265512266,
          0.012265512265512266,
          0.012987012987012988,
          0.012987012987012988,
          0.013468013468013467,
          0.013468013468013467,
          0.013708513708513708,
          0.013708513708513708,
          0.01418951418951419,
          0.01418951418951419,
          0.016594516594516596,
          0.016594516594516596,
          0.017075517075517077,
          0.017075517075517077,
          0.017797017797017797,
          0.018518518518518517,
          0.020202020202020204,
          0.02068302068302068,
          0.02068302068302068,
          0.022366522366522368,
          0.023088023088023088,
          0.02356902356902357,
          0.02356902356902357,
          0.023809523809523808,
          0.023809523809523808,
          0.02405002405002405,
          0.024531024531024532,
          0.025493025493025494,
          0.025493025493025494,
          0.026455026455026454,
          0.026455026455026454,
          0.027898027898027897,
          0.02837902837902838,
          0.02861952861952862,
          0.0291005291005291,
          0.0291005291005291,
          0.030543530543530543,
          0.031024531024531024,
          0.03294853294853295,
          0.03367003367003367,
          0.034151034151034154,
          0.034151034151034154,
          0.034872534872534874,
          0.03535353535353535,
          0.037037037037037035,
          0.037037037037037035,
          0.03727753727753728,
          0.03727753727753728,
          0.03992303992303992,
          0.03992303992303992,
          0.04136604136604136,
          0.04184704184704185,
          0.04329004329004329,
          0.04401154401154401,
          0.044733044733044736,
          0.044733044733044736,
          0.04497354497354497,
          0.04497354497354497,
          0.045454545454545456,
          0.045454545454545456,
          0.045935545935545934,
          0.045935545935545934,
          0.04785954785954786,
          0.04785954785954786,
          0.04882154882154882,
          0.0493025493025493,
          0.050024050024050026,
          0.050505050505050504,
          0.05098605098605099,
          0.05146705146705147,
          0.05170755170755171,
          0.05218855218855219,
          0.0545935545935546,
          0.0545935545935546,
          0.05723905723905724,
          0.0582010582010582,
          0.0594035594035594,
          0.0594035594035594,
          0.06228956228956229,
          0.06228956228956229,
          0.06277056277056277,
          0.06277056277056277,
          0.06373256373256374,
          0.06421356421356421,
          0.06565656565656566,
          0.06613756613756613,
          0.06830206830206831,
          0.06878306878306878,
          0.06926406926406926,
          0.06926406926406926,
          0.07575757575757576,
          0.07623857623857624,
          0.08465608465608465,
          0.08465608465608465,
          0.08682058682058683,
          0.0873015873015873,
          0.08754208754208755,
          0.08754208754208755,
          0.09018759018759019,
          0.09066859066859066,
          0.094997594997595,
          0.09547859547859548,
          0.09644059644059644,
          0.09740259740259741,
          0.09932659932659933,
          0.0998075998075998,
          0.10293410293410293,
          0.10341510341510342,
          0.10461760461760462,
          0.10557960557960558,
          0.1063011063011063,
          0.10678210678210678,
          0.10702260702260702,
          0.10702260702260702,
          0.10942760942760943,
          0.10942760942760943,
          0.11135161135161135,
          0.11135161135161135,
          0.11303511303511303,
          0.11303511303511303,
          0.11808561808561809,
          0.11856661856661857,
          0.12385762385762386,
          0.12433862433862433,
          0.12457912457912458,
          0.12457912457912458,
          0.12866762866762868,
          0.12914862914862915,
          0.13035113035113036,
          0.13035113035113036,
          0.13107263107263106,
          0.13203463203463203,
          0.1325156325156325,
          0.132996632996633,
          0.13516113516113515,
          0.13564213564213565,
          0.13732563732563732,
          0.1378066378066378,
          0.13997113997113997,
          0.14045214045214044,
          0.14213564213564214,
          0.1426166426166426,
          0.14405964405964405,
          0.1443001443001443,
          0.14454064454064455,
          0.14502164502164502,
          0.14526214526214526,
          0.14574314574314573,
          0.14646464646464646,
          0.1471861471861472,
          0.14886964886964887,
          0.14935064935064934,
          0.15175565175565175,
          0.15175565175565175,
          0.15824915824915825,
          0.15873015873015872,
          0.16017316017316016,
          0.1608946608946609,
          0.1620971620971621,
          0.16305916305916307,
          0.16378066378066378,
          0.16378066378066378,
          0.1645021645021645,
          0.16498316498316498,
          0.17412217412217412,
          0.1746031746031746,
          0.17724867724867724,
          0.17772967772967774,
          0.1815776815776816,
          0.1815776815776816,
          0.18374218374218373,
          0.18422318422318423,
          0.1847041847041847,
          0.1847041847041847,
          0.18542568542568544,
          0.1859066859066859,
          0.18686868686868688,
          0.18686868686868688,
          0.18710918710918711,
          0.18759018759018758,
          0.18759018759018758,
          0.18783068783068782,
          0.18831168831168832,
          0.18831168831168832,
          0.1936026936026936,
          0.19432419432419432,
          0.19600769600769602,
          0.1964886964886965,
          0.19672919672919673,
          0.1972101972101972,
          0.19865319865319866,
          0.19913419913419914,
          0.19937469937469937,
          0.19985569985569984,
          0.2012987012987013,
          0.20177970177970178,
          0.20226070226070225,
          0.20274170274170275,
          0.20514670514670516,
          0.20514670514670516,
          0.20562770562770563,
          0.2061087061087061,
          0.2130832130832131,
          0.2130832130832131,
          0.21356421356421357,
          0.21356421356421357,
          0.215007215007215,
          0.21548821548821548,
          0.21596921596921598,
          0.21645021645021645,
          0.22053872053872053,
          0.22101972101972103,
          0.22126022126022127,
          0.22126022126022127,
          0.2255892255892256,
          0.22607022607022606,
          0.2267917267917268,
          0.234006734006734,
          0.23424723424723426,
          0.23472823472823473,
          0.2352092352092352,
          0.23905723905723905,
          0.23953823953823955,
          0.24386724386724387,
          0.24482924482924484,
          0.24555074555074555,
          0.24555074555074555,
          0.24675324675324675,
          0.24723424723424722,
          0.24843674843674843,
          0.24891774891774893,
          0.2542087542087542,
          0.2546897546897547,
          0.2558922558922559,
          0.25637325637325636,
          0.2566137566137566,
          0.25685425685425683,
          0.2587782587782588,
          0.25925925925925924,
          0.2638287638287638,
          0.26430976430976433,
          0.2688792688792689,
          0.26936026936026936,
          0.27344877344877344,
          0.27441077441077444,
          0.2748917748917749,
          0.27585377585377585,
          0.278018278018278,
          0.2784992784992785,
          0.2809042809042809,
          0.2813852813852814,
          0.28643578643578643,
          0.2869167869167869,
          0.2893217893217893,
          0.2898027898027898,
          0.2905242905242905,
          0.291005291005291,
          0.297017797017797,
          0.2974987974987975,
          0.30038480038480037,
          0.3008658008658009,
          0.303992303992304,
          0.30447330447330445,
          0.30904280904280906,
          0.30904280904280906,
          0.3140933140933141,
          0.31457431457431456,
          0.3189033189033189,
          0.3193843193843194,
          0.3253968253968254,
          0.3258778258778259,
          0.3270803270803271,
          0.32756132756132755,
          0.33261183261183264,
          0.3330928330928331,
          0.33381433381433384,
          0.3347763347763348,
          0.335016835016835,
          0.335016835016835,
          0.33910533910533913,
          0.3395863395863396,
          0.34054834054834054,
          0.341029341029341,
          0.34295334295334295,
          0.3434343434343434,
          0.34463684463684463,
          0.3451178451178451,
          0.34535834535834536,
          0.34583934583934584,
          0.3487253487253487,
          0.3487253487253487,
          0.3513708513708514,
          0.35185185185185186,
          0.35233285233285233,
          0.3528138528138528,
          0.367003367003367,
          0.36796536796536794,
          0.3710918710918711,
          0.37157287157287155,
          0.3718133718133718,
          0.37277537277537276,
          0.37421837421837423,
          0.37493987493987496,
          0.38263588263588266,
          0.38311688311688313,
          0.3840788840788841,
          0.3840788840788841,
          0.3927368927368927,
          0.39321789321789324,
          0.39321789321789324,
          0.39345839345839345,
          0.3939393939393939,
          0.3961038961038961,
          0.3961038961038961,
          0.4001924001924002,
          0.4006734006734007,
          0.4016354016354016,
          0.4021164021164021,
          0.4054834054834055,
          0.40596440596440597,
          0.4066859066859067,
          0.4071669071669072,
          0.4098124098124098,
          0.4102934102934103,
          0.4126984126984127,
          0.4131794131794132,
          0.4134199134199134,
          0.4143819143819144,
          0.4148629148629149,
          0.4155844155844156,
          0.4160654160654161,
          0.4187109187109187,
          0.41919191919191917,
          0.42448292448292446,
          0.424963924963925,
          0.4316979316979317,
          0.4316979316979317,
          0.43217893217893216,
          0.43265993265993263,
          0.4329004329004329,
          0.4329004329004329,
          0.43338143338143337,
          0.43362193362193363,
          0.4341029341029341,
          0.4345839345839346,
          0.43506493506493504,
          0.44203944203944207,
          0.44252044252044254,
          0.4446849446849447,
          0.44516594516594515,
          0.4466089466089466,
          0.4470899470899471,
          0.44733044733044736,
          0.4478114478114478,
          0.4533429533429533,
          0.45406445406445406,
          0.4555074555074555,
          0.455988455988456,
          0.4595959595959596,
          0.4600769600769601,
          0.4612794612794613,
          0.46176046176046176,
          0.4627224627224627,
          0.46320346320346323,
          0.4675324675324675,
          0.468013468013468,
          0.4687349687349687,
          0.4692159692159692,
          0.4728234728234728,
          0.4742664742664743,
          0.47474747474747475,
          0.4752284752284752,
          0.4797979797979798,
          0.4802789802789803,
          0.481962481962482,
          0.48244348244348245,
          0.4874939874939875,
          0.48797498797498795,
          0.49446849446849445,
          0.494949494949495,
          0.4959114959114959,
          0.4963924963924964,
          0.49807599807599806,
          0.49903799903799906,
          0.49951899951899953,
          0.5,
          0.5012025012025012,
          0.5021645021645021,
          0.5161135161135161,
          0.5165945165945166,
          0.5168350168350169,
          0.5173160173160173,
          0.5211640211640212,
          0.5218855218855218,
          0.523088023088023,
          0.5235690235690236,
          0.5298220298220299,
          0.5307840307840308,
          0.532948532948533,
          0.5334295334295335,
          0.5343915343915344,
          0.5348725348725348,
          0.538961038961039,
          0.538961038961039,
          0.5425685425685426,
          0.543049543049543,
          0.5432900432900433,
          0.5437710437710438,
          0.544973544973545,
          0.5454545454545454,
          0.5464165464165465,
          0.5468975468975469,
          0.5488215488215489,
          0.5493025493025493,
          0.5502645502645502,
          0.5507455507455508,
          0.5536315536315536,
          0.5543530543530544,
          0.5553150553150553,
          0.5594035594035595,
          0.5598845598845599,
          0.5707070707070707,
          0.5716690716690717,
          0.5774410774410774,
          0.5774410774410774,
          0.5793650793650794,
          0.5798460798460798,
          0.5815295815295816,
          0.582010582010582,
          0.5873015873015873,
          0.5873015873015873,
          0.588023088023088,
          0.5885040885040885,
          0.5887445887445888,
          0.5892255892255892,
          0.5928330928330928,
          0.5933140933140933,
          0.5959595959595959,
          0.5964405964405964,
          0.5966810966810967,
          0.5971620971620971,
          0.5988455988455988,
          0.5993265993265994,
          0.6002886002886003,
          0.6007696007696007,
          0.6036556036556037,
          0.6041366041366041,
          0.6053391053391053,
          0.6058201058201058,
          0.6123136123136124,
          0.6123136123136124,
          0.6154401154401155,
          0.6159211159211159,
          0.6176046176046176,
          0.6180856180856181,
          0.6185666185666185,
          0.6185666185666185,
          0.620971620971621,
          0.6219336219336219,
          0.6233766233766234,
          0.6238576238576239,
          0.6253006253006252,
          0.6257816257816258,
          0.6274651274651275,
          0.6279461279461279,
          0.6375661375661376,
          0.6378066378066378,
          0.6421356421356421,
          0.6421356421356421,
          0.6445406445406445,
          0.645021645021645,
          0.6452621452621453,
          0.6457431457431457,
          0.6464646464646465,
          0.6464646464646465,
          0.6469456469456469,
          0.6476671476671476,
          0.6481481481481481,
          0.6512746512746512,
          0.6517556517556518,
          0.6534391534391535,
          0.6539201539201539,
          0.6599326599326599,
          0.6606541606541606,
          0.6618566618566618,
          0.6623376623376623,
          0.6628186628186629,
          0.6632996632996633,
          0.664983164983165,
          0.6654641654641654,
          0.6666666666666666,
          0.6666666666666666,
          0.6707551707551708,
          0.6712361712361712,
          0.6738816738816739,
          0.6743626743626744,
          0.677970177970178,
          0.6784511784511784,
          0.6815776815776816,
          0.682058682058682,
          0.6854256854256854,
          0.6859066859066859,
          0.6907166907166907,
          0.6911976911976911,
          0.6940836940836941,
          0.6945646945646946,
          0.7027417027417028,
          0.7032227032227032,
          0.7049062049062049,
          0.7053872053872053,
          0.7058682058682059,
          0.7063492063492064,
          0.7181337181337182,
          0.7186147186147186,
          0.721981721981722,
          0.7224627224627225,
          0.7241462241462241,
          0.7251082251082251,
          0.7282347282347282,
          0.7287157287157288,
          0.7301587301587301,
          0.7301587301587301,
          0.7303992303992304,
          0.7303992303992304,
          0.7366522366522367,
          0.7371332371332371,
          0.7395382395382395,
          0.74001924001924,
          0.7417027417027418,
          0.7421837421837422,
          0.7445887445887446,
          0.7450697450697451,
          0.746031746031746,
          0.7465127465127465,
          0.7465127465127465,
          0.7474747474747475,
          0.7479557479557479,
          0.7484367484367485,
          0.7489177489177489,
          0.7493987493987494,
          0.7498797498797499,
          0.7513227513227513,
          0.7522847522847523,
          0.757094757094757,
          0.7575757575757576,
          0.7585377585377585,
          0.759018759018759,
          0.7650312650312651,
          0.7655122655122655,
          0.766955266955267,
          0.7674362674362675,
          0.7676767676767676,
          0.7681577681577682,
          0.7703222703222703,
          0.7708032708032708,
          0.7717652717652718,
          0.7722462722462723,
          0.772967772967773,
          0.7734487734487735,
          0.7753727753727754,
          0.7758537758537759,
          0.7794612794612794,
          0.7799422799422799,
          0.7818662818662818,
          0.7823472823472823,
          0.784992784992785,
          0.785954785954786,
          0.7864357864357865,
          0.7917267917267917,
          0.7922077922077922,
          0.7948532948532948,
          0.7953342953342953,
          0.797979797979798,
          0.798941798941799,
          0.8051948051948052,
          0.8056758056758057,
          0.8095238095238095,
          0.81000481000481,
          0.8102453102453102,
          0.8107263107263107,
          0.810966810966811,
          0.8114478114478114,
          0.8116883116883117,
          0.8121693121693122,
          0.816017316017316,
          0.816979316979317,
          0.8222703222703223,
          0.8227513227513228,
          0.8237133237133237,
          0.8241943241943241,
          0.8318903318903319,
          0.8323713323713323,
          0.8367003367003367,
          0.8371813371813371,
          0.8427128427128427,
          0.8431938431938432,
          0.8441558441558441,
          0.8446368446368446,
          0.8475228475228476,
          0.848003848003848,
          0.8511303511303512,
          0.8516113516113516,
          0.8552188552188552,
          0.8556998556998557,
          0.8569023569023569,
          0.8573833573833574,
          0.8581048581048581,
          0.8585858585858586,
          0.8602693602693603,
          0.8602693602693603,
          0.8621933621933622,
          0.8626743626743627,
          0.8645983645983646,
          0.8650793650793651,
          0.8665223665223665,
          0.867003367003367,
          0.8689273689273689,
          0.8694083694083694,
          0.8763828763828764,
          0.8768638768638769,
          0.8807118807118807,
          0.8811928811928812,
          0.8823953823953824,
          0.8831168831168831,
          0.8855218855218855,
          0.886002886002886,
          0.8886483886483887,
          0.8891293891293891,
          0.8893698893698894,
          0.8898508898508899,
          0.8922558922558923,
          0.8927368927368927,
          0.8949013949013949,
          0.8953823953823954,
          0.8980278980278981,
          0.8985088985088985,
          0.8987493987493987,
          0.8992303992303993,
          0.9023569023569024,
          0.9028379028379029,
          0.905964405964406,
          0.9064454064454065,
          0.9095719095719096,
          0.91005291005291,
          0.9102934102934103,
          0.9102934102934103,
          0.9105339105339105,
          0.911014911014911,
          0.9129389129389129,
          0.9129389129389129,
          0.9172679172679172,
          0.9177489177489178,
          0.9194324194324194,
          0.9199134199134199,
          0.9203944203944204,
          0.9208754208754208,
          0.9285714285714286,
          0.929052429052429,
          0.9307359307359307,
          0.9312169312169312,
          0.931938431938432,
          0.9324194324194324,
          0.9415584415584416,
          0.942039442039442,
          0.944925444925445,
          0.9454064454064454,
          0.948051948051948,
          0.9485329485329486,
          0.9516594516594516,
          0.9521404521404522,
          0.9528619528619529,
          0.9533429533429534,
          0.9538239538239538,
          0.9543049543049543,
          0.9605579605579606,
          0.9615199615199616,
          0.9665704665704665,
          0.967051467051467,
          0.9713804713804713,
          0.9718614718614719,
          0.9721019721019721,
          0.9725829725829725,
          0.9745069745069745,
          0.974987974987975,
          0.9752284752284752,
          0.9761904761904762,
          0.9797979797979798,
          0.9802789802789803,
          0.9822029822029822,
          0.9826839826839827,
          0.982924482924483,
          0.9834054834054834,
          0.9846079846079846,
          0.9850889850889851,
          0.9867724867724867,
          0.9872534872534873,
          0.9877344877344877,
          0.9882154882154882,
          0.9901394901394901,
          0.9906204906204906,
          1
         ]
        },
        {
         "mode": "lines",
         "name": "test",
         "type": "scatter",
         "x": [
          0,
          0.023809523809523808,
          0.07142857142857142,
          0.07142857142857142,
          0.09523809523809523,
          0.09523809523809523,
          0.11904761904761904,
          0.11904761904761904,
          0.19047619047619047,
          0.19047619047619047,
          0.2857142857142857,
          0.2857142857142857,
          0.38095238095238093,
          0.38095238095238093,
          0.40476190476190477,
          0.40476190476190477,
          0.47619047619047616,
          0.5,
          0.5476190476190477,
          0.5476190476190477,
          0.5714285714285714,
          0.5714285714285714,
          0.5714285714285714,
          0.5714285714285714,
          0.5714285714285714,
          0.5714285714285714,
          0.5952380952380952,
          0.5952380952380952,
          0.6428571428571429,
          0.6428571428571429,
          0.6666666666666666,
          0.6666666666666666,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.6904761904761905,
          0.7142857142857143,
          0.7142857142857143,
          0.7142857142857143,
          0.7142857142857143,
          0.7380952380952381,
          0.7380952380952381,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7619047619047619,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.7857142857142857,
          0.8095238095238095,
          0.8095238095238095,
          0.8333333333333334,
          0.8333333333333334,
          0.8333333333333334,
          0.8333333333333334,
          0.8571428571428571,
          0.8571428571428571,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.8809523809523809,
          0.9047619047619048,
          0.9047619047619048,
          0.9047619047619048,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9285714285714286,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9523809523809523,
          0.9761904761904762,
          0.9761904761904762,
          1,
          1,
          1,
          1
         ],
         "y": [
          0,
          0.0028846153846153848,
          0.0028846153846153848,
          0.0057692307692307696,
          0.0057692307692307696,
          0.006730769230769231,
          0.006730769230769231,
          0.007692307692307693,
          0.007692307692307693,
          0.008653846153846154,
          0.008653846153846154,
          0.011538461538461539,
          0.011538461538461539,
          0.0125,
          0.0125,
          0.014423076923076924,
          0.014423076923076924,
          0.015384615384615385,
          0.015384615384615385,
          0.021153846153846155,
          0.021153846153846155,
          0.025961538461538463,
          0.027884615384615386,
          0.04230769230769231,
          0.04423076923076923,
          0.05576923076923077,
          0.05576923076923077,
          0.05961538461538462,
          0.05961538461538462,
          0.0625,
          0.0625,
          0.07403846153846154,
          0.07403846153846154,
          0.09326923076923077,
          0.09519230769230769,
          0.11634615384615385,
          0.11826923076923077,
          0.15576923076923077,
          0.15576923076923077,
          0.1596153846153846,
          0.16153846153846155,
          0.17115384615384616,
          0.17115384615384616,
          0.2048076923076923,
          0.2048076923076923,
          0.20865384615384616,
          0.21057692307692308,
          0.24903846153846154,
          0.25096153846153846,
          0.2673076923076923,
          0.2692307692307692,
          0.3346153846153846,
          0.33653846153846156,
          0.3471153846153846,
          0.3490384615384615,
          0.35192307692307695,
          0.35384615384615387,
          0.35673076923076924,
          0.35673076923076924,
          0.39326923076923076,
          0.3951923076923077,
          0.4721153846153846,
          0.4721153846153846,
          0.5048076923076923,
          0.5048076923076923,
          0.5076923076923077,
          0.5096153846153846,
          0.5230769230769231,
          0.5230769230769231,
          0.5278846153846154,
          0.5278846153846154,
          0.5576923076923077,
          0.5596153846153846,
          0.5807692307692308,
          0.5826923076923077,
          0.6163461538461539,
          0.6182692307692308,
          0.6471153846153846,
          0.6480769230769231,
          0.65,
          0.6538461538461539,
          0.6538461538461539,
          0.6730769230769231,
          0.675,
          0.6971153846153846,
          0.6971153846153846,
          0.7192307692307692,
          0.7211538461538461,
          0.864423076923077,
          0.8682692307692308,
          0.8769230769230769,
          0.8788461538461538,
          0.9173076923076923,
          0.9192307692307692,
          0.9384615384615385,
          0.9384615384615385,
          0.9769230769230769,
          0.9769230769230769,
          0.9903846153846154,
          0.9923076923076923,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROC curve",
         "x": 0.5
        },
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize ROC curves\n",
    "probas_train = classifier.predict_proba(X_train)[:,1]\n",
    "precisions, recalls, thresholds = roc_curve(Y_train, probas_train)\n",
    "fig = go.Figure(\n",
    "    data = go.Scatter(\n",
    "        name = 'train',\n",
    "        x = recalls, \n",
    "        y = precisions, \n",
    "        mode = 'lines'\n",
    "    ),\n",
    "    layout = go.Layout(\n",
    "        title = go.layout.Title(text = \"ROC curve\", x = 0.5),\n",
    "        xaxis = go.layout.XAxis(title = 'False Positive Rate'),\n",
    "        yaxis = go.layout.YAxis(title = 'True Positive Rate')\n",
    "    )\n",
    ")\n",
    "\n",
    "probas_test = classifier.predict_proba(X_test)[:,1]\n",
    "precisions, recalls, thresholds = roc_curve(Y_test, probas_test)\n",
    "fig.add_trace(go.Scatter(\n",
    "    name = 'test',\n",
    "    x = recalls, \n",
    "    y = precisions, \n",
    "    mode = 'lines'\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
