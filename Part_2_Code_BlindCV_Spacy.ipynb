{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - BlindCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement de la part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des librairies nécessaires\n",
    "import pandas as pd\n",
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 4,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la dataset\n",
    "dataset = pd.read_csv(\"dataset_CV.csv\", delimiter = \";\")\n",
    "\n",
    "# Instanciation de la bibliothèque fr_core_news_lg de Spacy\n",
    "nlp = spacy.load(\"fr_core_news_lg\")\n",
    "\n",
    "# Tokenization des textes de CV\n",
    "dataset[\"Tokenization_preparation\"] = dataset[\"CV_text\"].apply(lambda x : str(x).replace(\"\\n\", \" \"))\n",
    "dataset[\"Tokenization\"] = dataset[\"Tokenization_preparation\"].apply(lambda x : nlp(x))\n",
    "dataset[\"Number_of_tokens\"] = dataset[\"Tokenization\"].apply(lambda x : len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Process NLP avec Spacy"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = dataset.iloc[0,2]\n",
    "doc = nlp(doc)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " '_bulk_merge',\n",
       " '_context',\n",
       " '_get_array_attrs',\n",
       " '_realloc',\n",
       " '_vector',\n",
       " '_vector_norm',\n",
       " 'cats',\n",
       " 'char_span',\n",
       " 'copy',\n",
       " 'count_by',\n",
       " 'doc',\n",
       " 'ents',\n",
       " 'extend_tensor',\n",
       " 'from_array',\n",
       " 'from_bytes',\n",
       " 'from_dict',\n",
       " 'from_disk',\n",
       " 'from_docs',\n",
       " 'from_json',\n",
       " 'get_extension',\n",
       " 'get_lca_matrix',\n",
       " 'has_annotation',\n",
       " 'has_extension',\n",
       " 'has_unknown_spaces',\n",
       " 'has_vector',\n",
       " 'is_nered',\n",
       " 'is_parsed',\n",
       " 'is_sentenced',\n",
       " 'is_tagged',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'mem',\n",
       " 'noun_chunks',\n",
       " 'noun_chunks_iterator',\n",
       " 'remove_extension',\n",
       " 'retokenize',\n",
       " 'sentiment',\n",
       " 'sents',\n",
       " 'set_ents',\n",
       " 'set_extension',\n",
       " 'similarity',\n",
       " 'spans',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'to_array',\n",
       " 'to_bytes',\n",
       " 'to_dict',\n",
       " 'to_disk',\n",
       " 'to_json',\n",
       " 'to_utf8_array',\n",
       " 'user_data',\n",
       " 'user_hooks',\n",
       " 'user_span_hooks',\n",
       " 'user_token_hooks',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
=======
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE\n",
      "PROFIL\n",
      "PERSONNEL Je suis étudiante au lycée Condorcet.\n",
      "Je code depuis l'âge de 13 ans et j'aime créer des sites Web et utiliser la technologie pour aider les gens.\n",
      "RÉALISATIONS\n",
      "Chef d'équipe du site Web du lycée\n",
      "-\n",
      "Vice-présidente du club cinématographique du lycée\n",
      "- Trésorière de la société des codeurs du lycée -\n",
      "Premier prix au Hackathon de Condorcet EXPÉRIENCE Tuteur en mathématiques\n",
      "Centre scolaire de Condorcet Jan 2019\n",
      "- présent • Cours particuliers avec des élèves du secondaire sur différents domaines des mathématiques • Cours d'algèbre Développeuse stagiaire\n",
      "| Berou Solutions, Inc.\n",
      "mars\n",
      "- mai 2019 Traduction de wireframes en code frontal Aide à la création d'une application de commande en ligne Recherche d'utilisateurs effectuée par le biais d'enquêtes et d'entretiens PARCOURS SCOLAIRE\n",
      "Lycée de Condorcet\n",
      "· Spécialisation en technologie\n",
      "| Classe de 2020 •\n",
      "Diplômée avec une moyenne de 16/20 • Membre de l'association des étudiants en histoire\n",
      "Excellence académique en histoire, mathématiques et multimédia durant 2 années consécutives RÉFÉRENCES\n",
      "Marion Bardot\n",
      "| Professeure, lycée de Condorcet Caroline Clément | Professeure, lycée Beaulieu Myriam Barbu\n",
      "| Directrice, Centre scolaire de Condorcet\n",
      "01 12 13 14 15\n",
      "bonjour@sitevraimentsuper.fr\n",
      "www.sitevraimentsuper.fr\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents :\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE\n",
      "PROFIL\n",
      "PERSONNEL Je suis étudiante au lycée Condorcet.\n",
      "Je code depuis l'âge de 13 ans et j'aime créer des sites Web et utiliser la technologie pour aider les gens.\n",
      "RÉALISATIONS\n",
      "Chef d'équipe du site Web du lycée\n",
      "-\n",
      "Vice-présidente du club cinématographique du lycée\n",
      "- Trésorière de la société des codeurs du lycée -\n",
      "Premier prix au Hackathon de Condorcet EXPÉRIENCE Tuteur en mathématiques\n",
      "Centre scolaire de Condorcet Jan 2019\n",
      "- présent • Cours particuliers avec des élèves du secondaire sur différents domaines des mathématiques • Cours d'algèbre Développeuse stagiaire\n",
      "| Berou Solutions, Inc.\n",
      "mars\n",
      "- mai 2019 Traduction de wireframes en code frontal Aide à la création d'une application de commande en ligne Recherche d'utilisateurs effectuée par le biais d'enquêtes et d'entretiens PARCOURS SCOLAIRE\n",
      "Lycée de Condorcet\n",
      "· Spécialisation en technologie\n",
      "| Classe de 2020 •\n",
      "Diplômée avec une moyenne de 16/20 • Membre de l'association des étudiants en histoire\n",
      "Excellence académique en histoire, mathématiques et multimédia durant 2 années consécutives RÉFÉRENCES\n",
      "Marion Bardot\n",
      "| Professeure, lycée de Condorcet Caroline Clément | Professeure, lycée Beaulieu Myriam Barbu\n",
      "| Directrice, Centre scolaire de Condorcet\n",
      "01 12 13 14 15\n",
      "bonjour@sitevraimentsuper.fr\n",
      "www.sitevraimentsuper.fr\n"
     ]
    }
   ],
   "source": [
    "## Création d'une liste de phrase\n",
    "list_sentence = []\n",
    "for sent in doc.sents :\n",
    "    list_sentence.append(sent)\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 26,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
<<<<<<< HEAD
     "execution_count": 10,
=======
     "execution_count": 26,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(list_sentence)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 30,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Sentence_CV1'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 32,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence_CV1'] = list_sentence"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 33,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_CV1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SELMA, LAFKIR, CORDE, 80, CODEUSE, ENTHOUSIASTE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(PROFIL)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(PERSONNEL, Je, suis, étudiante, au, lycée, Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Je, code, depuis, l', âge, de, 13, ans, et, j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(RÉALISATIONS)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Sentence_CV1\n",
       "0  (SELMA, LAFKIR, CORDE, 80, CODEUSE, ENTHOUSIASTE)\n",
       "1                                           (PROFIL)\n",
       "2  (PERSONNEL, Je, suis, étudiante, au, lycée, Co...\n",
       "3  (Je, code, depuis, l', âge, de, 13, ans, et, j...\n",
       "4                                     (RÉALISATIONS)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 13,
=======
     "execution_count": 33,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 35,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence_CV1_clean'] = df['Sentence_CV1'].apply(lambda x : str(x).replace(\"(\",\"\").replace(\")\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 36,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_CV1</th>\n",
       "      <th>Sentence_CV1_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(SELMA, LAFKIR, CORDE, 80, CODEUSE, ENTHOUSIASTE)</td>\n",
       "      <td>SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(PROFIL)</td>\n",
       "      <td>PROFIL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(PERSONNEL, Je, suis, étudiante, au, lycée, Co...</td>\n",
       "      <td>PERSONNEL Je suis étudiante au lycée Condorcet.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Je, code, depuis, l', âge, de, 13, ans, et, j...</td>\n",
       "      <td>Je code depuis l'âge de 13 ans et j'aime créer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(RÉALISATIONS)</td>\n",
       "      <td>RÉALISATIONS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Sentence_CV1  \\\n",
       "0  (SELMA, LAFKIR, CORDE, 80, CODEUSE, ENTHOUSIASTE)   \n",
       "1                                           (PROFIL)   \n",
       "2  (PERSONNEL, Je, suis, étudiante, au, lycée, Co...   \n",
       "3  (Je, code, depuis, l', âge, de, 13, ans, et, j...   \n",
       "4                                     (RÉALISATIONS)   \n",
       "\n",
       "                                  Sentence_CV1_clean  \n",
       "0         SELMA LAFKIR CORDE 80 CODEUSE ENTHOUSIASTE  \n",
       "1                                             PROFIL  \n",
       "2    PERSONNEL Je suis étudiante au lycée Condorcet.  \n",
       "3  Je code depuis l'âge de 13 ans et j'aime créer...  \n",
       "4                                       RÉALISATIONS  "
      ]
     },
<<<<<<< HEAD
     "execution_count": 15,
=======
     "execution_count": 36,
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
=======
>>>>>>> f7d2a5dafa97f8ea5e761bf6e1115290200f4876
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
